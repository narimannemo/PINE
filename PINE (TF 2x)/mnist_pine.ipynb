{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, UpSampling2D, Cropping2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINE():\n",
    "    model_name = \"pine_mnist\"     # name for checkpoint\n",
    "    dataset_name = \"mnist\"\n",
    "\n",
    "    def __init__(self, batch_size, dataset_name):\n",
    "    \n",
    "      # Input shape\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.y_dim = 10\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100 \n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate_main_model = 0.0001\n",
    "        self.learning_rate_interpreter = 0.0001\n",
    "        self.checkpoint_dir = 'checkpoint'\n",
    "        self.dataset_name = dataset_name\n",
    " \n",
    "        # Build and compile the interpreter\n",
    "        self.interpreter = self.build_interpreter()\n",
    "\n",
    "        # Build the mian model\n",
    "        self.main_model = self.build_main_model()\n",
    "\n",
    "    \n",
    "#            ___________\n",
    "#           /           \\\n",
    "#          / MAIN  MODEL \\\n",
    "#         /_______________\\        \n",
    "        \n",
    "    def build_main_model(self):\n",
    "\n",
    "\n",
    "        imgs = tf.keras.Input(shape=(28, 28, 1), name=\"img\")\n",
    "        x = tf.keras.layers.Conv2D(64, 4, activation=LeakyReLU(0.2), strides=2, padding='same')(imgs)\n",
    "        x = tf.keras.layers.Conv2D(128, 4, activation=LeakyReLU(0.2), strides=2, padding='same')(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        x = tf.keras.layers.Dense(1024, activation=LeakyReLU(0.2))(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        out = tf.keras.layers.Dense(10, activation=\"softmax\")(x)\n",
    "        model = tf.keras.Model(inputs = imgs, outputs = out)\n",
    "\n",
    "        print(model.summary())\n",
    "        return model\n",
    "\n",
    "    \n",
    "#          _________________\n",
    "#          \\               /\n",
    "#           \\             /\n",
    "#            \\           /\n",
    "#             INTERPRETER\n",
    "#            /           \\\n",
    "#           /             \\\n",
    "#          /_______________\\\n",
    "    \n",
    "    \n",
    "    def build_interpreter(self):\n",
    "\n",
    "        # # Encoder\n",
    "        encoder_input = tf.keras.Input(shape=(28, 28, 1), name=\"img\")\n",
    "        x = tf.keras.layers.Conv2D(64, 4, activation=\"relu\",strides=2, padding='same')(encoder_input)\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        x = tf.keras.layers.Dense(32)(x)\n",
    "         # # Decoder\n",
    "        x = tf.keras.layers.Dense(64 * 14 * 14, activation=\"relu\")(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        x = tf.keras.layers.Reshape((14, 14, 64))(x)\n",
    "        out = tf.keras.layers.Conv2DTranspose(1, 4, activation=\"sigmoid\",strides=2, padding='same')(x)\n",
    "\n",
    "\n",
    "        model = tf.keras.Model(inputs = encoder_input, outputs = out)\n",
    "\n",
    "\n",
    "        print(model.summary())\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def main_model_loss_fn(self, out_img):\n",
    "        CatCrossEnt = tf.keras.losses.CategoricalCrossentropy()\n",
    "        return CatCrossEnt(self.y, out_img)  \n",
    "    def interpreter_loss_fn(self, ints, out_int, imgs, out_img):\n",
    "        c1 = 10000\n",
    "        c2 = 10000\n",
    "        c3 = 15000\n",
    "        CatCrossEnt = tf.keras.losses.CategoricalCrossentropy()\n",
    "        int_error = tf.sqrt(2 * tf.nn.l2_loss(ints - imgs)) / self.batch_size           \n",
    "        l1 = int_error\n",
    "        l2 = tf.dtypes.cast(CatCrossEnt(out_img, out_int), tf.float32)\n",
    "        out_sqrt = tf.keras.backend.sqrt(ints)\n",
    "        sumi = tf.keras.backend.sum(out_sqrt)**2        \n",
    "        l3 = sumi  \n",
    "        return c1*l1+c2*l2+l3/c3\n",
    "\n",
    "        #################################################### \n",
    "        #                                ________________  #\n",
    "        #    ___________                \\               /  #\n",
    "        #   /           \\    Parallel    \\             /   #\n",
    "        #  / MAIN  MODEL \\      ||        \\           /    #\n",
    "        # /_______________\\  Training      INTERPRETER     #\n",
    "        #                                 /           \\    #\n",
    "        #                                /             \\   #\n",
    "        #                               /_______________\\  #\n",
    "        ####################################################    \n",
    "    \n",
    "    def train(self, epochs, batch_size=128):\n",
    "        def categorical_accuracy(self, y_true, y_pred):\n",
    "            return tf.keras.backend.mean(tf.keras.backend.equal(tf.math.argmax(y_true, axis=-1), tf.math.argmax(y_pred, axis=-1)))\n",
    "\n",
    "\n",
    "\n",
    "        start_batch_id=0\n",
    "        self.epochs = epochs\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train,y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = X_train / 255.\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "\n",
    "        X_test = X_test / 255.\n",
    "        X_test = np.expand_dims(X_test, axis=3)\n",
    "\n",
    "        y_vec = np.zeros((len(y_train), 10), dtype=np.float)\n",
    "        for i, label in enumerate(y_train):\n",
    "            y_vec[i, y_train[i]] = 1.0\n",
    "\n",
    "        y_vec_test = np.zeros((len(y_test), 10), dtype=np.float)\n",
    "        for i, label in enumerate(y_test):\n",
    "            y_vec_test[i, y_test[i]] = 1.0\n",
    "\n",
    "        \n",
    "        opt_interpreter = tf.keras.optimizers.Adam(self.learning_rate_interpreter)\n",
    "        opt_main_model = tf.keras.optimizers.Adam(self.learning_rate_main_model)\n",
    "\n",
    "\n",
    "        self.num_batches = len(X_train) // self.batch_size  \n",
    "        for epoch in range(self.epochs):\n",
    "            for idx in range(start_batch_id, self.num_batches):\n",
    "                print('Epoch:[',epoch,'] Batch:',idx,'/',self.num_batches, end=\" \")\n",
    "                imgs = X_train[idx * self.batch_size:(idx+1) * self.batch_size]\n",
    "                self.y = y_vec[idx * self.batch_size:(idx+1) * self.batch_size]\n",
    "\n",
    "                with tf.GradientTape() as int_tape, tf.GradientTape() as main_tape:\n",
    "\n",
    "                    ints = self.interpreter(imgs, training=True)\n",
    "                    \n",
    "                    out_int = self.main_model(ints, training=True)\n",
    "\n",
    "                    out_img = self.main_model(imgs, training=True)\n",
    "\n",
    "                    # Main Model Loss\n",
    "                    loss_eval = self.main_model_loss_fn(out_img)\n",
    "                    \n",
    "                    # Interpreter Loss\n",
    "                    interpreter_loss = self.interpreter_loss_fn(ints, out_int, imgs, out_img)\n",
    "                    \n",
    "                # Get gradients of loss wrt the weights.    \n",
    "                main_model_grads = main_tape.gradient(loss_eval, self.main_model.trainable_variables)                                           \n",
    "                interpreter_grads = int_tape.gradient(interpreter_loss, self.interpreter.trainable_variables)\n",
    "\n",
    "                # Update the weights of the model.\n",
    "                    \n",
    "                opt_main_model.apply_gradients(zip(main_model_grads, self.main_model.trainable_variables))                        \n",
    "                opt_interpreter.apply_gradients(zip(interpreter_grads, self.interpreter.trainable_variables))\n",
    "                \n",
    "\n",
    "                \n",
    "\n",
    "                print('Main Model Loss:',loss_eval.numpy(), end=\" \")\n",
    "                print('Interpreter Loss:',interpreter_loss.numpy())\n",
    "        \n",
    "\n",
    "            ints_test = self.interpreter(X_test[0:64], training=False)\n",
    "\n",
    "            out_int_test = self.main_model(ints_test, training=False)\n",
    "\n",
    "            out_img_test = self.main_model(X_test[0:64], training=False)\n",
    "\n",
    "            main_model_acc = categorical_accuracy(self, y_vec_test[0:64],out_img_test)\n",
    "            interpreter_acc =categorical_accuracy(self, y_vec_test[0:64],out_int_test)\n",
    "            print(' Main Model Acc: ', main_model_acc.numpy(), 'Interpreter Acc: ', interpreter_acc.numpy())\n",
    "            self.main_model.save(self.checkpoint_dir)\n",
    "            self.interpreter.save(self.checkpoint_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img (InputLayer)             [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 14, 14, 64)        1088      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                401440    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12544)             413952    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 12544)             50176     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 28, 28, 1)         1025      \n",
      "=================================================================\n",
      "Total params: 867,681\n",
      "Trainable params: 842,593\n",
      "Non-trainable params: 25,088\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img (InputLayer)             [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        1088      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 128)         131200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              6423552   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 6,570,698\n",
      "Trainable params: 6,568,394\n",
      "Non-trainable params: 2,304\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch:[ 0 ] Batch: 0 / 937 Main Model Loss: 2.962132 Interpreter Loss: 124567.984\n",
      "Epoch:[ 0 ] Batch: 1 / 937 Main Model Loss: 1.2868031 Interpreter Loss: 124204.76\n",
      "Epoch:[ 0 ] Batch: 2 / 937 Main Model Loss: 1.7151783 Interpreter Loss: 122416.42\n",
      "Epoch:[ 0 ] Batch: 3 / 937 Main Model Loss: 0.9094276 Interpreter Loss: 119887.125\n",
      "Epoch:[ 0 ] Batch: 4 / 937 Main Model Loss: 0.946021 Interpreter Loss: 116461.92\n",
      "Epoch:[ 0 ] Batch: 5 / 937 Main Model Loss: 0.6738621 Interpreter Loss: 115292.66\n",
      "Epoch:[ 0 ] Batch: 6 / 937 Main Model Loss: 0.6748129 Interpreter Loss: 112223.766\n",
      "Epoch:[ 0 ] Batch: 7 / 937 Main Model Loss: 0.9926151 Interpreter Loss: 111793.2\n",
      "Epoch:[ 0 ] Batch: 8 / 937 Main Model Loss: 0.7883048 Interpreter Loss: 112935.47\n",
      "Epoch:[ 0 ] Batch: 9 / 937 Main Model Loss: 1.040704 Interpreter Loss: 113129.164\n",
      "Epoch:[ 0 ] Batch: 10 / 937 Main Model Loss: 0.72481686 Interpreter Loss: 110672.15\n",
      "Epoch:[ 0 ] Batch: 11 / 937 Main Model Loss: 0.447113 Interpreter Loss: 113867.48\n",
      "Epoch:[ 0 ] Batch: 12 / 937 Main Model Loss: 0.6477072 Interpreter Loss: 109649.08\n",
      "Epoch:[ 0 ] Batch: 13 / 937 Main Model Loss: 0.8181821 Interpreter Loss: 111401.445\n",
      "Epoch:[ 0 ] Batch: 14 / 937 Main Model Loss: 0.6033607 Interpreter Loss: 109432.25\n",
      "Epoch:[ 0 ] Batch: 15 / 937 Main Model Loss: 0.49772355 Interpreter Loss: 108676.36\n",
      "Epoch:[ 0 ] Batch: 16 / 937 Main Model Loss: 0.89251995 Interpreter Loss: 109424.734\n",
      "Epoch:[ 0 ] Batch: 17 / 937 Main Model Loss: 0.97133327 Interpreter Loss: 108892.35\n",
      "Epoch:[ 0 ] Batch: 18 / 937 Main Model Loss: 0.23847549 Interpreter Loss: 105925.52\n",
      "Epoch:[ 0 ] Batch: 19 / 937 Main Model Loss: 0.78052217 Interpreter Loss: 108225.49\n",
      "Epoch:[ 0 ] Batch: 20 / 937 Main Model Loss: 0.5785452 Interpreter Loss: 107461.266\n",
      "Epoch:[ 0 ] Batch: 21 / 937 Main Model Loss: 0.690725 Interpreter Loss: 107801.64\n",
      "Epoch:[ 0 ] Batch: 22 / 937 Main Model Loss: 0.23800232 Interpreter Loss: 106659.2\n",
      "Epoch:[ 0 ] Batch: 23 / 937 Main Model Loss: 0.44263387 Interpreter Loss: 107010.44\n",
      "Epoch:[ 0 ] Batch: 24 / 937 Main Model Loss: 0.30817872 Interpreter Loss: 106193.055\n",
      "Epoch:[ 0 ] Batch: 25 / 937 Main Model Loss: 0.340351 Interpreter Loss: 107318.234\n",
      "Epoch:[ 0 ] Batch: 26 / 937 Main Model Loss: 0.43426692 Interpreter Loss: 105040.34\n",
      "Epoch:[ 0 ] Batch: 27 / 937 Main Model Loss: 0.5740347 Interpreter Loss: 105755.41\n",
      "Epoch:[ 0 ] Batch: 28 / 937 Main Model Loss: 0.3191112 Interpreter Loss: 105166.42\n",
      "Epoch:[ 0 ] Batch: 29 / 937 Main Model Loss: 0.1845654 Interpreter Loss: 105210.98\n",
      "Epoch:[ 0 ] Batch: 30 / 937 Main Model Loss: 0.27660865 Interpreter Loss: 105074.39\n",
      "Epoch:[ 0 ] Batch: 31 / 937 Main Model Loss: 0.32136428 Interpreter Loss: 106357.164\n",
      "Epoch:[ 0 ] Batch: 32 / 937 Main Model Loss: 0.46829697 Interpreter Loss: 104213.95\n",
      "Epoch:[ 0 ] Batch: 33 / 937 Main Model Loss: 0.16230156 Interpreter Loss: 103758.85\n",
      "Epoch:[ 0 ] Batch: 34 / 937 Main Model Loss: 0.44861022 Interpreter Loss: 104333.02\n",
      "Epoch:[ 0 ] Batch: 35 / 937 Main Model Loss: 0.2618108 Interpreter Loss: 104173.36\n",
      "Epoch:[ 0 ] Batch: 36 / 937 Main Model Loss: 0.24986199 Interpreter Loss: 104316.43\n",
      "Epoch:[ 0 ] Batch: 37 / 937 Main Model Loss: 0.4856814 Interpreter Loss: 107259.73\n",
      "Epoch:[ 0 ] Batch: 38 / 937 Main Model Loss: 0.36580747 Interpreter Loss: 105938.445\n",
      "Epoch:[ 0 ] Batch: 39 / 937 Main Model Loss: 0.06655978 Interpreter Loss: 104157.59\n",
      "Epoch:[ 0 ] Batch: 40 / 937 Main Model Loss: 0.29098633 Interpreter Loss: 104276.29\n",
      "Epoch:[ 0 ] Batch: 41 / 937 Main Model Loss: 0.5424179 Interpreter Loss: 104027.586\n",
      "Epoch:[ 0 ] Batch: 42 / 937 Main Model Loss: 0.32767805 Interpreter Loss: 104645.0\n",
      "Epoch:[ 0 ] Batch: 43 / 937 Main Model Loss: 0.38312548 Interpreter Loss: 104750.83\n",
      "Epoch:[ 0 ] Batch: 44 / 937 Main Model Loss: 0.22291112 Interpreter Loss: 103435.32\n",
      "Epoch:[ 0 ] Batch: 45 / 937 Main Model Loss: 0.30512193 Interpreter Loss: 104004.86\n",
      "Epoch:[ 0 ] Batch: 46 / 937 Main Model Loss: 0.30030054 Interpreter Loss: 103726.266\n",
      "Epoch:[ 0 ] Batch: 47 / 937 Main Model Loss: 0.44413304 Interpreter Loss: 104537.75\n",
      "Epoch:[ 0 ] Batch: 48 / 937 Main Model Loss: 0.29073653 Interpreter Loss: 104034.016\n",
      "Epoch:[ 0 ] Batch: 49 / 937 Main Model Loss: 0.13645785 Interpreter Loss: 103265.07\n",
      "Epoch:[ 0 ] Batch: 50 / 937 Main Model Loss: 0.28502816 Interpreter Loss: 104468.45\n",
      "Epoch:[ 0 ] Batch: 51 / 937 Main Model Loss: 0.37967592 Interpreter Loss: 103669.93\n",
      "Epoch:[ 0 ] Batch: 52 / 937 Main Model Loss: 0.2804981 Interpreter Loss: 104660.24\n",
      "Epoch:[ 0 ] Batch: 53 / 937 Main Model Loss: 0.20905386 Interpreter Loss: 103261.49\n",
      "Epoch:[ 0 ] Batch: 54 / 937 Main Model Loss: 0.37130284 Interpreter Loss: 103497.59\n",
      "Epoch:[ 0 ] Batch: 55 / 937 Main Model Loss: 0.24090675 Interpreter Loss: 103915.81\n",
      "Epoch:[ 0 ] Batch: 56 / 937 Main Model Loss: 0.120212734 Interpreter Loss: 103145.5\n",
      "Epoch:[ 0 ] Batch: 57 / 937 Main Model Loss: 0.43718535 Interpreter Loss: 103274.61\n",
      "Epoch:[ 0 ] Batch: 58 / 937 Main Model Loss: 0.5891243 Interpreter Loss: 103418.57\n",
      "Epoch:[ 0 ] Batch: 59 / 937 Main Model Loss: 0.45929328 Interpreter Loss: 104307.05\n",
      "Epoch:[ 0 ] Batch: 60 / 937 Main Model Loss: 0.20295417 Interpreter Loss: 102695.83\n",
      "Epoch:[ 0 ] Batch: 61 / 937 Main Model Loss: 0.16451141 Interpreter Loss: 102854.21\n",
      "Epoch:[ 0 ] Batch: 62 / 937 Main Model Loss: 0.25254482 Interpreter Loss: 104868.0\n",
      "Epoch:[ 0 ] Batch: 63 / 937 Main Model Loss: 0.3079428 Interpreter Loss: 103332.26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 0 ] Batch: 64 / 937 Main Model Loss: 0.25830138 Interpreter Loss: 103829.164\n",
      "Epoch:[ 0 ] Batch: 65 / 937 Main Model Loss: 0.3505766 Interpreter Loss: 103837.16\n",
      "Epoch:[ 0 ] Batch: 66 / 937 Main Model Loss: 0.5353695 Interpreter Loss: 103167.66\n",
      "Epoch:[ 0 ] Batch: 67 / 937 Main Model Loss: 0.36966184 Interpreter Loss: 102577.016\n",
      "Epoch:[ 0 ] Batch: 68 / 937 Main Model Loss: 0.26108032 Interpreter Loss: 103051.5\n",
      "Epoch:[ 0 ] Batch: 69 / 937 Main Model Loss: 0.16889888 Interpreter Loss: 104021.57\n",
      "Epoch:[ 0 ] Batch: 70 / 937 Main Model Loss: 0.14491834 Interpreter Loss: 102313.31\n",
      "Epoch:[ 0 ] Batch: 71 / 937 Main Model Loss: 0.10331985 Interpreter Loss: 102768.555\n",
      "Epoch:[ 0 ] Batch: 72 / 937 Main Model Loss: 0.34886116 Interpreter Loss: 104375.91\n",
      "Epoch:[ 0 ] Batch: 73 / 937 Main Model Loss: 0.17731528 Interpreter Loss: 103576.125\n",
      "Epoch:[ 0 ] Batch: 74 / 937 Main Model Loss: 0.3332975 Interpreter Loss: 102911.29\n",
      "Epoch:[ 0 ] Batch: 75 / 937 Main Model Loss: 0.19273831 Interpreter Loss: 104745.24\n",
      "Epoch:[ 0 ] Batch: 76 / 937 Main Model Loss: 0.168403 Interpreter Loss: 103215.76\n",
      "Epoch:[ 0 ] Batch: 77 / 937 Main Model Loss: 0.40119338 Interpreter Loss: 103340.39\n",
      "Epoch:[ 0 ] Batch: 78 / 937 Main Model Loss: 0.18962194 Interpreter Loss: 104140.766\n",
      "Epoch:[ 0 ] Batch: 79 / 937 Main Model Loss: 0.1285381 Interpreter Loss: 104597.35\n",
      "Epoch:[ 0 ] Batch: 80 / 937 Main Model Loss: 0.6135894 Interpreter Loss: 105775.25\n",
      "Epoch:[ 0 ] Batch: 81 / 937 Main Model Loss: 0.16585514 Interpreter Loss: 102980.08\n",
      "Epoch:[ 0 ] Batch: 82 / 937 Main Model Loss: 0.27610412 Interpreter Loss: 104130.05\n",
      "Epoch:[ 0 ] Batch: 83 / 937 Main Model Loss: 0.2553903 Interpreter Loss: 103838.52\n",
      "Epoch:[ 0 ] Batch: 84 / 937 Main Model Loss: 0.16657929 Interpreter Loss: 102692.02\n",
      "Epoch:[ 0 ] Batch: 85 / 937 Main Model Loss: 0.08212085 Interpreter Loss: 102694.16\n",
      "Epoch:[ 0 ] Batch: 86 / 937 Main Model Loss: 0.2513544 Interpreter Loss: 103125.18\n",
      "Epoch:[ 0 ] Batch: 87 / 937 Main Model Loss: 0.27251428 Interpreter Loss: 102875.67\n",
      "Epoch:[ 0 ] Batch: 88 / 937 Main Model Loss: 0.34853223 Interpreter Loss: 103695.09\n",
      "Epoch:[ 0 ] Batch: 89 / 937 Main Model Loss: 0.112960875 Interpreter Loss: 102702.336\n",
      "Epoch:[ 0 ] Batch: 90 / 937 Main Model Loss: 0.09937952 Interpreter Loss: 102464.15\n",
      "Epoch:[ 0 ] Batch: 91 / 937 Main Model Loss: 0.21454178 Interpreter Loss: 103363.9\n",
      "Epoch:[ 0 ] Batch: 92 / 937 Main Model Loss: 0.18120743 Interpreter Loss: 102280.26\n",
      "Epoch:[ 0 ] Batch: 93 / 937 Main Model Loss: 0.16236164 Interpreter Loss: 101757.266\n",
      "Epoch:[ 0 ] Batch: 94 / 937 Main Model Loss: 0.18515103 Interpreter Loss: 101188.36\n",
      "Epoch:[ 0 ] Batch: 95 / 937 Main Model Loss: 0.27715203 Interpreter Loss: 102339.18\n",
      "Epoch:[ 0 ] Batch: 96 / 937 Main Model Loss: 0.08990159 Interpreter Loss: 101932.414\n",
      "Epoch:[ 0 ] Batch: 97 / 937 Main Model Loss: 0.20450446 Interpreter Loss: 103350.37\n",
      "Epoch:[ 0 ] Batch: 98 / 937 Main Model Loss: 0.27891335 Interpreter Loss: 104280.195\n",
      "Epoch:[ 0 ] Batch: 99 / 937 Main Model Loss: 0.26525593 Interpreter Loss: 102621.84\n",
      "Epoch:[ 0 ] Batch: 100 / 937 Main Model Loss: 0.31367052 Interpreter Loss: 103196.16\n",
      "Epoch:[ 0 ] Batch: 101 / 937 Main Model Loss: 0.30410627 Interpreter Loss: 102760.83\n",
      "Epoch:[ 0 ] Batch: 102 / 937 Main Model Loss: 0.1345938 Interpreter Loss: 101796.42\n",
      "Epoch:[ 0 ] Batch: 103 / 937 Main Model Loss: 0.16969182 Interpreter Loss: 101894.984\n",
      "Epoch:[ 0 ] Batch: 104 / 937 Main Model Loss: 0.31741217 Interpreter Loss: 102729.38\n",
      "Epoch:[ 0 ] Batch: 105 / 937 Main Model Loss: 0.11414428 Interpreter Loss: 102285.59\n",
      "Epoch:[ 0 ] Batch: 106 / 937 Main Model Loss: 0.53669465 Interpreter Loss: 103038.62\n",
      "Epoch:[ 0 ] Batch: 107 / 937 Main Model Loss: 0.34337074 Interpreter Loss: 102711.414\n",
      "Epoch:[ 0 ] Batch: 108 / 937 Main Model Loss: 0.42963958 Interpreter Loss: 105556.75\n",
      "Epoch:[ 0 ] Batch: 109 / 937 Main Model Loss: 0.45659298 Interpreter Loss: 102773.49\n",
      "Epoch:[ 0 ] Batch: 110 / 937 Main Model Loss: 0.20294508 Interpreter Loss: 102397.85\n",
      "Epoch:[ 0 ] Batch: 111 / 937 Main Model Loss: 0.39006802 Interpreter Loss: 102061.73\n",
      "Epoch:[ 0 ] Batch: 112 / 937 Main Model Loss: 0.42230856 Interpreter Loss: 103527.69\n",
      "Epoch:[ 0 ] Batch: 113 / 937 Main Model Loss: 0.42274323 Interpreter Loss: 103754.34\n",
      "Epoch:[ 0 ] Batch: 114 / 937 Main Model Loss: 0.337686 Interpreter Loss: 102809.91\n",
      "Epoch:[ 0 ] Batch: 115 / 937 Main Model Loss: 0.15574212 Interpreter Loss: 102329.53\n",
      "Epoch:[ 0 ] Batch: 116 / 937 Main Model Loss: 0.13510755 Interpreter Loss: 101723.57\n",
      "Epoch:[ 0 ] Batch: 117 / 937 Main Model Loss: 0.27213588 Interpreter Loss: 102963.41\n",
      "Epoch:[ 0 ] Batch: 118 / 937 Main Model Loss: 0.24492869 Interpreter Loss: 102002.4\n",
      "Epoch:[ 0 ] Batch: 119 / 937 Main Model Loss: 0.22681044 Interpreter Loss: 103455.47\n",
      "Epoch:[ 0 ] Batch: 120 / 937 Main Model Loss: 0.21139008 Interpreter Loss: 102760.31\n",
      "Epoch:[ 0 ] Batch: 121 / 937 Main Model Loss: 0.33195794 Interpreter Loss: 103724.15\n",
      "Epoch:[ 0 ] Batch: 122 / 937 Main Model Loss: 0.31536332 Interpreter Loss: 103111.77\n",
      "Epoch:[ 0 ] Batch: 123 / 937 Main Model Loss: 0.35750777 Interpreter Loss: 102487.94\n",
      "Epoch:[ 0 ] Batch: 124 / 937 Main Model Loss: 0.12532365 Interpreter Loss: 101946.1\n",
      "Epoch:[ 0 ] Batch: 125 / 937 Main Model Loss: 0.121280596 Interpreter Loss: 102152.53\n",
      "Epoch:[ 0 ] Batch: 126 / 937 Main Model Loss: 0.30866465 Interpreter Loss: 101674.0\n",
      "Epoch:[ 0 ] Batch: 127 / 937 Main Model Loss: 0.1280464 Interpreter Loss: 101957.78\n",
      "Epoch:[ 0 ] Batch: 128 / 937 Main Model Loss: 0.4769647 Interpreter Loss: 103526.83\n",
      "Epoch:[ 0 ] Batch: 129 / 937 Main Model Loss: 0.2951478 Interpreter Loss: 102187.43\n",
      "Epoch:[ 0 ] Batch: 130 / 937 Main Model Loss: 0.04973739 Interpreter Loss: 101701.58\n",
      "Epoch:[ 0 ] Batch: 131 / 937 Main Model Loss: 0.09360779 Interpreter Loss: 101906.92\n",
      "Epoch:[ 0 ] Batch: 132 / 937 Main Model Loss: 0.32219237 Interpreter Loss: 102176.77\n",
      "Epoch:[ 0 ] Batch: 133 / 937 Main Model Loss: 0.10262847 Interpreter Loss: 101665.65\n",
      "Epoch:[ 0 ] Batch: 134 / 937 Main Model Loss: 0.19456851 Interpreter Loss: 103352.66\n",
      "Epoch:[ 0 ] Batch: 135 / 937 Main Model Loss: 0.36868882 Interpreter Loss: 103160.85\n",
      "Epoch:[ 0 ] Batch: 136 / 937 Main Model Loss: 0.7321758 Interpreter Loss: 103370.18\n",
      "Epoch:[ 0 ] Batch: 137 / 937 Main Model Loss: 0.35028985 Interpreter Loss: 103011.984\n",
      "Epoch:[ 0 ] Batch: 138 / 937 Main Model Loss: 0.31686276 Interpreter Loss: 106388.81\n",
      "Epoch:[ 0 ] Batch: 139 / 937 Main Model Loss: 0.33827767 Interpreter Loss: 103351.14\n",
      "Epoch:[ 0 ] Batch: 140 / 937 Main Model Loss: 0.28571868 Interpreter Loss: 100763.516\n",
      "Epoch:[ 0 ] Batch: 141 / 937 Main Model Loss: 0.15234235 Interpreter Loss: 100686.62\n",
      "Epoch:[ 0 ] Batch: 142 / 937 Main Model Loss: 0.34038877 Interpreter Loss: 102081.33\n",
      "Epoch:[ 0 ] Batch: 143 / 937 Main Model Loss: 0.20301619 Interpreter Loss: 102333.09\n",
      "Epoch:[ 0 ] Batch: 144 / 937 Main Model Loss: 0.43343604 Interpreter Loss: 101028.63\n",
      "Epoch:[ 0 ] Batch: 145 / 937 Main Model Loss: 0.20301765 Interpreter Loss: 100939.56\n",
      "Epoch:[ 0 ] Batch: 146 / 937 Main Model Loss: 0.5536394 Interpreter Loss: 101742.44\n",
      "Epoch:[ 0 ] Batch: 147 / 937 Main Model Loss: 0.44583175 Interpreter Loss: 103476.875\n",
      "Epoch:[ 0 ] Batch: 148 / 937 Main Model Loss: 0.23791605 Interpreter Loss: 101785.14\n",
      "Epoch:[ 0 ] Batch: 149 / 937 Main Model Loss: 0.18569416 Interpreter Loss: 102280.84\n",
      "Epoch:[ 0 ] Batch: 150 / 937 Main Model Loss: 0.22609434 Interpreter Loss: 103313.25\n",
      "Epoch:[ 0 ] Batch: 151 / 937 Main Model Loss: 0.08917643 Interpreter Loss: 100975.445\n",
      "Epoch:[ 0 ] Batch: 152 / 937 Main Model Loss: 0.45010814 Interpreter Loss: 102084.875\n",
      "Epoch:[ 0 ] Batch: 153 / 937 Main Model Loss: 0.092830494 Interpreter Loss: 101183.375\n",
      "Epoch:[ 0 ] Batch: 154 / 937 Main Model Loss: 0.076041825 Interpreter Loss: 101703.94\n",
      "Epoch:[ 0 ] Batch: 155 / 937 Main Model Loss: 0.27527946 Interpreter Loss: 101948.695\n",
      "Epoch:[ 0 ] Batch: 156 / 937 Main Model Loss: 0.16810097 Interpreter Loss: 101686.016\n",
      "Epoch:[ 0 ] Batch: 157 / 937 Main Model Loss: 0.28509074 Interpreter Loss: 101228.64\n",
      "Epoch:[ 0 ] Batch: 158 / 937 Main Model Loss: 0.2016052 Interpreter Loss: 101872.37\n",
      "Epoch:[ 0 ] Batch: 159 / 937 Main Model Loss: 0.35253918 Interpreter Loss: 102549.53\n",
      "Epoch:[ 0 ] Batch: 160 / 937 Main Model Loss: 0.2570787 Interpreter Loss: 102965.03\n",
      "Epoch:[ 0 ] Batch: 161 / 937 Main Model Loss: 0.10961151 Interpreter Loss: 101282.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 0 ] Batch: 162 / 937 Main Model Loss: 0.14466569 Interpreter Loss: 100512.87\n",
      "Epoch:[ 0 ] Batch: 163 / 937 Main Model Loss: 0.083505824 Interpreter Loss: 101540.586\n",
      "Epoch:[ 0 ] Batch: 164 / 937 Main Model Loss: 0.08120722 Interpreter Loss: 100678.39\n",
      "Epoch:[ 0 ] Batch: 165 / 937 Main Model Loss: 0.11442496 Interpreter Loss: 101376.36\n",
      "Epoch:[ 0 ] Batch: 166 / 937 Main Model Loss: 0.12756118 Interpreter Loss: 100672.78\n",
      "Epoch:[ 0 ] Batch: 167 / 937 Main Model Loss: 0.18595552 Interpreter Loss: 101276.69\n",
      "Epoch:[ 0 ] Batch: 168 / 937 Main Model Loss: 0.24144441 Interpreter Loss: 101484.266\n",
      "Epoch:[ 0 ] Batch: 169 / 937 Main Model Loss: 0.19018412 Interpreter Loss: 100721.766\n",
      "Epoch:[ 0 ] Batch: 170 / 937 Main Model Loss: 0.1250321 Interpreter Loss: 100361.85\n",
      "Epoch:[ 0 ] Batch: 171 / 937 Main Model Loss: 0.1801266 Interpreter Loss: 100978.05\n",
      "Epoch:[ 0 ] Batch: 172 / 937 Main Model Loss: 0.19019741 Interpreter Loss: 100000.09\n",
      "Epoch:[ 0 ] Batch: 173 / 937 Main Model Loss: 0.17622793 Interpreter Loss: 100759.29\n",
      "Epoch:[ 0 ] Batch: 174 / 937 Main Model Loss: 0.12395454 Interpreter Loss: 101469.74\n",
      "Epoch:[ 0 ] Batch: 175 / 937 Main Model Loss: 0.15894118 Interpreter Loss: 100073.28\n",
      "Epoch:[ 0 ] Batch: 176 / 937 Main Model Loss: 0.0963162 Interpreter Loss: 100394.41\n",
      "Epoch:[ 0 ] Batch: 177 / 937 Main Model Loss: 0.118476115 Interpreter Loss: 100571.06\n",
      "Epoch:[ 0 ] Batch: 178 / 937 Main Model Loss: 0.0995671 Interpreter Loss: 100278.055\n",
      "Epoch:[ 0 ] Batch: 179 / 937 Main Model Loss: 0.2516133 Interpreter Loss: 101207.86\n",
      "Epoch:[ 0 ] Batch: 180 / 937 Main Model Loss: 0.3087107 Interpreter Loss: 100987.234\n",
      "Epoch:[ 0 ] Batch: 181 / 937 Main Model Loss: 0.35840502 Interpreter Loss: 101427.0\n",
      "Epoch:[ 0 ] Batch: 182 / 937 Main Model Loss: 0.38625148 Interpreter Loss: 101529.766\n",
      "Epoch:[ 0 ] Batch: 183 / 937 Main Model Loss: 0.20822032 Interpreter Loss: 101030.55\n",
      "Epoch:[ 0 ] Batch: 184 / 937 Main Model Loss: 0.11559639 Interpreter Loss: 101407.98\n",
      "Epoch:[ 0 ] Batch: 185 / 937 Main Model Loss: 0.3233552 Interpreter Loss: 100652.484\n",
      "Epoch:[ 0 ] Batch: 186 / 937 Main Model Loss: 0.14886746 Interpreter Loss: 100765.74\n",
      "Epoch:[ 0 ] Batch: 187 / 937 Main Model Loss: 0.28579175 Interpreter Loss: 100099.41\n",
      "Epoch:[ 0 ] Batch: 188 / 937 Main Model Loss: 0.24195582 Interpreter Loss: 101019.94\n",
      "Epoch:[ 0 ] Batch: 189 / 937 Main Model Loss: 0.041500274 Interpreter Loss: 99756.664\n",
      "Epoch:[ 0 ] Batch: 190 / 937 Main Model Loss: 0.24992585 Interpreter Loss: 101178.27\n",
      "Epoch:[ 0 ] Batch: 191 / 937 Main Model Loss: 0.30246258 Interpreter Loss: 100682.4\n",
      "Epoch:[ 0 ] Batch: 192 / 937 Main Model Loss: 0.3243316 Interpreter Loss: 101611.64\n",
      "Epoch:[ 0 ] Batch: 193 / 937 Main Model Loss: 0.255557 Interpreter Loss: 101490.92\n",
      "Epoch:[ 0 ] Batch: 194 / 937 Main Model Loss: 0.12504011 Interpreter Loss: 101159.66\n",
      "Epoch:[ 0 ] Batch: 195 / 937 Main Model Loss: 0.2596096 Interpreter Loss: 99864.9\n",
      "Epoch:[ 0 ] Batch: 196 / 937 Main Model Loss: 0.8526858 Interpreter Loss: 99912.9\n",
      "Epoch:[ 0 ] Batch: 197 / 937 Main Model Loss: 0.54601085 Interpreter Loss: 100074.92\n",
      "Epoch:[ 0 ] Batch: 198 / 937 Main Model Loss: 0.55374765 Interpreter Loss: 99521.734\n",
      "Epoch:[ 0 ] Batch: 199 / 937 Main Model Loss: 0.24099937 Interpreter Loss: 100872.92\n",
      "Epoch:[ 0 ] Batch: 200 / 937 Main Model Loss: 0.15229982 Interpreter Loss: 100423.69\n",
      "Epoch:[ 0 ] Batch: 201 / 937 Main Model Loss: 0.18088749 Interpreter Loss: 100362.09\n",
      "Epoch:[ 0 ] Batch: 202 / 937 Main Model Loss: 0.36546853 Interpreter Loss: 102268.93\n",
      "Epoch:[ 0 ] Batch: 203 / 937 Main Model Loss: 0.43841845 Interpreter Loss: 101213.08\n",
      "Epoch:[ 0 ] Batch: 204 / 937 Main Model Loss: 0.27987993 Interpreter Loss: 101543.64\n",
      "Epoch:[ 0 ] Batch: 205 / 937 Main Model Loss: 0.26882482 Interpreter Loss: 100282.414\n",
      "Epoch:[ 0 ] Batch: 206 / 937 Main Model Loss: 0.17644525 Interpreter Loss: 100184.35\n",
      "Epoch:[ 0 ] Batch: 207 / 937 Main Model Loss: 0.12968716 Interpreter Loss: 98679.11\n",
      "Epoch:[ 0 ] Batch: 208 / 937 Main Model Loss: 0.10676368 Interpreter Loss: 99778.42\n",
      "Epoch:[ 0 ] Batch: 209 / 937 Main Model Loss: 0.2733604 Interpreter Loss: 99764.68\n",
      "Epoch:[ 0 ] Batch: 210 / 937 Main Model Loss: 0.059075896 Interpreter Loss: 98751.01\n",
      "Epoch:[ 0 ] Batch: 211 / 937 Main Model Loss: 0.33059743 Interpreter Loss: 99779.53\n",
      "Epoch:[ 0 ] Batch: 212 / 937 Main Model Loss: 0.08451806 Interpreter Loss: 99939.89\n",
      "Epoch:[ 0 ] Batch: 213 / 937 Main Model Loss: 0.3018258 Interpreter Loss: 101883.44\n",
      "Epoch:[ 0 ] Batch: 214 / 937 Main Model Loss: 0.33770525 Interpreter Loss: 101269.89\n",
      "Epoch:[ 0 ] Batch: 215 / 937 Main Model Loss: 0.1380447 Interpreter Loss: 99222.95\n",
      "Epoch:[ 0 ] Batch: 216 / 937 Main Model Loss: 0.17398642 Interpreter Loss: 100143.266\n",
      "Epoch:[ 0 ] Batch: 217 / 937 Main Model Loss: 0.13430789 Interpreter Loss: 100512.76\n",
      "Epoch:[ 0 ] Batch: 218 / 937 Main Model Loss: 0.48602992 Interpreter Loss: 100089.48\n",
      "Epoch:[ 0 ] Batch: 219 / 937 Main Model Loss: 0.2131717 Interpreter Loss: 100280.35\n",
      "Epoch:[ 0 ] Batch: 220 / 937 Main Model Loss: 0.12286385 Interpreter Loss: 101202.77\n",
      "Epoch:[ 0 ] Batch: 221 / 937 Main Model Loss: 0.1881374 Interpreter Loss: 100441.19\n",
      "Epoch:[ 0 ] Batch: 222 / 937 Main Model Loss: 0.26766536 Interpreter Loss: 99230.48\n",
      "Epoch:[ 0 ] Batch: 223 / 937 Main Model Loss: 0.22567728 Interpreter Loss: 100491.25\n",
      "Epoch:[ 0 ] Batch: 224 / 937 Main Model Loss: 0.41754884 Interpreter Loss: 100320.6\n",
      "Epoch:[ 0 ] Batch: 225 / 937 Main Model Loss: 0.1982152 Interpreter Loss: 98734.17\n",
      "Epoch:[ 0 ] Batch: 226 / 937 Main Model Loss: 0.06399123 Interpreter Loss: 98989.3\n",
      "Epoch:[ 0 ] Batch: 227 / 937 Main Model Loss: 0.27971667 Interpreter Loss: 100216.55\n",
      "Epoch:[ 0 ] Batch: 228 / 937 Main Model Loss: 0.18471715 Interpreter Loss: 100377.734\n",
      "Epoch:[ 0 ] Batch: 229 / 937 Main Model Loss: 0.30893132 Interpreter Loss: 101886.375\n",
      "Epoch:[ 0 ] Batch: 230 / 937 Main Model Loss: 0.37801772 Interpreter Loss: 101358.68\n",
      "Epoch:[ 0 ] Batch: 231 / 937 Main Model Loss: 0.3264225 Interpreter Loss: 100821.82\n",
      "Epoch:[ 0 ] Batch: 232 / 937 Main Model Loss: 0.19468394 Interpreter Loss: 99574.1\n",
      "Epoch:[ 0 ] Batch: 233 / 937 Main Model Loss: 0.13293616 Interpreter Loss: 98938.17\n",
      "Epoch:[ 0 ] Batch: 234 / 937 Main Model Loss: 0.05010138 Interpreter Loss: 99129.164\n",
      "Epoch:[ 0 ] Batch: 235 / 937 Main Model Loss: 0.16960365 Interpreter Loss: 98396.97\n",
      "Epoch:[ 0 ] Batch: 236 / 937 Main Model Loss: 0.25142562 Interpreter Loss: 100617.516\n",
      "Epoch:[ 0 ] Batch: 237 / 937 Main Model Loss: 0.30239522 Interpreter Loss: 98759.62\n",
      "Epoch:[ 0 ] Batch: 238 / 937 Main Model Loss: 0.1607373 Interpreter Loss: 98896.664\n",
      "Epoch:[ 0 ] Batch: 239 / 937 Main Model Loss: 0.1082281 Interpreter Loss: 98962.7\n",
      "Epoch:[ 0 ] Batch: 240 / 937 Main Model Loss: 0.17031793 Interpreter Loss: 98476.54\n",
      "Epoch:[ 0 ] Batch: 241 / 937 Main Model Loss: 0.09182642 Interpreter Loss: 97814.18\n",
      "Epoch:[ 0 ] Batch: 242 / 937 Main Model Loss: 0.2364157 Interpreter Loss: 98872.82\n",
      "Epoch:[ 0 ] Batch: 243 / 937 Main Model Loss: 0.17623946 Interpreter Loss: 98857.14\n",
      "Epoch:[ 0 ] Batch: 244 / 937 Main Model Loss: 0.0650444 Interpreter Loss: 98043.78\n",
      "Epoch:[ 0 ] Batch: 245 / 937 Main Model Loss: 0.12989172 Interpreter Loss: 99136.11\n",
      "Epoch:[ 0 ] Batch: 246 / 937 Main Model Loss: 0.1909545 Interpreter Loss: 101141.29\n",
      "Epoch:[ 0 ] Batch: 247 / 937 Main Model Loss: 0.29272485 Interpreter Loss: 99394.96\n",
      "Epoch:[ 0 ] Batch: 248 / 937 Main Model Loss: 0.1588757 Interpreter Loss: 98794.61\n",
      "Epoch:[ 0 ] Batch: 249 / 937 Main Model Loss: 0.30283684 Interpreter Loss: 99046.16\n",
      "Epoch:[ 0 ] Batch: 250 / 937 Main Model Loss: 0.3672154 Interpreter Loss: 100666.7\n",
      "Epoch:[ 0 ] Batch: 251 / 937 Main Model Loss: 0.054410882 Interpreter Loss: 98259.516\n",
      "Epoch:[ 0 ] Batch: 252 / 937 Main Model Loss: 0.060488578 Interpreter Loss: 97347.76\n",
      "Epoch:[ 0 ] Batch: 253 / 937 Main Model Loss: 0.09690409 Interpreter Loss: 97133.01\n",
      "Epoch:[ 0 ] Batch: 254 / 937 Main Model Loss: 0.046989735 Interpreter Loss: 97748.625\n",
      "Epoch:[ 0 ] Batch: 255 / 937 Main Model Loss: 0.14391848 Interpreter Loss: 97268.195\n",
      "Epoch:[ 0 ] Batch: 256 / 937 Main Model Loss: 0.10209312 Interpreter Loss: 97667.11\n",
      "Epoch:[ 0 ] Batch: 257 / 937 Main Model Loss: 0.17182586 Interpreter Loss: 97385.41\n",
      "Epoch:[ 0 ] Batch: 258 / 937 Main Model Loss: 0.18650085 Interpreter Loss: 97117.19\n",
      "Epoch:[ 0 ] Batch: 259 / 937 Main Model Loss: 0.056311104 Interpreter Loss: 97486.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 0 ] Batch: 260 / 937 Main Model Loss: 0.2476624 Interpreter Loss: 98562.95\n",
      "Epoch:[ 0 ] Batch: 261 / 937 Main Model Loss: 0.30956545 Interpreter Loss: 97261.44\n",
      "Epoch:[ 0 ] Batch: 262 / 937 Main Model Loss: 0.11463369 Interpreter Loss: 99054.22\n",
      "Epoch:[ 0 ] Batch: 263 / 937 Main Model Loss: 0.1862245 Interpreter Loss: 98019.06\n",
      "Epoch:[ 0 ] Batch: 264 / 937 Main Model Loss: 0.09487066 Interpreter Loss: 98001.75\n",
      "Epoch:[ 0 ] Batch: 265 / 937 Main Model Loss: 0.17920311 Interpreter Loss: 98714.41\n",
      "Epoch:[ 0 ] Batch: 266 / 937 Main Model Loss: 0.28917137 Interpreter Loss: 98251.6\n",
      "Epoch:[ 0 ] Batch: 267 / 937 Main Model Loss: 0.16119164 Interpreter Loss: 97953.625\n",
      "Epoch:[ 0 ] Batch: 268 / 937 Main Model Loss: 0.11945814 Interpreter Loss: 97024.28\n",
      "Epoch:[ 0 ] Batch: 269 / 937 Main Model Loss: 0.18361913 Interpreter Loss: 96960.54\n",
      "Epoch:[ 0 ] Batch: 270 / 937 Main Model Loss: 0.09936419 Interpreter Loss: 96932.516\n",
      "Epoch:[ 0 ] Batch: 271 / 937 Main Model Loss: 0.12616679 Interpreter Loss: 97150.805\n",
      "Epoch:[ 0 ] Batch: 272 / 937 Main Model Loss: 0.17210405 Interpreter Loss: 97053.85\n",
      "Epoch:[ 0 ] Batch: 273 / 937 Main Model Loss: 0.26313782 Interpreter Loss: 97978.75\n",
      "Epoch:[ 0 ] Batch: 274 / 937 Main Model Loss: 0.3563317 Interpreter Loss: 97558.125\n",
      "Epoch:[ 0 ] Batch: 275 / 937 Main Model Loss: 0.052085806 Interpreter Loss: 96630.91\n",
      "Epoch:[ 0 ] Batch: 276 / 937 Main Model Loss: 0.24949835 Interpreter Loss: 98019.75\n",
      "Epoch:[ 0 ] Batch: 277 / 937 Main Model Loss: 0.35185546 Interpreter Loss: 97300.83\n",
      "Epoch:[ 0 ] Batch: 278 / 937 Main Model Loss: 0.15511064 Interpreter Loss: 98527.3\n",
      "Epoch:[ 0 ] Batch: 279 / 937 Main Model Loss: 0.10054994 Interpreter Loss: 96615.34\n",
      "Epoch:[ 0 ] Batch: 280 / 937 Main Model Loss: 0.14528821 Interpreter Loss: 96734.586\n",
      "Epoch:[ 0 ] Batch: 281 / 937 Main Model Loss: 0.28230125 Interpreter Loss: 96486.24\n",
      "Epoch:[ 0 ] Batch: 282 / 937 Main Model Loss: 0.250859 Interpreter Loss: 95790.55\n",
      "Epoch:[ 0 ] Batch: 283 / 937 Main Model Loss: 0.17956546 Interpreter Loss: 95613.664\n",
      "Epoch:[ 0 ] Batch: 284 / 937 Main Model Loss: 0.058053657 Interpreter Loss: 95297.89\n",
      "Epoch:[ 0 ] Batch: 285 / 937 Main Model Loss: 0.03861875 Interpreter Loss: 95318.31\n",
      "Epoch:[ 0 ] Batch: 286 / 937 Main Model Loss: 0.19161853 Interpreter Loss: 95372.164\n",
      "Epoch:[ 0 ] Batch: 287 / 937 Main Model Loss: 0.14190389 Interpreter Loss: 96945.03\n",
      "Epoch:[ 0 ] Batch: 288 / 937 Main Model Loss: 0.17381719 Interpreter Loss: 95815.39\n",
      "Epoch:[ 0 ] Batch: 289 / 937 Main Model Loss: 0.10002877 Interpreter Loss: 95457.586\n",
      "Epoch:[ 0 ] Batch: 290 / 937 Main Model Loss: 0.16868597 Interpreter Loss: 95769.234\n",
      "Epoch:[ 0 ] Batch: 291 / 937 Main Model Loss: 0.04240136 Interpreter Loss: 96345.26\n",
      "Epoch:[ 0 ] Batch: 292 / 937 Main Model Loss: 0.1390238 Interpreter Loss: 96180.516\n",
      "Epoch:[ 0 ] Batch: 293 / 937 Main Model Loss: 0.050256394 Interpreter Loss: 95894.695\n",
      "Epoch:[ 0 ] Batch: 294 / 937 Main Model Loss: 0.09234934 Interpreter Loss: 95943.05\n",
      "Epoch:[ 0 ] Batch: 295 / 937 Main Model Loss: 0.023404425 Interpreter Loss: 94953.805\n",
      "Epoch:[ 0 ] Batch: 296 / 937 Main Model Loss: 0.056123573 Interpreter Loss: 95093.84\n",
      "Epoch:[ 0 ] Batch: 297 / 937 Main Model Loss: 0.2391807 Interpreter Loss: 95214.71\n",
      "Epoch:[ 0 ] Batch: 298 / 937 Main Model Loss: 0.27155817 Interpreter Loss: 95630.086\n",
      "Epoch:[ 0 ] Batch: 299 / 937 Main Model Loss: 0.0794193 Interpreter Loss: 95797.02\n",
      "Epoch:[ 0 ] Batch: 300 / 937 Main Model Loss: 0.16488045 Interpreter Loss: 95002.55\n",
      "Epoch:[ 0 ] Batch: 301 / 937 Main Model Loss: 0.07609148 Interpreter Loss: 95430.93\n",
      "Epoch:[ 0 ] Batch: 302 / 937 Main Model Loss: 0.30610263 Interpreter Loss: 94925.0\n",
      "Epoch:[ 0 ] Batch: 303 / 937 Main Model Loss: 0.07605446 Interpreter Loss: 94509.164\n",
      "Epoch:[ 0 ] Batch: 304 / 937 Main Model Loss: 0.08933318 Interpreter Loss: 95426.79\n",
      "Epoch:[ 0 ] Batch: 305 / 937 Main Model Loss: 0.25651088 Interpreter Loss: 95639.33\n",
      "Epoch:[ 0 ] Batch: 306 / 937 Main Model Loss: 0.04926999 Interpreter Loss: 94835.484\n",
      "Epoch:[ 0 ] Batch: 307 / 937 Main Model Loss: 0.086106755 Interpreter Loss: 93921.86\n",
      "Epoch:[ 0 ] Batch: 308 / 937 Main Model Loss: 0.103107065 Interpreter Loss: 93981.91\n",
      "Epoch:[ 0 ] Batch: 309 / 937 Main Model Loss: 0.2011221 Interpreter Loss: 95064.195\n",
      "Epoch:[ 0 ] Batch: 310 / 937 Main Model Loss: 0.13137403 Interpreter Loss: 94266.28\n",
      "Epoch:[ 0 ] Batch: 311 / 937 Main Model Loss: 0.13139182 Interpreter Loss: 94643.43\n",
      "Epoch:[ 0 ] Batch: 312 / 937 Main Model Loss: 0.114390545 Interpreter Loss: 95506.31\n",
      "Epoch:[ 0 ] Batch: 313 / 937 Main Model Loss: 0.2009442 Interpreter Loss: 94637.695\n",
      "Epoch:[ 0 ] Batch: 314 / 937 Main Model Loss: 0.112418704 Interpreter Loss: 94512.164\n",
      "Epoch:[ 0 ] Batch: 315 / 937 Main Model Loss: 0.23556824 Interpreter Loss: 96013.234\n",
      "Epoch:[ 0 ] Batch: 316 / 937 Main Model Loss: 0.110539794 Interpreter Loss: 93818.09\n",
      "Epoch:[ 0 ] Batch: 317 / 937 Main Model Loss: 0.15005895 Interpreter Loss: 93775.87\n",
      "Epoch:[ 0 ] Batch: 318 / 937 Main Model Loss: 0.03673 Interpreter Loss: 93486.55\n",
      "Epoch:[ 0 ] Batch: 319 / 937 Main Model Loss: 0.08369559 Interpreter Loss: 93436.58\n",
      "Epoch:[ 0 ] Batch: 320 / 937 Main Model Loss: 0.06712914 Interpreter Loss: 93125.26\n",
      "Epoch:[ 0 ] Batch: 321 / 937 Main Model Loss: 0.06603754 Interpreter Loss: 94136.36\n",
      "Epoch:[ 0 ] Batch: 322 / 937 Main Model Loss: 0.13613236 Interpreter Loss: 94273.69\n",
      "Epoch:[ 0 ] Batch: 323 / 937 Main Model Loss: 0.37696502 Interpreter Loss: 93366.766\n",
      "Epoch:[ 0 ] Batch: 324 / 937 Main Model Loss: 0.29947907 Interpreter Loss: 93080.39\n",
      "Epoch:[ 0 ] Batch: 325 / 937 Main Model Loss: 0.17275493 Interpreter Loss: 93632.46\n",
      "Epoch:[ 0 ] Batch: 326 / 937 Main Model Loss: 0.23012742 Interpreter Loss: 94651.12\n",
      "Epoch:[ 0 ] Batch: 327 / 937 Main Model Loss: 0.15621392 Interpreter Loss: 94378.82\n",
      "Epoch:[ 0 ] Batch: 328 / 937 Main Model Loss: 0.25958848 Interpreter Loss: 93669.38\n",
      "Epoch:[ 0 ] Batch: 329 / 937 Main Model Loss: 0.1383765 Interpreter Loss: 93820.78\n",
      "Epoch:[ 0 ] Batch: 330 / 937 Main Model Loss: 0.16296075 Interpreter Loss: 93111.0\n",
      "Epoch:[ 0 ] Batch: 331 / 937 Main Model Loss: 0.14357714 Interpreter Loss: 93464.61\n",
      "Epoch:[ 0 ] Batch: 332 / 937 Main Model Loss: 0.05607576 Interpreter Loss: 92924.56\n",
      "Epoch:[ 0 ] Batch: 333 / 937 Main Model Loss: 0.08761731 Interpreter Loss: 93802.586\n",
      "Epoch:[ 0 ] Batch: 334 / 937 Main Model Loss: 0.16736549 Interpreter Loss: 94009.08\n",
      "Epoch:[ 0 ] Batch: 335 / 937 Main Model Loss: 0.05683779 Interpreter Loss: 92825.32\n",
      "Epoch:[ 0 ] Batch: 336 / 937 Main Model Loss: 0.1386478 Interpreter Loss: 92625.77\n",
      "Epoch:[ 0 ] Batch: 337 / 937 Main Model Loss: 0.34540525 Interpreter Loss: 94960.34\n",
      "Epoch:[ 0 ] Batch: 338 / 937 Main Model Loss: 0.09137365 Interpreter Loss: 93030.36\n",
      "Epoch:[ 0 ] Batch: 339 / 937 Main Model Loss: 0.11260028 Interpreter Loss: 93305.86\n",
      "Epoch:[ 0 ] Batch: 340 / 937 Main Model Loss: 0.039180234 Interpreter Loss: 91802.87\n",
      "Epoch:[ 0 ] Batch: 341 / 937 Main Model Loss: 0.078987546 Interpreter Loss: 92453.41\n",
      "Epoch:[ 0 ] Batch: 342 / 937 Main Model Loss: 0.15556218 Interpreter Loss: 91776.86\n",
      "Epoch:[ 0 ] Batch: 343 / 937 Main Model Loss: 0.17554708 Interpreter Loss: 92150.86\n",
      "Epoch:[ 0 ] Batch: 344 / 937 Main Model Loss: 0.04747004 Interpreter Loss: 91518.67\n",
      "Epoch:[ 0 ] Batch: 345 / 937 Main Model Loss: 0.2035 Interpreter Loss: 91881.836\n",
      "Epoch:[ 0 ] Batch: 346 / 937 Main Model Loss: 0.2577031 Interpreter Loss: 92627.28\n",
      "Epoch:[ 0 ] Batch: 347 / 937 Main Model Loss: 0.13163905 Interpreter Loss: 92137.91\n",
      "Epoch:[ 0 ] Batch: 348 / 937 Main Model Loss: 0.12405545 Interpreter Loss: 91529.56\n",
      "Epoch:[ 0 ] Batch: 349 / 937 Main Model Loss: 0.030216932 Interpreter Loss: 90816.695\n",
      "Epoch:[ 0 ] Batch: 350 / 937 Main Model Loss: 0.13384512 Interpreter Loss: 91692.65\n",
      "Epoch:[ 0 ] Batch: 351 / 937 Main Model Loss: 0.31470656 Interpreter Loss: 94256.766\n",
      "Epoch:[ 0 ] Batch: 352 / 937 Main Model Loss: 0.20276922 Interpreter Loss: 94198.03\n",
      "Epoch:[ 0 ] Batch: 353 / 937 Main Model Loss: 0.18866868 Interpreter Loss: 92199.93\n",
      "Epoch:[ 0 ] Batch: 354 / 937 Main Model Loss: 0.108138815 Interpreter Loss: 92055.445\n",
      "Epoch:[ 0 ] Batch: 355 / 937 Main Model Loss: 0.108392455 Interpreter Loss: 91275.11\n",
      "Epoch:[ 0 ] Batch: 356 / 937 Main Model Loss: 0.08028371 Interpreter Loss: 92269.39\n",
      "Epoch:[ 0 ] Batch: 357 / 937 Main Model Loss: 0.12653866 Interpreter Loss: 90274.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 0 ] Batch: 358 / 937 Main Model Loss: 0.008294015 Interpreter Loss: 89830.17\n",
      "Epoch:[ 0 ] Batch: 359 / 937 Main Model Loss: 0.04996095 Interpreter Loss: 90482.01\n",
      "Epoch:[ 0 ] Batch: 360 / 937 Main Model Loss: 0.18043755 Interpreter Loss: 92179.88\n",
      "Epoch:[ 0 ] Batch: 361 / 937 Main Model Loss: 0.09682104 Interpreter Loss: 90010.69\n",
      "Epoch:[ 0 ] Batch: 362 / 937 Main Model Loss: 0.09322943 Interpreter Loss: 90193.33\n",
      "Epoch:[ 0 ] Batch: 363 / 937 Main Model Loss: 0.03539306 Interpreter Loss: 89882.59\n",
      "Epoch:[ 0 ] Batch: 364 / 937 Main Model Loss: 0.039001837 Interpreter Loss: 89654.57\n",
      "Epoch:[ 0 ] Batch: 365 / 937 Main Model Loss: 0.14632796 Interpreter Loss: 90004.86\n",
      "Epoch:[ 0 ] Batch: 366 / 937 Main Model Loss: 0.102785595 Interpreter Loss: 90987.37\n",
      "Epoch:[ 0 ] Batch: 367 / 937 Main Model Loss: 0.110848285 Interpreter Loss: 90178.94\n",
      "Epoch:[ 0 ] Batch: 368 / 937 Main Model Loss: 0.10865834 Interpreter Loss: 89428.49\n",
      "Epoch:[ 0 ] Batch: 369 / 937 Main Model Loss: 0.18531498 Interpreter Loss: 90310.77\n",
      "Epoch:[ 0 ] Batch: 370 / 937 Main Model Loss: 0.29258406 Interpreter Loss: 91195.38\n",
      "Epoch:[ 0 ] Batch: 371 / 937 Main Model Loss: 0.06639522 Interpreter Loss: 90008.55\n",
      "Epoch:[ 0 ] Batch: 372 / 937 Main Model Loss: 0.18506779 Interpreter Loss: 90083.766\n",
      "Epoch:[ 0 ] Batch: 373 / 937 Main Model Loss: 0.09729838 Interpreter Loss: 89543.36\n",
      "Epoch:[ 0 ] Batch: 374 / 937 Main Model Loss: 0.17472364 Interpreter Loss: 89772.95\n",
      "Epoch:[ 0 ] Batch: 375 / 937 Main Model Loss: 0.15658452 Interpreter Loss: 89932.16\n",
      "Epoch:[ 0 ] Batch: 376 / 937 Main Model Loss: 0.06691915 Interpreter Loss: 89516.375\n",
      "Epoch:[ 0 ] Batch: 377 / 937 Main Model Loss: 0.086585626 Interpreter Loss: 89282.64\n",
      "Epoch:[ 0 ] Batch: 378 / 937 Main Model Loss: 0.15201496 Interpreter Loss: 89415.3\n",
      "Epoch:[ 0 ] Batch: 379 / 937 Main Model Loss: 0.15846755 Interpreter Loss: 89696.68\n",
      "Epoch:[ 0 ] Batch: 380 / 937 Main Model Loss: 0.014352672 Interpreter Loss: 88119.24\n",
      "Epoch:[ 0 ] Batch: 381 / 937 Main Model Loss: 0.06630135 Interpreter Loss: 89677.12\n",
      "Epoch:[ 0 ] Batch: 382 / 937 Main Model Loss: 0.058858234 Interpreter Loss: 88843.125\n",
      "Epoch:[ 0 ] Batch: 383 / 937 Main Model Loss: 0.14171815 Interpreter Loss: 90289.37\n",
      "Epoch:[ 0 ] Batch: 384 / 937 Main Model Loss: 0.13012506 Interpreter Loss: 89861.07\n",
      "Epoch:[ 0 ] Batch: 385 / 937 Main Model Loss: 0.10822165 Interpreter Loss: 89960.65\n",
      "Epoch:[ 0 ] Batch: 386 / 937 Main Model Loss: 0.14789182 Interpreter Loss: 89214.46\n",
      "Epoch:[ 0 ] Batch: 387 / 937 Main Model Loss: 0.18727416 Interpreter Loss: 88053.35\n",
      "Epoch:[ 0 ] Batch: 388 / 937 Main Model Loss: 0.059830602 Interpreter Loss: 88021.19\n",
      "Epoch:[ 0 ] Batch: 389 / 937 Main Model Loss: 0.192676 Interpreter Loss: 88475.94\n",
      "Epoch:[ 0 ] Batch: 390 / 937 Main Model Loss: 0.053988215 Interpreter Loss: 87644.586\n",
      "Epoch:[ 0 ] Batch: 391 / 937 Main Model Loss: 0.04949604 Interpreter Loss: 87338.71\n",
      "Epoch:[ 0 ] Batch: 392 / 937 Main Model Loss: 0.14827861 Interpreter Loss: 87776.484\n",
      "Epoch:[ 0 ] Batch: 393 / 937 Main Model Loss: 0.18386215 Interpreter Loss: 87834.516\n",
      "Epoch:[ 0 ] Batch: 394 / 937 Main Model Loss: 0.11348807 Interpreter Loss: 87138.39\n",
      "Epoch:[ 0 ] Batch: 395 / 937 Main Model Loss: 0.07884757 Interpreter Loss: 87919.28\n",
      "Epoch:[ 0 ] Batch: 396 / 937 Main Model Loss: 0.10430321 Interpreter Loss: 87214.31\n",
      "Epoch:[ 0 ] Batch: 397 / 937 Main Model Loss: 0.01853054 Interpreter Loss: 86577.42\n",
      "Epoch:[ 0 ] Batch: 398 / 937 Main Model Loss: 0.1111392 Interpreter Loss: 86542.08\n",
      "Epoch:[ 0 ] Batch: 399 / 937 Main Model Loss: 0.21828732 Interpreter Loss: 86289.72\n",
      "Epoch:[ 0 ] Batch: 400 / 937 Main Model Loss: 0.07184326 Interpreter Loss: 87418.83\n",
      "Epoch:[ 0 ] Batch: 401 / 937 Main Model Loss: 0.21020772 Interpreter Loss: 86700.76\n",
      "Epoch:[ 0 ] Batch: 402 / 937 Main Model Loss: 0.06707806 Interpreter Loss: 86674.3\n",
      "Epoch:[ 0 ] Batch: 403 / 937 Main Model Loss: 0.239549 Interpreter Loss: 86836.56\n",
      "Epoch:[ 0 ] Batch: 404 / 937 Main Model Loss: 0.06780834 Interpreter Loss: 86434.83\n",
      "Epoch:[ 0 ] Batch: 405 / 937 Main Model Loss: 0.20929965 Interpreter Loss: 87033.52\n",
      "Epoch:[ 0 ] Batch: 406 / 937 Main Model Loss: 0.11336137 Interpreter Loss: 87077.65\n",
      "Epoch:[ 0 ] Batch: 407 / 937 Main Model Loss: 0.087780915 Interpreter Loss: 86627.32\n",
      "Epoch:[ 0 ] Batch: 408 / 937 Main Model Loss: 0.062319856 Interpreter Loss: 86196.25\n",
      "Epoch:[ 0 ] Batch: 409 / 937 Main Model Loss: 0.09390645 Interpreter Loss: 85736.61\n",
      "Epoch:[ 0 ] Batch: 410 / 937 Main Model Loss: 0.10499434 Interpreter Loss: 86001.8\n",
      "Epoch:[ 0 ] Batch: 411 / 937 Main Model Loss: 0.13730882 Interpreter Loss: 85347.086\n",
      "Epoch:[ 0 ] Batch: 412 / 937 Main Model Loss: 0.33517152 Interpreter Loss: 87592.41\n",
      "Epoch:[ 0 ] Batch: 413 / 937 Main Model Loss: 0.06404032 Interpreter Loss: 85701.45\n",
      "Epoch:[ 0 ] Batch: 414 / 937 Main Model Loss: 0.18092127 Interpreter Loss: 85968.16\n",
      "Epoch:[ 0 ] Batch: 415 / 937 Main Model Loss: 0.20795974 Interpreter Loss: 85799.35\n",
      "Epoch:[ 0 ] Batch: 416 / 937 Main Model Loss: 0.41583893 Interpreter Loss: 85502.88\n",
      "Epoch:[ 0 ] Batch: 417 / 937 Main Model Loss: 0.3297764 Interpreter Loss: 86308.695\n",
      "Epoch:[ 0 ] Batch: 418 / 937 Main Model Loss: 0.095141314 Interpreter Loss: 85303.086\n",
      "Epoch:[ 0 ] Batch: 419 / 937 Main Model Loss: 0.30926794 Interpreter Loss: 85802.99\n",
      "Epoch:[ 0 ] Batch: 420 / 937 Main Model Loss: 0.34323096 Interpreter Loss: 84284.1\n",
      "Epoch:[ 0 ] Batch: 421 / 937 Main Model Loss: 0.01235151 Interpreter Loss: 83590.47\n",
      "Epoch:[ 0 ] Batch: 422 / 937 Main Model Loss: 0.018384703 Interpreter Loss: 83620.34\n",
      "Epoch:[ 0 ] Batch: 423 / 937 Main Model Loss: 0.17552716 Interpreter Loss: 85235.22\n",
      "Epoch:[ 0 ] Batch: 424 / 937 Main Model Loss: 0.37035102 Interpreter Loss: 87313.664\n",
      "Epoch:[ 0 ] Batch: 425 / 937 Main Model Loss: 0.15251982 Interpreter Loss: 85164.3\n",
      "Epoch:[ 0 ] Batch: 426 / 937 Main Model Loss: 0.039505914 Interpreter Loss: 84125.83\n",
      "Epoch:[ 0 ] Batch: 427 / 937 Main Model Loss: 0.024962721 Interpreter Loss: 83075.75\n",
      "Epoch:[ 0 ] Batch: 428 / 937 Main Model Loss: 0.05973042 Interpreter Loss: 84194.64\n",
      "Epoch:[ 0 ] Batch: 429 / 937 Main Model Loss: 0.13048735 Interpreter Loss: 83429.445\n",
      "Epoch:[ 0 ] Batch: 430 / 937 Main Model Loss: 0.09463428 Interpreter Loss: 83140.72\n",
      "Epoch:[ 0 ] Batch: 431 / 937 Main Model Loss: 0.07883262 Interpreter Loss: 83755.34\n",
      "Epoch:[ 0 ] Batch: 432 / 937 Main Model Loss: 0.110587716 Interpreter Loss: 83783.8\n",
      "Epoch:[ 0 ] Batch: 433 / 937 Main Model Loss: 0.03682727 Interpreter Loss: 83172.22\n",
      "Epoch:[ 0 ] Batch: 434 / 937 Main Model Loss: 0.08822074 Interpreter Loss: 83567.375\n",
      "Epoch:[ 0 ] Batch: 435 / 937 Main Model Loss: 0.21052833 Interpreter Loss: 84120.69\n",
      "Epoch:[ 0 ] Batch: 436 / 937 Main Model Loss: 0.057698973 Interpreter Loss: 82744.72\n",
      "Epoch:[ 0 ] Batch: 437 / 937 Main Model Loss: 0.08882996 Interpreter Loss: 82891.02\n",
      "Epoch:[ 0 ] Batch: 438 / 937 Main Model Loss: 0.04221638 Interpreter Loss: 82288.64\n",
      "Epoch:[ 0 ] Batch: 439 / 937 Main Model Loss: 0.17333573 Interpreter Loss: 82551.96\n",
      "Epoch:[ 0 ] Batch: 440 / 937 Main Model Loss: 0.09813571 Interpreter Loss: 82515.39\n",
      "Epoch:[ 0 ] Batch: 441 / 937 Main Model Loss: 0.038342103 Interpreter Loss: 81713.06\n",
      "Epoch:[ 0 ] Batch: 442 / 937 Main Model Loss: 0.017407246 Interpreter Loss: 81148.27\n",
      "Epoch:[ 0 ] Batch: 443 / 937 Main Model Loss: 0.2676552 Interpreter Loss: 83030.914\n",
      "Epoch:[ 0 ] Batch: 444 / 937 Main Model Loss: 0.036047444 Interpreter Loss: 81184.234\n",
      "Epoch:[ 0 ] Batch: 445 / 937 Main Model Loss: 0.066878185 Interpreter Loss: 81177.73\n",
      "Epoch:[ 0 ] Batch: 446 / 937 Main Model Loss: 0.09828854 Interpreter Loss: 81058.78\n",
      "Epoch:[ 0 ] Batch: 447 / 937 Main Model Loss: 0.31065866 Interpreter Loss: 82682.67\n",
      "Epoch:[ 0 ] Batch: 448 / 937 Main Model Loss: 0.19058232 Interpreter Loss: 81695.234\n",
      "Epoch:[ 0 ] Batch: 449 / 937 Main Model Loss: 0.14762801 Interpreter Loss: 80945.55\n",
      "Epoch:[ 0 ] Batch: 450 / 937 Main Model Loss: 0.04941973 Interpreter Loss: 80996.25\n",
      "Epoch:[ 0 ] Batch: 451 / 937 Main Model Loss: 0.01514766 Interpreter Loss: 79863.69\n",
      "Epoch:[ 0 ] Batch: 452 / 937 Main Model Loss: 0.18338214 Interpreter Loss: 81389.28\n",
      "Epoch:[ 0 ] Batch: 453 / 937 Main Model Loss: 0.02652455 Interpreter Loss: 80020.92\n",
      "Epoch:[ 0 ] Batch: 454 / 937 Main Model Loss: 0.064480305 Interpreter Loss: 80368.234\n",
      "Epoch:[ 0 ] Batch: 455 / 937 Main Model Loss: 0.2031526 Interpreter Loss: 81553.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 0 ] Batch: 456 / 937 Main Model Loss: 0.16091101 Interpreter Loss: 80980.01\n",
      "Epoch:[ 0 ] Batch: 457 / 937 Main Model Loss: 0.14287895 Interpreter Loss: 80861.16\n",
      "Epoch:[ 0 ] Batch: 458 / 937 Main Model Loss: 0.10983405 Interpreter Loss: 80883.99\n",
      "Epoch:[ 0 ] Batch: 459 / 937 Main Model Loss: 0.12009959 Interpreter Loss: 79335.125\n",
      "Epoch:[ 0 ] Batch: 460 / 937 Main Model Loss: 0.1304654 Interpreter Loss: 79766.81\n",
      "Epoch:[ 0 ] Batch: 461 / 937 Main Model Loss: 0.027146185 Interpreter Loss: 78336.37\n",
      "Epoch:[ 0 ] Batch: 462 / 937 Main Model Loss: 0.039618775 Interpreter Loss: 79310.22\n",
      "Epoch:[ 0 ] Batch: 463 / 937 Main Model Loss: 0.06577433 Interpreter Loss: 78633.81\n",
      "Epoch:[ 0 ] Batch: 464 / 937 Main Model Loss: 0.17158504 Interpreter Loss: 80189.05\n",
      "Epoch:[ 0 ] Batch: 465 / 937 Main Model Loss: 0.043651924 Interpreter Loss: 78943.92\n",
      "Epoch:[ 0 ] Batch: 466 / 937 Main Model Loss: 0.1617911 Interpreter Loss: 80502.805\n",
      "Epoch:[ 0 ] Batch: 467 / 937 Main Model Loss: 0.11259237 Interpreter Loss: 79789.984\n",
      "Epoch:[ 0 ] Batch: 468 / 937 Main Model Loss: 0.16421483 Interpreter Loss: 79455.336\n",
      "Epoch:[ 0 ] Batch: 469 / 937 Main Model Loss: 0.28170916 Interpreter Loss: 78765.625\n",
      "Epoch:[ 0 ] Batch: 470 / 937 Main Model Loss: 0.11314197 Interpreter Loss: 78861.914\n",
      "Epoch:[ 0 ] Batch: 471 / 937 Main Model Loss: 0.11924976 Interpreter Loss: 80147.38\n",
      "Epoch:[ 0 ] Batch: 472 / 937 Main Model Loss: 0.026910735 Interpreter Loss: 78002.164\n",
      "Epoch:[ 0 ] Batch: 473 / 937 Main Model Loss: 0.09115123 Interpreter Loss: 77125.8\n",
      "Epoch:[ 0 ] Batch: 474 / 937 Main Model Loss: 0.023230353 Interpreter Loss: 76928.62\n",
      "Epoch:[ 0 ] Batch: 475 / 937 Main Model Loss: 0.035202 Interpreter Loss: 78471.67\n",
      "Epoch:[ 0 ] Batch: 476 / 937 Main Model Loss: 0.18083583 Interpreter Loss: 79191.3\n",
      "Epoch:[ 0 ] Batch: 477 / 937 Main Model Loss: 0.109330274 Interpreter Loss: 77146.4\n",
      "Epoch:[ 0 ] Batch: 478 / 937 Main Model Loss: 0.13694504 Interpreter Loss: 77567.695\n",
      "Epoch:[ 0 ] Batch: 479 / 937 Main Model Loss: 0.06652759 Interpreter Loss: 77426.61\n",
      "Epoch:[ 0 ] Batch: 480 / 937 Main Model Loss: 0.069190815 Interpreter Loss: 77735.25\n",
      "Epoch:[ 0 ] Batch: 481 / 937 Main Model Loss: 0.08389907 Interpreter Loss: 76878.87\n",
      "Epoch:[ 0 ] Batch: 482 / 937 Main Model Loss: 0.12662427 Interpreter Loss: 77333.7\n",
      "Epoch:[ 0 ] Batch: 483 / 937 Main Model Loss: 0.12113887 Interpreter Loss: 76340.35\n",
      "Epoch:[ 0 ] Batch: 484 / 937 Main Model Loss: 0.018289635 Interpreter Loss: 76787.97\n",
      "Epoch:[ 0 ] Batch: 485 / 937 Main Model Loss: 0.086426705 Interpreter Loss: 76159.11\n",
      "Epoch:[ 0 ] Batch: 486 / 937 Main Model Loss: 0.11190492 Interpreter Loss: 75176.91\n",
      "Epoch:[ 0 ] Batch: 487 / 937 Main Model Loss: 0.21037154 Interpreter Loss: 75731.56\n",
      "Epoch:[ 0 ] Batch: 488 / 937 Main Model Loss: 0.09884798 Interpreter Loss: 76275.66\n",
      "Epoch:[ 0 ] Batch: 489 / 937 Main Model Loss: 0.29175162 Interpreter Loss: 76279.51\n",
      "Epoch:[ 0 ] Batch: 490 / 937 Main Model Loss: 0.18139601 Interpreter Loss: 76314.766\n",
      "Epoch:[ 0 ] Batch: 491 / 937 Main Model Loss: 0.12229031 Interpreter Loss: 76420.266\n",
      "Epoch:[ 0 ] Batch: 492 / 937 Main Model Loss: 0.08712068 Interpreter Loss: 74778.96\n",
      "Epoch:[ 0 ] Batch: 493 / 937 Main Model Loss: 0.16988623 Interpreter Loss: 75140.15\n",
      "Epoch:[ 0 ] Batch: 494 / 937 Main Model Loss: 0.23143084 Interpreter Loss: 75223.81\n",
      "Epoch:[ 0 ] Batch: 495 / 937 Main Model Loss: 0.32363367 Interpreter Loss: 75587.6\n",
      "Epoch:[ 0 ] Batch: 496 / 937 Main Model Loss: 0.1869034 Interpreter Loss: 75125.34\n",
      "Epoch:[ 0 ] Batch: 497 / 937 Main Model Loss: 0.12803684 Interpreter Loss: 75364.53\n",
      "Epoch:[ 0 ] Batch: 498 / 937 Main Model Loss: 0.026063891 Interpreter Loss: 73618.13\n",
      "Epoch:[ 0 ] Batch: 499 / 937 Main Model Loss: 0.164594 Interpreter Loss: 74429.65\n",
      "Epoch:[ 0 ] Batch: 500 / 937 Main Model Loss: 0.3464306 Interpreter Loss: 74716.76\n",
      "Epoch:[ 0 ] Batch: 501 / 937 Main Model Loss: 0.18635395 Interpreter Loss: 74283.9\n",
      "Epoch:[ 0 ] Batch: 502 / 937 Main Model Loss: 0.12294647 Interpreter Loss: 75302.08\n",
      "Epoch:[ 0 ] Batch: 503 / 937 Main Model Loss: 0.06543877 Interpreter Loss: 74037.38\n",
      "Epoch:[ 0 ] Batch: 504 / 937 Main Model Loss: 0.16163212 Interpreter Loss: 73228.875\n",
      "Epoch:[ 0 ] Batch: 505 / 937 Main Model Loss: 0.23098832 Interpreter Loss: 74767.84\n",
      "Epoch:[ 0 ] Batch: 506 / 937 Main Model Loss: 0.24143207 Interpreter Loss: 74831.17\n",
      "Epoch:[ 0 ] Batch: 507 / 937 Main Model Loss: 0.16040571 Interpreter Loss: 73950.05\n",
      "Epoch:[ 0 ] Batch: 508 / 937 Main Model Loss: 0.11292337 Interpreter Loss: 72557.39\n",
      "Epoch:[ 0 ] Batch: 509 / 937 Main Model Loss: 0.017719215 Interpreter Loss: 71731.09\n",
      "Epoch:[ 0 ] Batch: 510 / 937 Main Model Loss: 0.09373686 Interpreter Loss: 72914.67\n",
      "Epoch:[ 0 ] Batch: 511 / 937 Main Model Loss: 0.1320824 Interpreter Loss: 71852.62\n",
      "Epoch:[ 0 ] Batch: 512 / 937 Main Model Loss: 0.20656775 Interpreter Loss: 73480.14\n",
      "Epoch:[ 0 ] Batch: 513 / 937 Main Model Loss: 0.11920966 Interpreter Loss: 71911.16\n",
      "Epoch:[ 0 ] Batch: 514 / 937 Main Model Loss: 0.11767976 Interpreter Loss: 72277.805\n",
      "Epoch:[ 0 ] Batch: 515 / 937 Main Model Loss: 0.014492148 Interpreter Loss: 70638.66\n",
      "Epoch:[ 0 ] Batch: 516 / 937 Main Model Loss: 0.1262603 Interpreter Loss: 71044.55\n",
      "Epoch:[ 0 ] Batch: 517 / 937 Main Model Loss: 0.05593635 Interpreter Loss: 71284.43\n",
      "Epoch:[ 0 ] Batch: 518 / 937 Main Model Loss: 0.07724931 Interpreter Loss: 71474.51\n",
      "Epoch:[ 0 ] Batch: 519 / 937 Main Model Loss: 0.11841288 Interpreter Loss: 70957.87\n",
      "Epoch:[ 0 ] Batch: 520 / 937 Main Model Loss: 0.21164611 Interpreter Loss: 71981.62\n",
      "Epoch:[ 0 ] Batch: 521 / 937 Main Model Loss: 0.20191634 Interpreter Loss: 72100.71\n",
      "Epoch:[ 0 ] Batch: 522 / 937 Main Model Loss: 0.13816197 Interpreter Loss: 71045.766\n",
      "Epoch:[ 0 ] Batch: 523 / 937 Main Model Loss: 0.09541447 Interpreter Loss: 70191.47\n",
      "Epoch:[ 0 ] Batch: 524 / 937 Main Model Loss: 0.06834291 Interpreter Loss: 70051.3\n",
      "Epoch:[ 0 ] Batch: 525 / 937 Main Model Loss: 0.13038214 Interpreter Loss: 70319.86\n",
      "Epoch:[ 0 ] Batch: 526 / 937 Main Model Loss: 0.062952906 Interpreter Loss: 69580.62\n",
      "Epoch:[ 0 ] Batch: 527 / 937 Main Model Loss: 0.15231426 Interpreter Loss: 69732.086\n",
      "Epoch:[ 0 ] Batch: 528 / 937 Main Model Loss: 0.022810604 Interpreter Loss: 69527.484\n",
      "Epoch:[ 0 ] Batch: 529 / 937 Main Model Loss: 0.030320816 Interpreter Loss: 68899.56\n",
      "Epoch:[ 0 ] Batch: 530 / 937 Main Model Loss: 0.047769345 Interpreter Loss: 68230.22\n",
      "Epoch:[ 0 ] Batch: 531 / 937 Main Model Loss: 0.087668896 Interpreter Loss: 68060.45\n",
      "Epoch:[ 0 ] Batch: 532 / 937 Main Model Loss: 0.19938724 Interpreter Loss: 69042.766\n",
      "Epoch:[ 0 ] Batch: 533 / 937 Main Model Loss: 0.09158575 Interpreter Loss: 68126.016\n",
      "Epoch:[ 0 ] Batch: 534 / 937 Main Model Loss: 0.05676642 Interpreter Loss: 68071.15\n",
      "Epoch:[ 0 ] Batch: 535 / 937 Main Model Loss: 0.030622263 Interpreter Loss: 67597.625\n",
      "Epoch:[ 0 ] Batch: 536 / 937 Main Model Loss: 0.11503674 Interpreter Loss: 68499.734\n",
      "Epoch:[ 0 ] Batch: 537 / 937 Main Model Loss: 0.2644282 Interpreter Loss: 68583.945\n",
      "Epoch:[ 0 ] Batch: 538 / 937 Main Model Loss: 0.05818207 Interpreter Loss: 69047.56\n",
      "Epoch:[ 0 ] Batch: 539 / 937 Main Model Loss: 0.20066163 Interpreter Loss: 67960.555\n",
      "Epoch:[ 0 ] Batch: 540 / 937 Main Model Loss: 0.059877172 Interpreter Loss: 67772.44\n",
      "Epoch:[ 0 ] Batch: 541 / 937 Main Model Loss: 0.40480772 Interpreter Loss: 67969.89\n",
      "Epoch:[ 0 ] Batch: 542 / 937 Main Model Loss: 0.23283485 Interpreter Loss: 68401.45\n",
      "Epoch:[ 0 ] Batch: 543 / 937 Main Model Loss: 0.14683096 Interpreter Loss: 67519.12\n",
      "Epoch:[ 0 ] Batch: 544 / 937 Main Model Loss: 0.20344353 Interpreter Loss: 68765.07\n",
      "Epoch:[ 0 ] Batch: 545 / 937 Main Model Loss: 0.20672095 Interpreter Loss: 67768.984\n",
      "Epoch:[ 0 ] Batch: 546 / 937 Main Model Loss: 0.038110167 Interpreter Loss: 66218.14\n",
      "Epoch:[ 0 ] Batch: 547 / 937 Main Model Loss: 0.15346684 Interpreter Loss: 67286.3\n",
      "Epoch:[ 0 ] Batch: 548 / 937 Main Model Loss: 0.039735243 Interpreter Loss: 66549.06\n",
      "Epoch:[ 0 ] Batch: 549 / 937 Main Model Loss: 0.12827453 Interpreter Loss: 66097.11\n",
      "Epoch:[ 0 ] Batch: 550 / 937 Main Model Loss: 0.23576286 Interpreter Loss: 66092.44\n",
      "Epoch:[ 0 ] Batch: 551 / 937 Main Model Loss: 0.12361589 Interpreter Loss: 65929.35\n",
      "Epoch:[ 0 ] Batch: 552 / 937 Main Model Loss: 0.041044846 Interpreter Loss: 65670.95\n",
      "Epoch:[ 0 ] Batch: 553 / 937 Main Model Loss: 0.06518209 Interpreter Loss: 66401.47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 0 ] Batch: 554 / 937 Main Model Loss: 0.24573621 Interpreter Loss: 65565.95\n",
      "Epoch:[ 0 ] Batch: 555 / 937 Main Model Loss: 0.059526198 Interpreter Loss: 64997.63\n",
      "Epoch:[ 0 ] Batch: 556 / 937 Main Model Loss: 0.099933326 Interpreter Loss: 65326.14\n",
      "Epoch:[ 0 ] Batch: 557 / 937 Main Model Loss: 0.123946145 Interpreter Loss: 65317.805\n",
      "Epoch:[ 0 ] Batch: 558 / 937 Main Model Loss: 0.030028284 Interpreter Loss: 64927.74\n",
      "Epoch:[ 0 ] Batch: 559 / 937 Main Model Loss: 0.022581505 Interpreter Loss: 64034.28\n",
      "Epoch:[ 0 ] Batch: 560 / 937 Main Model Loss: 0.09613941 Interpreter Loss: 64201.21\n",
      "Epoch:[ 0 ] Batch: 561 / 937 Main Model Loss: 0.124918096 Interpreter Loss: 64777.72\n",
      "Epoch:[ 0 ] Batch: 562 / 937 Main Model Loss: 0.08217356 Interpreter Loss: 64726.812\n",
      "Epoch:[ 0 ] Batch: 563 / 937 Main Model Loss: 0.16591948 Interpreter Loss: 64480.15\n",
      "Epoch:[ 0 ] Batch: 564 / 937 Main Model Loss: 0.13879064 Interpreter Loss: 64133.477\n",
      "Epoch:[ 0 ] Batch: 565 / 937 Main Model Loss: 0.11912545 Interpreter Loss: 64228.855\n",
      "Epoch:[ 0 ] Batch: 566 / 937 Main Model Loss: 0.073238626 Interpreter Loss: 64531.953\n",
      "Epoch:[ 0 ] Batch: 567 / 937 Main Model Loss: 0.02326481 Interpreter Loss: 63376.457\n",
      "Epoch:[ 0 ] Batch: 568 / 937 Main Model Loss: 0.09910278 Interpreter Loss: 63215.758\n",
      "Epoch:[ 0 ] Batch: 569 / 937 Main Model Loss: 0.17345029 Interpreter Loss: 63661.266\n",
      "Epoch:[ 0 ] Batch: 570 / 937 Main Model Loss: 0.03300474 Interpreter Loss: 62878.82\n",
      "Epoch:[ 0 ] Batch: 571 / 937 Main Model Loss: 0.096659005 Interpreter Loss: 63936.38\n",
      "Epoch:[ 0 ] Batch: 572 / 937 Main Model Loss: 0.061998222 Interpreter Loss: 62833.523\n",
      "Epoch:[ 0 ] Batch: 573 / 937 Main Model Loss: 0.1392876 Interpreter Loss: 63141.816\n",
      "Epoch:[ 0 ] Batch: 574 / 937 Main Model Loss: 0.20205006 Interpreter Loss: 63357.016\n",
      "Epoch:[ 0 ] Batch: 575 / 937 Main Model Loss: 0.09772582 Interpreter Loss: 63831.254\n",
      "Epoch:[ 0 ] Batch: 576 / 937 Main Model Loss: 0.07182261 Interpreter Loss: 63573.676\n",
      "Epoch:[ 0 ] Batch: 577 / 937 Main Model Loss: 0.098036185 Interpreter Loss: 61513.363\n",
      "Epoch:[ 0 ] Batch: 578 / 937 Main Model Loss: 0.29197016 Interpreter Loss: 61714.83\n",
      "Epoch:[ 0 ] Batch: 579 / 937 Main Model Loss: 0.12575161 Interpreter Loss: 62763.297\n",
      "Epoch:[ 0 ] Batch: 580 / 937 Main Model Loss: 0.14494443 Interpreter Loss: 63067.535\n",
      "Epoch:[ 0 ] Batch: 581 / 937 Main Model Loss: 0.032957815 Interpreter Loss: 62290.867\n",
      "Epoch:[ 0 ] Batch: 582 / 937 Main Model Loss: 0.20108193 Interpreter Loss: 61737.5\n",
      "Epoch:[ 0 ] Batch: 583 / 937 Main Model Loss: 0.30357242 Interpreter Loss: 62800.57\n",
      "Epoch:[ 0 ] Batch: 584 / 937 Main Model Loss: 0.3433486 Interpreter Loss: 61200.965\n",
      "Epoch:[ 0 ] Batch: 585 / 937 Main Model Loss: 0.32472032 Interpreter Loss: 62294.223\n",
      "Epoch:[ 0 ] Batch: 586 / 937 Main Model Loss: 0.10018815 Interpreter Loss: 61437.793\n",
      "Epoch:[ 0 ] Batch: 587 / 937 Main Model Loss: 0.04828941 Interpreter Loss: 60743.406\n",
      "Epoch:[ 0 ] Batch: 588 / 937 Main Model Loss: 0.09589648 Interpreter Loss: 60508.664\n",
      "Epoch:[ 0 ] Batch: 589 / 937 Main Model Loss: 0.19865853 Interpreter Loss: 61182.54\n",
      "Epoch:[ 0 ] Batch: 590 / 937 Main Model Loss: 0.15989539 Interpreter Loss: 60328.688\n",
      "Epoch:[ 0 ] Batch: 591 / 937 Main Model Loss: 0.17673546 Interpreter Loss: 59679.79\n",
      "Epoch:[ 0 ] Batch: 592 / 937 Main Model Loss: 0.057061914 Interpreter Loss: 60001.613\n",
      "Epoch:[ 0 ] Batch: 593 / 937 Main Model Loss: 0.04684291 Interpreter Loss: 59541.69\n",
      "Epoch:[ 0 ] Batch: 594 / 937 Main Model Loss: 0.090735376 Interpreter Loss: 59249.805\n",
      "Epoch:[ 0 ] Batch: 595 / 937 Main Model Loss: 0.025988577 Interpreter Loss: 59359.773\n",
      "Epoch:[ 0 ] Batch: 596 / 937 Main Model Loss: 0.025465 Interpreter Loss: 58664.816\n",
      "Epoch:[ 0 ] Batch: 597 / 937 Main Model Loss: 0.0730126 Interpreter Loss: 60361.867\n",
      "Epoch:[ 0 ] Batch: 598 / 937 Main Model Loss: 0.107638165 Interpreter Loss: 59792.03\n",
      "Epoch:[ 0 ] Batch: 599 / 937 Main Model Loss: 0.105673805 Interpreter Loss: 59592.05\n",
      "Epoch:[ 0 ] Batch: 600 / 937 Main Model Loss: 0.15106142 Interpreter Loss: 58744.93\n",
      "Epoch:[ 0 ] Batch: 601 / 937 Main Model Loss: 0.10264723 Interpreter Loss: 58028.906\n",
      "Epoch:[ 0 ] Batch: 602 / 937 Main Model Loss: 0.06630339 Interpreter Loss: 58380.207\n",
      "Epoch:[ 0 ] Batch: 603 / 937 Main Model Loss: 0.21377128 Interpreter Loss: 60019.254\n",
      "Epoch:[ 0 ] Batch: 604 / 937 Main Model Loss: 0.17604885 Interpreter Loss: 58449.69\n",
      "Epoch:[ 0 ] Batch: 605 / 937 Main Model Loss: 0.13148032 Interpreter Loss: 57696.242\n",
      "Epoch:[ 0 ] Batch: 606 / 937 Main Model Loss: 0.015246335 Interpreter Loss: 56877.902\n",
      "Epoch:[ 0 ] Batch: 607 / 937 Main Model Loss: 0.03802847 Interpreter Loss: 57053.777\n",
      "Epoch:[ 0 ] Batch: 608 / 937 Main Model Loss: 0.10567341 Interpreter Loss: 57477.098\n",
      "Epoch:[ 0 ] Batch: 609 / 937 Main Model Loss: 0.14420669 Interpreter Loss: 56711.117\n",
      "Epoch:[ 0 ] Batch: 610 / 937 Main Model Loss: 0.016914276 Interpreter Loss: 56856.906\n",
      "Epoch:[ 0 ] Batch: 611 / 937 Main Model Loss: 0.026119133 Interpreter Loss: 58280.8\n",
      "Epoch:[ 0 ] Batch: 612 / 937 Main Model Loss: 0.1779637 Interpreter Loss: 57105.523\n",
      "Epoch:[ 0 ] Batch: 613 / 937 Main Model Loss: 0.118343115 Interpreter Loss: 58063.746\n",
      "Epoch:[ 0 ] Batch: 614 / 937 Main Model Loss: 0.21148565 Interpreter Loss: 58653.227\n",
      "Epoch:[ 0 ] Batch: 615 / 937 Main Model Loss: 0.26380736 Interpreter Loss: 57939.535\n",
      "Epoch:[ 0 ] Batch: 616 / 937 Main Model Loss: 0.15499526 Interpreter Loss: 57644.7\n",
      "Epoch:[ 0 ] Batch: 617 / 937 Main Model Loss: 0.04288025 Interpreter Loss: 56744.098\n",
      "Epoch:[ 0 ] Batch: 618 / 937 Main Model Loss: 0.0543815 Interpreter Loss: 56623.26\n",
      "Epoch:[ 0 ] Batch: 619 / 937 Main Model Loss: 0.20617129 Interpreter Loss: 56136.97\n",
      "Epoch:[ 0 ] Batch: 620 / 937 Main Model Loss: 0.11192342 Interpreter Loss: 55193.43\n",
      "Epoch:[ 0 ] Batch: 621 / 937 Main Model Loss: 0.17989278 Interpreter Loss: 55294.17\n",
      "Epoch:[ 0 ] Batch: 622 / 937 Main Model Loss: 0.10915517 Interpreter Loss: 55445.18\n",
      "Epoch:[ 0 ] Batch: 623 / 937 Main Model Loss: 0.031852543 Interpreter Loss: 54975.883\n",
      "Epoch:[ 0 ] Batch: 624 / 937 Main Model Loss: 0.115798056 Interpreter Loss: 56667.348\n",
      "Epoch:[ 0 ] Batch: 625 / 937 Main Model Loss: 0.06327696 Interpreter Loss: 55290.727\n",
      "Epoch:[ 0 ] Batch: 626 / 937 Main Model Loss: 0.121317156 Interpreter Loss: 55167.176\n",
      "Epoch:[ 0 ] Batch: 627 / 937 Main Model Loss: 0.090406165 Interpreter Loss: 54937.094\n",
      "Epoch:[ 0 ] Batch: 628 / 937 Main Model Loss: 0.06258365 Interpreter Loss: 54414.84\n",
      "Epoch:[ 0 ] Batch: 629 / 937 Main Model Loss: 0.10058251 Interpreter Loss: 55054.574\n",
      "Epoch:[ 0 ] Batch: 630 / 937 Main Model Loss: 0.1684203 Interpreter Loss: 53934.06\n",
      "Epoch:[ 0 ] Batch: 631 / 937 Main Model Loss: 0.13622203 Interpreter Loss: 53882.203\n",
      "Epoch:[ 0 ] Batch: 632 / 937 Main Model Loss: 0.08709292 Interpreter Loss: 54317.562\n",
      "Epoch:[ 0 ] Batch: 633 / 937 Main Model Loss: 0.09999305 Interpreter Loss: 54546.44\n",
      "Epoch:[ 0 ] Batch: 634 / 937 Main Model Loss: 0.12083174 Interpreter Loss: 53786.39\n",
      "Epoch:[ 0 ] Batch: 635 / 937 Main Model Loss: 0.0771314 Interpreter Loss: 54216.887\n",
      "Epoch:[ 0 ] Batch: 636 / 937 Main Model Loss: 0.111761674 Interpreter Loss: 53547.19\n",
      "Epoch:[ 0 ] Batch: 637 / 937 Main Model Loss: 0.04897949 Interpreter Loss: 52902.945\n",
      "Epoch:[ 0 ] Batch: 638 / 937 Main Model Loss: 0.082806736 Interpreter Loss: 53450.68\n",
      "Epoch:[ 0 ] Batch: 639 / 937 Main Model Loss: 0.0761731 Interpreter Loss: 52097.49\n",
      "Epoch:[ 0 ] Batch: 640 / 937 Main Model Loss: 0.18170103 Interpreter Loss: 53388.605\n",
      "Epoch:[ 0 ] Batch: 641 / 937 Main Model Loss: 0.06093913 Interpreter Loss: 52804.2\n",
      "Epoch:[ 0 ] Batch: 642 / 937 Main Model Loss: 0.024794543 Interpreter Loss: 52421.67\n",
      "Epoch:[ 0 ] Batch: 643 / 937 Main Model Loss: 0.07234967 Interpreter Loss: 53366.73\n",
      "Epoch:[ 0 ] Batch: 644 / 937 Main Model Loss: 0.15486485 Interpreter Loss: 52609.617\n",
      "Epoch:[ 0 ] Batch: 645 / 937 Main Model Loss: 0.39055005 Interpreter Loss: 54033.062\n",
      "Epoch:[ 0 ] Batch: 646 / 937 Main Model Loss: 0.1392492 Interpreter Loss: 53282.867\n",
      "Epoch:[ 0 ] Batch: 647 / 937 Main Model Loss: 0.19537342 Interpreter Loss: 53584.52\n",
      "Epoch:[ 0 ] Batch: 648 / 937 Main Model Loss: 0.092308916 Interpreter Loss: 51298.61\n",
      "Epoch:[ 0 ] Batch: 649 / 937 Main Model Loss: 0.16135967 Interpreter Loss: 51799.453\n",
      "Epoch:[ 0 ] Batch: 650 / 937 Main Model Loss: 0.033965252 Interpreter Loss: 51370.41\n",
      "Epoch:[ 0 ] Batch: 651 / 937 Main Model Loss: 0.036998063 Interpreter Loss: 50340.438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 0 ] Batch: 652 / 937 Main Model Loss: 0.11719025 Interpreter Loss: 50363.29\n",
      "Epoch:[ 0 ] Batch: 653 / 937 Main Model Loss: 0.05817323 Interpreter Loss: 50552.023\n",
      "Epoch:[ 0 ] Batch: 654 / 937 Main Model Loss: 0.09800264 Interpreter Loss: 52092.58\n",
      "Epoch:[ 0 ] Batch: 655 / 937 Main Model Loss: 0.04461002 Interpreter Loss: 51630.44\n",
      "Epoch:[ 0 ] Batch: 656 / 937 Main Model Loss: 0.10782011 Interpreter Loss: 51384.04\n",
      "Epoch:[ 0 ] Batch: 657 / 937 Main Model Loss: 0.016523391 Interpreter Loss: 50406.7\n",
      "Epoch:[ 0 ] Batch: 658 / 937 Main Model Loss: 0.03327122 Interpreter Loss: 51601.58\n",
      "Epoch:[ 0 ] Batch: 659 / 937 Main Model Loss: 0.11803667 Interpreter Loss: 50826.145\n",
      "Epoch:[ 0 ] Batch: 660 / 937 Main Model Loss: 0.047094796 Interpreter Loss: 50269.06\n",
      "Epoch:[ 0 ] Batch: 661 / 937 Main Model Loss: 0.16137269 Interpreter Loss: 51157.15\n",
      "Epoch:[ 0 ] Batch: 662 / 937 Main Model Loss: 0.11207011 Interpreter Loss: 50947.71\n",
      "Epoch:[ 0 ] Batch: 663 / 937 Main Model Loss: 0.2528882 Interpreter Loss: 50344.9\n",
      "Epoch:[ 0 ] Batch: 664 / 937 Main Model Loss: 0.15223405 Interpreter Loss: 50622.87\n",
      "Epoch:[ 0 ] Batch: 665 / 937 Main Model Loss: 0.11269347 Interpreter Loss: 49385.836\n",
      "Epoch:[ 0 ] Batch: 666 / 937 Main Model Loss: 0.042126857 Interpreter Loss: 51025.496\n",
      "Epoch:[ 0 ] Batch: 667 / 937 Main Model Loss: 0.11587413 Interpreter Loss: 50053.418\n",
      "Epoch:[ 0 ] Batch: 668 / 937 Main Model Loss: 0.107916996 Interpreter Loss: 49924.375\n",
      "Epoch:[ 0 ] Batch: 669 / 937 Main Model Loss: 0.2457901 Interpreter Loss: 49307.016\n",
      "Epoch:[ 0 ] Batch: 670 / 937 Main Model Loss: 0.18678007 Interpreter Loss: 49767.15\n",
      "Epoch:[ 0 ] Batch: 671 / 937 Main Model Loss: 0.10303234 Interpreter Loss: 48505.316\n",
      "Epoch:[ 0 ] Batch: 672 / 937 Main Model Loss: 0.15064965 Interpreter Loss: 49190.6\n",
      "Epoch:[ 0 ] Batch: 673 / 937 Main Model Loss: 0.18979633 Interpreter Loss: 48390.242\n",
      "Epoch:[ 0 ] Batch: 674 / 937 Main Model Loss: 0.07240385 Interpreter Loss: 48939.516\n",
      "Epoch:[ 0 ] Batch: 675 / 937 Main Model Loss: 0.053852417 Interpreter Loss: 48396.953\n",
      "Epoch:[ 0 ] Batch: 676 / 937 Main Model Loss: 0.0029944058 Interpreter Loss: 47248.258\n",
      "Epoch:[ 0 ] Batch: 677 / 937 Main Model Loss: 0.051673386 Interpreter Loss: 48137.758\n",
      "Epoch:[ 0 ] Batch: 678 / 937 Main Model Loss: 0.11549725 Interpreter Loss: 47170.8\n",
      "Epoch:[ 0 ] Batch: 679 / 937 Main Model Loss: 0.05129101 Interpreter Loss: 48398.355\n",
      "Epoch:[ 0 ] Batch: 680 / 937 Main Model Loss: 0.14608285 Interpreter Loss: 47289.137\n",
      "Epoch:[ 0 ] Batch: 681 / 937 Main Model Loss: 0.10169184 Interpreter Loss: 47660.23\n",
      "Epoch:[ 0 ] Batch: 682 / 937 Main Model Loss: 0.21670024 Interpreter Loss: 47136.1\n",
      "Epoch:[ 0 ] Batch: 683 / 937 Main Model Loss: 0.010168588 Interpreter Loss: 46527.406\n",
      "Epoch:[ 0 ] Batch: 684 / 937 Main Model Loss: 0.08316055 Interpreter Loss: 46618.082\n",
      "Epoch:[ 0 ] Batch: 685 / 937 Main Model Loss: 0.1535382 Interpreter Loss: 47499.477\n",
      "Epoch:[ 0 ] Batch: 686 / 937 Main Model Loss: 0.11233652 Interpreter Loss: 47054.53\n",
      "Epoch:[ 0 ] Batch: 687 / 937 Main Model Loss: 0.10490523 Interpreter Loss: 46613.832\n",
      "Epoch:[ 0 ] Batch: 688 / 937 Main Model Loss: 0.09873131 Interpreter Loss: 46696.707\n",
      "Epoch:[ 0 ] Batch: 689 / 937 Main Model Loss: 0.07470769 Interpreter Loss: 47321.445\n",
      "Epoch:[ 0 ] Batch: 690 / 937 Main Model Loss: 0.06489729 Interpreter Loss: 46412.008\n",
      "Epoch:[ 0 ] Batch: 691 / 937 Main Model Loss: 0.10292612 Interpreter Loss: 46801.285\n",
      "Epoch:[ 0 ] Batch: 692 / 937 Main Model Loss: 0.036700595 Interpreter Loss: 46232.41\n",
      "Epoch:[ 0 ] Batch: 693 / 937 Main Model Loss: 0.19117206 Interpreter Loss: 46130.746\n",
      "Epoch:[ 0 ] Batch: 694 / 937 Main Model Loss: 0.34755945 Interpreter Loss: 45611.85\n",
      "Epoch:[ 0 ] Batch: 695 / 937 Main Model Loss: 0.048986293 Interpreter Loss: 45613.008\n",
      "Epoch:[ 0 ] Batch: 696 / 937 Main Model Loss: 0.07301227 Interpreter Loss: 45221.184\n",
      "Epoch:[ 0 ] Batch: 697 / 937 Main Model Loss: 0.025575228 Interpreter Loss: 44934.203\n",
      "Epoch:[ 0 ] Batch: 698 / 937 Main Model Loss: 0.06968459 Interpreter Loss: 45193.156\n",
      "Epoch:[ 0 ] Batch: 699 / 937 Main Model Loss: 0.055117637 Interpreter Loss: 45525.375\n",
      "Epoch:[ 0 ] Batch: 700 / 937 Main Model Loss: 0.22239526 Interpreter Loss: 45638.664\n",
      "Epoch:[ 0 ] Batch: 701 / 937 Main Model Loss: 0.12483493 Interpreter Loss: 46001.613\n",
      "Epoch:[ 0 ] Batch: 702 / 937 Main Model Loss: 0.14863086 Interpreter Loss: 46855.7\n",
      "Epoch:[ 0 ] Batch: 703 / 937 Main Model Loss: 0.06392267 Interpreter Loss: 46024.87\n",
      "Epoch:[ 0 ] Batch: 704 / 937 Main Model Loss: 0.049645722 Interpreter Loss: 45388.906\n",
      "Epoch:[ 0 ] Batch: 705 / 937 Main Model Loss: 0.17918742 Interpreter Loss: 44675.39\n",
      "Epoch:[ 0 ] Batch: 706 / 937 Main Model Loss: 0.097335026 Interpreter Loss: 44552.63\n",
      "Epoch:[ 0 ] Batch: 707 / 937 Main Model Loss: 0.1398836 Interpreter Loss: 44651.176\n",
      "Epoch:[ 0 ] Batch: 708 / 937 Main Model Loss: 0.07596494 Interpreter Loss: 43319.54\n",
      "Epoch:[ 0 ] Batch: 709 / 937 Main Model Loss: 0.10749489 Interpreter Loss: 43891.914\n",
      "Epoch:[ 0 ] Batch: 710 / 937 Main Model Loss: 0.15794736 Interpreter Loss: 46384.523\n",
      "Epoch:[ 0 ] Batch: 711 / 937 Main Model Loss: 0.03780534 Interpreter Loss: 43919.645\n",
      "Epoch:[ 0 ] Batch: 712 / 937 Main Model Loss: 0.26748228 Interpreter Loss: 44376.547\n",
      "Epoch:[ 0 ] Batch: 713 / 937 Main Model Loss: 0.11335282 Interpreter Loss: 43654.73\n",
      "Epoch:[ 0 ] Batch: 714 / 937 Main Model Loss: 0.018865272 Interpreter Loss: 43178.9\n",
      "Epoch:[ 0 ] Batch: 715 / 937 Main Model Loss: 0.16430593 Interpreter Loss: 44575.15\n",
      "Epoch:[ 0 ] Batch: 716 / 937 Main Model Loss: 0.20117806 Interpreter Loss: 44076.863\n",
      "Epoch:[ 0 ] Batch: 717 / 937 Main Model Loss: 0.048892256 Interpreter Loss: 43886.754\n",
      "Epoch:[ 0 ] Batch: 718 / 937 Main Model Loss: 0.09462546 Interpreter Loss: 42680.832\n",
      "Epoch:[ 0 ] Batch: 719 / 937 Main Model Loss: 0.0928905 Interpreter Loss: 43924.46\n",
      "Epoch:[ 0 ] Batch: 720 / 937 Main Model Loss: 0.24527162 Interpreter Loss: 42611.105\n",
      "Epoch:[ 0 ] Batch: 721 / 937 Main Model Loss: 0.06476554 Interpreter Loss: 42316.703\n",
      "Epoch:[ 0 ] Batch: 722 / 937 Main Model Loss: 0.3352244 Interpreter Loss: 44184.62\n",
      "Epoch:[ 0 ] Batch: 723 / 937 Main Model Loss: 0.23706336 Interpreter Loss: 43343.156\n",
      "Epoch:[ 0 ] Batch: 724 / 937 Main Model Loss: 0.1288501 Interpreter Loss: 44218.816\n",
      "Epoch:[ 0 ] Batch: 725 / 937 Main Model Loss: 0.20687237 Interpreter Loss: 42519.14\n",
      "Epoch:[ 0 ] Batch: 726 / 937 Main Model Loss: 0.018866729 Interpreter Loss: 41655.953\n",
      "Epoch:[ 0 ] Batch: 727 / 937 Main Model Loss: 0.033689715 Interpreter Loss: 42194.47\n",
      "Epoch:[ 0 ] Batch: 728 / 937 Main Model Loss: 0.035349775 Interpreter Loss: 42666.957\n",
      "Epoch:[ 0 ] Batch: 729 / 937 Main Model Loss: 0.075712435 Interpreter Loss: 42040.184\n",
      "Epoch:[ 0 ] Batch: 730 / 937 Main Model Loss: 0.3015433 Interpreter Loss: 42730.625\n",
      "Epoch:[ 0 ] Batch: 731 / 937 Main Model Loss: 0.06771953 Interpreter Loss: 41771.953\n",
      "Epoch:[ 0 ] Batch: 732 / 937 Main Model Loss: 0.10738428 Interpreter Loss: 42071.445\n",
      "Epoch:[ 0 ] Batch: 733 / 937 Main Model Loss: 0.040866535 Interpreter Loss: 41102.727\n",
      "Epoch:[ 0 ] Batch: 734 / 937 Main Model Loss: 0.144114 Interpreter Loss: 41970.56\n",
      "Epoch:[ 0 ] Batch: 735 / 937 Main Model Loss: 0.042311125 Interpreter Loss: 41222.984\n",
      "Epoch:[ 0 ] Batch: 736 / 937 Main Model Loss: 0.15783018 Interpreter Loss: 40838.305\n",
      "Epoch:[ 0 ] Batch: 737 / 937 Main Model Loss: 0.060518675 Interpreter Loss: 40797.805\n",
      "Epoch:[ 0 ] Batch: 738 / 937 Main Model Loss: 0.12779528 Interpreter Loss: 42107.21\n",
      "Epoch:[ 0 ] Batch: 739 / 937 Main Model Loss: 0.114325 Interpreter Loss: 41082.824\n",
      "Epoch:[ 0 ] Batch: 740 / 937 Main Model Loss: 0.15007296 Interpreter Loss: 41698.67\n",
      "Epoch:[ 0 ] Batch: 741 / 937 Main Model Loss: 0.21840772 Interpreter Loss: 42520.75\n",
      "Epoch:[ 0 ] Batch: 742 / 937 Main Model Loss: 0.11084647 Interpreter Loss: 40885.21\n",
      "Epoch:[ 0 ] Batch: 743 / 937 Main Model Loss: 0.23186344 Interpreter Loss: 42686.293\n",
      "Epoch:[ 0 ] Batch: 744 / 937 Main Model Loss: 0.02785078 Interpreter Loss: 41276.227\n",
      "Epoch:[ 0 ] Batch: 745 / 937 Main Model Loss: 0.14966767 Interpreter Loss: 40306.977\n",
      "Epoch:[ 0 ] Batch: 746 / 937 Main Model Loss: 0.14944367 Interpreter Loss: 40239.89\n",
      "Epoch:[ 0 ] Batch: 747 / 937 Main Model Loss: 0.055986576 Interpreter Loss: 40382.21\n",
      "Epoch:[ 0 ] Batch: 748 / 937 Main Model Loss: 0.1630892 Interpreter Loss: 41044.977\n",
      "Epoch:[ 0 ] Batch: 749 / 937 Main Model Loss: 0.08617841 Interpreter Loss: 40923.55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 0 ] Batch: 750 / 937 Main Model Loss: 0.03691721 Interpreter Loss: 40571.145\n",
      "Epoch:[ 0 ] Batch: 751 / 937 Main Model Loss: 0.19306493 Interpreter Loss: 40909.97\n",
      "Epoch:[ 0 ] Batch: 752 / 937 Main Model Loss: 0.03214815 Interpreter Loss: 40070.723\n",
      "Epoch:[ 0 ] Batch: 753 / 937 Main Model Loss: 0.0613786 Interpreter Loss: 40213.363\n",
      "Epoch:[ 0 ] Batch: 754 / 937 Main Model Loss: 0.06481668 Interpreter Loss: 40010.867\n",
      "Epoch:[ 0 ] Batch: 755 / 937 Main Model Loss: 0.22052157 Interpreter Loss: 42122.504\n",
      "Epoch:[ 0 ] Batch: 756 / 937 Main Model Loss: 0.04003316 Interpreter Loss: 40171.695\n",
      "Epoch:[ 0 ] Batch: 757 / 937 Main Model Loss: 0.078770906 Interpreter Loss: 39887.18\n",
      "Epoch:[ 0 ] Batch: 758 / 937 Main Model Loss: 0.11605196 Interpreter Loss: 39553.598\n",
      "Epoch:[ 0 ] Batch: 759 / 937 Main Model Loss: 0.08496696 Interpreter Loss: 39377.57\n",
      "Epoch:[ 0 ] Batch: 760 / 937 Main Model Loss: 0.12826686 Interpreter Loss: 38948.51\n",
      "Epoch:[ 0 ] Batch: 761 / 937 Main Model Loss: 0.014292927 Interpreter Loss: 38907.57\n",
      "Epoch:[ 0 ] Batch: 762 / 937 Main Model Loss: 0.038733855 Interpreter Loss: 39021.21\n",
      "Epoch:[ 0 ] Batch: 763 / 937 Main Model Loss: 0.045954444 Interpreter Loss: 38991.7\n",
      "Epoch:[ 0 ] Batch: 764 / 937 Main Model Loss: 0.25999507 Interpreter Loss: 39099.875\n",
      "Epoch:[ 0 ] Batch: 765 / 937 Main Model Loss: 0.28404263 Interpreter Loss: 39437.023\n",
      "Epoch:[ 0 ] Batch: 766 / 937 Main Model Loss: 0.16516238 Interpreter Loss: 38952.812\n",
      "Epoch:[ 0 ] Batch: 767 / 937 Main Model Loss: 0.023655884 Interpreter Loss: 38326.69\n",
      "Epoch:[ 0 ] Batch: 768 / 937 Main Model Loss: 0.086164184 Interpreter Loss: 39286.75\n",
      "Epoch:[ 0 ] Batch: 769 / 937 Main Model Loss: 0.09196646 Interpreter Loss: 38541.016\n",
      "Epoch:[ 0 ] Batch: 770 / 937 Main Model Loss: 0.088241264 Interpreter Loss: 37635.11\n",
      "Epoch:[ 0 ] Batch: 771 / 937 Main Model Loss: 0.03813898 Interpreter Loss: 37582.56\n",
      "Epoch:[ 0 ] Batch: 772 / 937 Main Model Loss: 0.15128453 Interpreter Loss: 37513.98\n",
      "Epoch:[ 0 ] Batch: 773 / 937 Main Model Loss: 0.25060248 Interpreter Loss: 41197.094\n",
      "Epoch:[ 0 ] Batch: 774 / 937 Main Model Loss: 0.3158095 Interpreter Loss: 39226.805\n",
      "Epoch:[ 0 ] Batch: 775 / 937 Main Model Loss: 0.18656632 Interpreter Loss: 37819.562\n",
      "Epoch:[ 0 ] Batch: 776 / 937 Main Model Loss: 0.04009129 Interpreter Loss: 36734.117\n",
      "Epoch:[ 0 ] Batch: 777 / 937 Main Model Loss: 0.077917956 Interpreter Loss: 37780.133\n",
      "Epoch:[ 0 ] Batch: 778 / 937 Main Model Loss: 0.06342947 Interpreter Loss: 37283.42\n",
      "Epoch:[ 0 ] Batch: 779 / 937 Main Model Loss: 0.37942564 Interpreter Loss: 37677.12\n",
      "Epoch:[ 0 ] Batch: 780 / 937 Main Model Loss: 0.07332431 Interpreter Loss: 36936.875\n",
      "Epoch:[ 0 ] Batch: 781 / 937 Main Model Loss: 0.048285954 Interpreter Loss: 36649.184\n",
      "Epoch:[ 0 ] Batch: 782 / 937 Main Model Loss: 0.033355985 Interpreter Loss: 37144.6\n",
      "Epoch:[ 0 ] Batch: 783 / 937 Main Model Loss: 0.065748416 Interpreter Loss: 36633.49\n",
      "Epoch:[ 0 ] Batch: 784 / 937 Main Model Loss: 0.24329111 Interpreter Loss: 37629.008\n",
      "Epoch:[ 0 ] Batch: 785 / 937 Main Model Loss: 0.061391894 Interpreter Loss: 35979.707\n",
      "Epoch:[ 0 ] Batch: 786 / 937 Main Model Loss: 0.27650008 Interpreter Loss: 38201.266\n",
      "Epoch:[ 0 ] Batch: 787 / 937 Main Model Loss: 0.42824984 Interpreter Loss: 37941.977\n",
      "Epoch:[ 0 ] Batch: 788 / 937 Main Model Loss: 0.032380737 Interpreter Loss: 36393.395\n",
      "Epoch:[ 0 ] Batch: 789 / 937 Main Model Loss: 0.27503014 Interpreter Loss: 36258.566\n",
      "Epoch:[ 0 ] Batch: 790 / 937 Main Model Loss: 0.060064804 Interpreter Loss: 37404.383\n",
      "Epoch:[ 0 ] Batch: 791 / 937 Main Model Loss: 0.052812193 Interpreter Loss: 35550.176\n",
      "Epoch:[ 0 ] Batch: 792 / 937 Main Model Loss: 0.17185156 Interpreter Loss: 38779.324\n",
      "Epoch:[ 0 ] Batch: 793 / 937 Main Model Loss: 0.031155083 Interpreter Loss: 36949.797\n",
      "Epoch:[ 0 ] Batch: 794 / 937 Main Model Loss: 0.048441097 Interpreter Loss: 36051.215\n",
      "Epoch:[ 0 ] Batch: 795 / 937 Main Model Loss: 0.22663203 Interpreter Loss: 37028.746\n",
      "Epoch:[ 0 ] Batch: 796 / 937 Main Model Loss: 0.08489512 Interpreter Loss: 36342.78\n",
      "Epoch:[ 0 ] Batch: 797 / 937 Main Model Loss: 0.009303729 Interpreter Loss: 34731.312\n",
      "Epoch:[ 0 ] Batch: 798 / 937 Main Model Loss: 0.02693586 Interpreter Loss: 35330.785\n",
      "Epoch:[ 0 ] Batch: 799 / 937 Main Model Loss: 0.07454873 Interpreter Loss: 36139.21\n",
      "Epoch:[ 0 ] Batch: 800 / 937 Main Model Loss: 0.19127238 Interpreter Loss: 36906.11\n",
      "Epoch:[ 0 ] Batch: 801 / 937 Main Model Loss: 0.0682235 Interpreter Loss: 37455.74\n",
      "Epoch:[ 0 ] Batch: 802 / 937 Main Model Loss: 0.039028555 Interpreter Loss: 35688.605\n",
      "Epoch:[ 0 ] Batch: 803 / 937 Main Model Loss: 0.050797198 Interpreter Loss: 35151.844\n",
      "Epoch:[ 0 ] Batch: 804 / 937 Main Model Loss: 0.04798164 Interpreter Loss: 36048.54\n",
      "Epoch:[ 0 ] Batch: 805 / 937 Main Model Loss: 0.06355041 Interpreter Loss: 34495.254\n",
      "Epoch:[ 0 ] Batch: 806 / 937 Main Model Loss: 0.07791171 Interpreter Loss: 35359.49\n",
      "Epoch:[ 0 ] Batch: 807 / 937 Main Model Loss: 0.14432302 Interpreter Loss: 34314.46\n",
      "Epoch:[ 0 ] Batch: 808 / 937 Main Model Loss: 0.22596242 Interpreter Loss: 34647.164\n",
      "Epoch:[ 0 ] Batch: 809 / 937 Main Model Loss: 0.061536957 Interpreter Loss: 33803.184\n",
      "Epoch:[ 0 ] Batch: 810 / 937 Main Model Loss: 0.06649828 Interpreter Loss: 34354.707\n",
      "Epoch:[ 0 ] Batch: 811 / 937 Main Model Loss: 0.10482256 Interpreter Loss: 34450.438\n",
      "Epoch:[ 0 ] Batch: 812 / 937 Main Model Loss: 0.16918333 Interpreter Loss: 34260.758\n",
      "Epoch:[ 0 ] Batch: 813 / 937 Main Model Loss: 0.098273925 Interpreter Loss: 34719.477\n",
      "Epoch:[ 0 ] Batch: 814 / 937 Main Model Loss: 0.16824752 Interpreter Loss: 35034.98\n",
      "Epoch:[ 0 ] Batch: 815 / 937 Main Model Loss: 0.049230658 Interpreter Loss: 34350.75\n",
      "Epoch:[ 0 ] Batch: 816 / 937 Main Model Loss: 0.15270346 Interpreter Loss: 34518.98\n",
      "Epoch:[ 0 ] Batch: 817 / 937 Main Model Loss: 0.12592441 Interpreter Loss: 33609.14\n",
      "Epoch:[ 0 ] Batch: 818 / 937 Main Model Loss: 0.058350965 Interpreter Loss: 33485.453\n",
      "Epoch:[ 0 ] Batch: 819 / 937 Main Model Loss: 0.054196157 Interpreter Loss: 34169.555\n",
      "Epoch:[ 0 ] Batch: 820 / 937 Main Model Loss: 0.016551157 Interpreter Loss: 33460.58\n",
      "Epoch:[ 0 ] Batch: 821 / 937 Main Model Loss: 0.015479576 Interpreter Loss: 33366.305\n",
      "Epoch:[ 0 ] Batch: 822 / 937 Main Model Loss: 0.019079532 Interpreter Loss: 33476.426\n",
      "Epoch:[ 0 ] Batch: 823 / 937 Main Model Loss: 0.09188625 Interpreter Loss: 33523.91\n",
      "Epoch:[ 0 ] Batch: 824 / 937 Main Model Loss: 0.025434759 Interpreter Loss: 33176.008\n",
      "Epoch:[ 0 ] Batch: 825 / 937 Main Model Loss: 0.1954771 Interpreter Loss: 34721.375\n",
      "Epoch:[ 0 ] Batch: 826 / 937 Main Model Loss: 0.115006536 Interpreter Loss: 35218.676\n",
      "Epoch:[ 0 ] Batch: 827 / 937 Main Model Loss: 0.44934466 Interpreter Loss: 35320.844\n",
      "Epoch:[ 0 ] Batch: 828 / 937 Main Model Loss: 0.10873383 Interpreter Loss: 34572.15\n",
      "Epoch:[ 0 ] Batch: 829 / 937 Main Model Loss: 0.039464973 Interpreter Loss: 33933.246\n",
      "Epoch:[ 0 ] Batch: 830 / 937 Main Model Loss: 0.17806047 Interpreter Loss: 33077.17\n",
      "Epoch:[ 0 ] Batch: 831 / 937 Main Model Loss: 0.15083523 Interpreter Loss: 32986.336\n",
      "Epoch:[ 0 ] Batch: 832 / 937 Main Model Loss: 0.0048142076 Interpreter Loss: 32113.492\n",
      "Epoch:[ 0 ] Batch: 833 / 937 Main Model Loss: 0.017105745 Interpreter Loss: 31995.158\n",
      "Epoch:[ 0 ] Batch: 834 / 937 Main Model Loss: 0.08362703 Interpreter Loss: 32698.447\n",
      "Epoch:[ 0 ] Batch: 835 / 937 Main Model Loss: 0.08841925 Interpreter Loss: 32184.285\n",
      "Epoch:[ 0 ] Batch: 836 / 937 Main Model Loss: 0.070540145 Interpreter Loss: 32571.832\n",
      "Epoch:[ 0 ] Batch: 837 / 937 Main Model Loss: 0.08529913 Interpreter Loss: 31923.469\n",
      "Epoch:[ 0 ] Batch: 838 / 937 Main Model Loss: 0.19924681 Interpreter Loss: 33056.03\n",
      "Epoch:[ 0 ] Batch: 839 / 937 Main Model Loss: 0.067881465 Interpreter Loss: 32959.906\n",
      "Epoch:[ 0 ] Batch: 840 / 937 Main Model Loss: 0.024734538 Interpreter Loss: 31280.172\n",
      "Epoch:[ 0 ] Batch: 841 / 937 Main Model Loss: 0.21503246 Interpreter Loss: 34077.94\n",
      "Epoch:[ 0 ] Batch: 842 / 937 Main Model Loss: 0.114770845 Interpreter Loss: 33217.453\n",
      "Epoch:[ 0 ] Batch: 843 / 937 Main Model Loss: 0.16647008 Interpreter Loss: 33663.492\n",
      "Epoch:[ 0 ] Batch: 844 / 937 Main Model Loss: 0.07196554 Interpreter Loss: 32591.035\n",
      "Epoch:[ 0 ] Batch: 845 / 937 Main Model Loss: 0.047741197 Interpreter Loss: 31388.98\n",
      "Epoch:[ 0 ] Batch: 846 / 937 Main Model Loss: 0.025122505 Interpreter Loss: 33136.367\n",
      "Epoch:[ 0 ] Batch: 847 / 937 Main Model Loss: 0.024207698 Interpreter Loss: 30816.547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 0 ] Batch: 848 / 937 Main Model Loss: 0.035232373 Interpreter Loss: 31566.762\n",
      "Epoch:[ 0 ] Batch: 849 / 937 Main Model Loss: 0.019085485 Interpreter Loss: 31761.977\n",
      "Epoch:[ 0 ] Batch: 850 / 937 Main Model Loss: 0.05209699 Interpreter Loss: 32125.736\n",
      "Epoch:[ 0 ] Batch: 851 / 937 Main Model Loss: 0.10169078 Interpreter Loss: 31741.871\n",
      "Epoch:[ 0 ] Batch: 852 / 937 Main Model Loss: 0.111095324 Interpreter Loss: 32478.098\n",
      "Epoch:[ 0 ] Batch: 853 / 937 Main Model Loss: 0.07282382 Interpreter Loss: 31687.258\n",
      "Epoch:[ 0 ] Batch: 854 / 937 Main Model Loss: 0.029909946 Interpreter Loss: 31558.453\n",
      "Epoch:[ 0 ] Batch: 855 / 937 Main Model Loss: 0.087387644 Interpreter Loss: 32559.77\n",
      "Epoch:[ 0 ] Batch: 856 / 937 Main Model Loss: 0.07233638 Interpreter Loss: 32119.154\n",
      "Epoch:[ 0 ] Batch: 857 / 937 Main Model Loss: 0.14584416 Interpreter Loss: 32054.455\n",
      "Epoch:[ 0 ] Batch: 858 / 937 Main Model Loss: 0.09833875 Interpreter Loss: 33347.395\n",
      "Epoch:[ 0 ] Batch: 859 / 937 Main Model Loss: 0.08038461 Interpreter Loss: 31891.29\n",
      "Epoch:[ 0 ] Batch: 860 / 937 Main Model Loss: 0.011742525 Interpreter Loss: 30791.113\n",
      "Epoch:[ 0 ] Batch: 861 / 937 Main Model Loss: 0.03828025 Interpreter Loss: 30783.027\n",
      "Epoch:[ 0 ] Batch: 862 / 937 Main Model Loss: 0.0432384 Interpreter Loss: 31754.396\n",
      "Epoch:[ 0 ] Batch: 863 / 937 Main Model Loss: 0.09215434 Interpreter Loss: 31107.805\n",
      "Epoch:[ 0 ] Batch: 864 / 937 Main Model Loss: 0.13649663 Interpreter Loss: 31451.67\n",
      "Epoch:[ 0 ] Batch: 865 / 937 Main Model Loss: 0.030553909 Interpreter Loss: 30455.29\n",
      "Epoch:[ 0 ] Batch: 866 / 937 Main Model Loss: 0.031063814 Interpreter Loss: 30742.213\n",
      "Epoch:[ 0 ] Batch: 867 / 937 Main Model Loss: 0.16620278 Interpreter Loss: 31592.707\n",
      "Epoch:[ 0 ] Batch: 868 / 937 Main Model Loss: 0.079034284 Interpreter Loss: 31846.68\n",
      "Epoch:[ 0 ] Batch: 869 / 937 Main Model Loss: 0.07515254 Interpreter Loss: 32160.408\n",
      "Epoch:[ 0 ] Batch: 870 / 937 Main Model Loss: 0.17643966 Interpreter Loss: 31012.719\n",
      "Epoch:[ 0 ] Batch: 871 / 937 Main Model Loss: 0.071738966 Interpreter Loss: 31001.523\n",
      "Epoch:[ 0 ] Batch: 872 / 937 Main Model Loss: 0.13985398 Interpreter Loss: 30331.84\n",
      "Epoch:[ 0 ] Batch: 873 / 937 Main Model Loss: 0.10719971 Interpreter Loss: 31130.621\n",
      "Epoch:[ 0 ] Batch: 874 / 937 Main Model Loss: 0.0432169 Interpreter Loss: 29718.656\n",
      "Epoch:[ 0 ] Batch: 875 / 937 Main Model Loss: 0.21086921 Interpreter Loss: 30467.473\n",
      "Epoch:[ 0 ] Batch: 876 / 937 Main Model Loss: 0.066179186 Interpreter Loss: 30051.809\n",
      "Epoch:[ 0 ] Batch: 877 / 937 Main Model Loss: 0.100246586 Interpreter Loss: 30492.23\n",
      "Epoch:[ 0 ] Batch: 878 / 937 Main Model Loss: 0.16449007 Interpreter Loss: 30494.123\n",
      "Epoch:[ 0 ] Batch: 879 / 937 Main Model Loss: 0.040575884 Interpreter Loss: 30633.996\n",
      "Epoch:[ 0 ] Batch: 880 / 937 Main Model Loss: 0.01946167 Interpreter Loss: 29367.404\n",
      "Epoch:[ 0 ] Batch: 881 / 937 Main Model Loss: 0.06164805 Interpreter Loss: 28901.475\n",
      "Epoch:[ 0 ] Batch: 882 / 937 Main Model Loss: 0.19872357 Interpreter Loss: 30222.84\n",
      "Epoch:[ 0 ] Batch: 883 / 937 Main Model Loss: 0.059759855 Interpreter Loss: 29325.367\n",
      "Epoch:[ 0 ] Batch: 884 / 937 Main Model Loss: 0.109163746 Interpreter Loss: 29799.598\n",
      "Epoch:[ 0 ] Batch: 885 / 937 Main Model Loss: 0.11286138 Interpreter Loss: 29674.55\n",
      "Epoch:[ 0 ] Batch: 886 / 937 Main Model Loss: 0.053353433 Interpreter Loss: 30408.637\n",
      "Epoch:[ 0 ] Batch: 887 / 937 Main Model Loss: 0.16772184 Interpreter Loss: 30022.535\n",
      "Epoch:[ 0 ] Batch: 888 / 937 Main Model Loss: 0.023263736 Interpreter Loss: 29692.2\n",
      "Epoch:[ 0 ] Batch: 889 / 937 Main Model Loss: 0.008493418 Interpreter Loss: 28518.502\n",
      "Epoch:[ 0 ] Batch: 890 / 937 Main Model Loss: 0.016208526 Interpreter Loss: 28920.43\n",
      "Epoch:[ 0 ] Batch: 891 / 937 Main Model Loss: 0.12197114 Interpreter Loss: 28232.115\n",
      "Epoch:[ 0 ] Batch: 892 / 937 Main Model Loss: 0.0063404967 Interpreter Loss: 27956.984\n",
      "Epoch:[ 0 ] Batch: 893 / 937 Main Model Loss: 0.03222819 Interpreter Loss: 28455.518\n",
      "Epoch:[ 0 ] Batch: 894 / 937 Main Model Loss: 0.102972254 Interpreter Loss: 29434.617\n",
      "Epoch:[ 0 ] Batch: 895 / 937 Main Model Loss: 0.08116686 Interpreter Loss: 29868.125\n",
      "Epoch:[ 0 ] Batch: 896 / 937 Main Model Loss: 0.04209937 Interpreter Loss: 28884.246\n",
      "Epoch:[ 0 ] Batch: 897 / 937 Main Model Loss: 0.048246942 Interpreter Loss: 28807.195\n",
      "Epoch:[ 0 ] Batch: 898 / 937 Main Model Loss: 0.07733403 Interpreter Loss: 29592.398\n",
      "Epoch:[ 0 ] Batch: 899 / 937 Main Model Loss: 0.05932907 Interpreter Loss: 29236.027\n",
      "Epoch:[ 0 ] Batch: 900 / 937 Main Model Loss: 0.117019914 Interpreter Loss: 29427.139\n",
      "Epoch:[ 0 ] Batch: 901 / 937 Main Model Loss: 0.036562778 Interpreter Loss: 29074.836\n",
      "Epoch:[ 0 ] Batch: 902 / 937 Main Model Loss: 0.14814 Interpreter Loss: 28481.195\n",
      "Epoch:[ 0 ] Batch: 903 / 937 Main Model Loss: 0.048218105 Interpreter Loss: 27876.594\n",
      "Epoch:[ 0 ] Batch: 904 / 937 Main Model Loss: 0.07934607 Interpreter Loss: 27914.215\n",
      "Epoch:[ 0 ] Batch: 905 / 937 Main Model Loss: 0.120309874 Interpreter Loss: 27779.21\n",
      "Epoch:[ 0 ] Batch: 906 / 937 Main Model Loss: 0.048849188 Interpreter Loss: 27767.602\n",
      "Epoch:[ 0 ] Batch: 907 / 937 Main Model Loss: 0.14297657 Interpreter Loss: 28662.018\n",
      "Epoch:[ 0 ] Batch: 908 / 937 Main Model Loss: 0.007016695 Interpreter Loss: 26926.004\n",
      "Epoch:[ 0 ] Batch: 909 / 937 Main Model Loss: 0.0101922685 Interpreter Loss: 27380.166\n",
      "Epoch:[ 0 ] Batch: 910 / 937 Main Model Loss: 0.025282666 Interpreter Loss: 27919.012\n",
      "Epoch:[ 0 ] Batch: 911 / 937 Main Model Loss: 0.022497157 Interpreter Loss: 28007.555\n",
      "Epoch:[ 0 ] Batch: 912 / 937 Main Model Loss: 0.048584916 Interpreter Loss: 28899.02\n",
      "Epoch:[ 0 ] Batch: 913 / 937 Main Model Loss: 0.040892594 Interpreter Loss: 29056.168\n",
      "Epoch:[ 0 ] Batch: 914 / 937 Main Model Loss: 0.0056725284 Interpreter Loss: 26592.564\n",
      "Epoch:[ 0 ] Batch: 915 / 937 Main Model Loss: 0.016531153 Interpreter Loss: 26500.252\n",
      "Epoch:[ 0 ] Batch: 916 / 937 Main Model Loss: 0.03858945 Interpreter Loss: 26225.805\n",
      "Epoch:[ 0 ] Batch: 917 / 937 Main Model Loss: 0.009173102 Interpreter Loss: 25808.82\n",
      "Epoch:[ 0 ] Batch: 918 / 937 Main Model Loss: 0.22231191 Interpreter Loss: 27036.848\n",
      "Epoch:[ 0 ] Batch: 919 / 937 Main Model Loss: 0.10680343 Interpreter Loss: 28370.154\n",
      "Epoch:[ 0 ] Batch: 920 / 937 Main Model Loss: 0.0066339085 Interpreter Loss: 27168.96\n",
      "Epoch:[ 0 ] Batch: 921 / 937 Main Model Loss: 0.0015972566 Interpreter Loss: 26885.912\n",
      "Epoch:[ 0 ] Batch: 922 / 937 Main Model Loss: 0.003902933 Interpreter Loss: 26417.828\n",
      "Epoch:[ 0 ] Batch: 923 / 937 Main Model Loss: 0.0014906684 Interpreter Loss: 26211.027\n",
      "Epoch:[ 0 ] Batch: 924 / 937 Main Model Loss: 0.0016368763 Interpreter Loss: 26533.148\n",
      "Epoch:[ 0 ] Batch: 925 / 937 Main Model Loss: 0.0036616256 Interpreter Loss: 27060.2\n",
      "Epoch:[ 0 ] Batch: 926 / 937 Main Model Loss: 0.037663903 Interpreter Loss: 29678.842\n",
      "Epoch:[ 0 ] Batch: 927 / 937 Main Model Loss: 0.081532866 Interpreter Loss: 30778.57\n",
      "Epoch:[ 0 ] Batch: 928 / 937 Main Model Loss: 0.055870254 Interpreter Loss: 31575.848\n",
      "Epoch:[ 0 ] Batch: 929 / 937 Main Model Loss: 0.006556719 Interpreter Loss: 27382.209\n",
      "Epoch:[ 0 ] Batch: 930 / 937 Main Model Loss: 0.0039428337 Interpreter Loss: 25759.564\n",
      "Epoch:[ 0 ] Batch: 931 / 937 Main Model Loss: 0.007854899 Interpreter Loss: 26435.863\n",
      "Epoch:[ 0 ] Batch: 932 / 937 Main Model Loss: 0.14856313 Interpreter Loss: 27474.932\n",
      "Epoch:[ 0 ] Batch: 933 / 937 Main Model Loss: 0.60665023 Interpreter Loss: 29050.922\n",
      "Epoch:[ 0 ] Batch: 934 / 937 Main Model Loss: 0.0166194 Interpreter Loss: 27171.5\n",
      "Epoch:[ 0 ] Batch: 935 / 937 Main Model Loss: 0.0048268503 Interpreter Loss: 26861.605\n",
      "Epoch:[ 0 ] Batch: 936 / 937 Main Model Loss: 0.2671511 Interpreter Loss: 26004.531\n",
      " Main Model Acc:  1.0 Interpreter Acc:  0.75\n",
      "WARNING:tensorflow:From /home/nariman/.local/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nariman/.local/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nariman/.local/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nariman/.local/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 1 ] Batch: 0 / 937 Main Model Loss: 0.057199925 Interpreter Loss: 27209.074\n",
      "Epoch:[ 1 ] Batch: 1 / 937 Main Model Loss: 0.13030624 Interpreter Loss: 26931.21\n",
      "Epoch:[ 1 ] Batch: 2 / 937 Main Model Loss: 0.24994227 Interpreter Loss: 26984.498\n",
      "Epoch:[ 1 ] Batch: 3 / 937 Main Model Loss: 0.04026952 Interpreter Loss: 27231.19\n",
      "Epoch:[ 1 ] Batch: 4 / 937 Main Model Loss: 0.026041208 Interpreter Loss: 26226.543\n",
      "Epoch:[ 1 ] Batch: 5 / 937 Main Model Loss: 0.010706741 Interpreter Loss: 25955.89\n",
      "Epoch:[ 1 ] Batch: 6 / 937 Main Model Loss: 0.09014668 Interpreter Loss: 26717.02\n",
      "Epoch:[ 1 ] Batch: 7 / 937 Main Model Loss: 0.121875264 Interpreter Loss: 26037.88\n",
      "Epoch:[ 1 ] Batch: 8 / 937 Main Model Loss: 0.008860335 Interpreter Loss: 26243.848\n",
      "Epoch:[ 1 ] Batch: 9 / 937 Main Model Loss: 0.104068145 Interpreter Loss: 26806.824\n",
      "Epoch:[ 1 ] Batch: 10 / 937 Main Model Loss: 0.018338997 Interpreter Loss: 26191.57\n",
      "Epoch:[ 1 ] Batch: 11 / 937 Main Model Loss: 0.1456781 Interpreter Loss: 27566.11\n",
      "Epoch:[ 1 ] Batch: 12 / 937 Main Model Loss: 0.11092096 Interpreter Loss: 26712.76\n",
      "Epoch:[ 1 ] Batch: 13 / 937 Main Model Loss: 0.12856187 Interpreter Loss: 27555.873\n",
      "Epoch:[ 1 ] Batch: 14 / 937 Main Model Loss: 0.15651187 Interpreter Loss: 26893.463\n",
      "Epoch:[ 1 ] Batch: 15 / 937 Main Model Loss: 0.069721915 Interpreter Loss: 27225.725\n",
      "Epoch:[ 1 ] Batch: 16 / 937 Main Model Loss: 0.10742557 Interpreter Loss: 27403.713\n",
      "Epoch:[ 1 ] Batch: 17 / 937 Main Model Loss: 0.14928855 Interpreter Loss: 27502.34\n",
      "Epoch:[ 1 ] Batch: 18 / 937 Main Model Loss: 0.06781767 Interpreter Loss: 26959.3\n",
      "Epoch:[ 1 ] Batch: 19 / 937 Main Model Loss: 0.1126419 Interpreter Loss: 28963.86\n",
      "Epoch:[ 1 ] Batch: 20 / 937 Main Model Loss: 0.050769802 Interpreter Loss: 27892.562\n",
      "Epoch:[ 1 ] Batch: 21 / 937 Main Model Loss: 0.14394973 Interpreter Loss: 28324.164\n",
      "Epoch:[ 1 ] Batch: 22 / 937 Main Model Loss: 0.015102665 Interpreter Loss: 25427.965\n",
      "Epoch:[ 1 ] Batch: 23 / 937 Main Model Loss: 0.03145992 Interpreter Loss: 26170.05\n",
      "Epoch:[ 1 ] Batch: 24 / 937 Main Model Loss: 0.022774117 Interpreter Loss: 25218.299\n",
      "Epoch:[ 1 ] Batch: 25 / 937 Main Model Loss: 0.092851624 Interpreter Loss: 25994.297\n",
      "Epoch:[ 1 ] Batch: 26 / 937 Main Model Loss: 0.01577807 Interpreter Loss: 25132.535\n",
      "Epoch:[ 1 ] Batch: 27 / 937 Main Model Loss: 0.06691795 Interpreter Loss: 25072.303\n",
      "Epoch:[ 1 ] Batch: 28 / 937 Main Model Loss: 0.011251554 Interpreter Loss: 25273.762\n",
      "Epoch:[ 1 ] Batch: 29 / 937 Main Model Loss: 0.019820938 Interpreter Loss: 26011.316\n",
      "Epoch:[ 1 ] Batch: 30 / 937 Main Model Loss: 0.1200047 Interpreter Loss: 26809.332\n",
      "Epoch:[ 1 ] Batch: 31 / 937 Main Model Loss: 0.055608846 Interpreter Loss: 26773.83\n",
      "Epoch:[ 1 ] Batch: 32 / 937 Main Model Loss: 0.0080723325 Interpreter Loss: 25744.855\n",
      "Epoch:[ 1 ] Batch: 33 / 937 Main Model Loss: 0.025745612 Interpreter Loss: 25789.37\n",
      "Epoch:[ 1 ] Batch: 34 / 937 Main Model Loss: 0.050761253 Interpreter Loss: 25333.254\n",
      "Epoch:[ 1 ] Batch: 35 / 937 Main Model Loss: 0.04841444 Interpreter Loss: 26818.004\n",
      "Epoch:[ 1 ] Batch: 36 / 937 Main Model Loss: 0.011560125 Interpreter Loss: 25000.97\n",
      "Epoch:[ 1 ] Batch: 37 / 937 Main Model Loss: 0.08339814 Interpreter Loss: 25760.406\n",
      "Epoch:[ 1 ] Batch: 38 / 937 Main Model Loss: 0.023157848 Interpreter Loss: 25373.709\n",
      "Epoch:[ 1 ] Batch: 39 / 937 Main Model Loss: 0.012993527 Interpreter Loss: 25753.984\n",
      "Epoch:[ 1 ] Batch: 40 / 937 Main Model Loss: 0.048475288 Interpreter Loss: 25304.666\n",
      "Epoch:[ 1 ] Batch: 41 / 937 Main Model Loss: 0.19802417 Interpreter Loss: 25983.43\n",
      "Epoch:[ 1 ] Batch: 42 / 937 Main Model Loss: 0.111198336 Interpreter Loss: 24853.848\n",
      "Epoch:[ 1 ] Batch: 43 / 937 Main Model Loss: 0.07563863 Interpreter Loss: 25895.809\n",
      "Epoch:[ 1 ] Batch: 44 / 937 Main Model Loss: 0.03929903 Interpreter Loss: 25706.389\n",
      "Epoch:[ 1 ] Batch: 45 / 937 Main Model Loss: 0.060184438 Interpreter Loss: 25330.957\n",
      "Epoch:[ 1 ] Batch: 46 / 937 Main Model Loss: 0.033242762 Interpreter Loss: 24602.953\n",
      "Epoch:[ 1 ] Batch: 47 / 937 Main Model Loss: 0.14595923 Interpreter Loss: 25799.09\n",
      "Epoch:[ 1 ] Batch: 48 / 937 Main Model Loss: 0.01779724 Interpreter Loss: 24570.133\n",
      "Epoch:[ 1 ] Batch: 49 / 937 Main Model Loss: 0.0023857276 Interpreter Loss: 23885.713\n",
      "Epoch:[ 1 ] Batch: 50 / 937 Main Model Loss: 0.026749497 Interpreter Loss: 24187.047\n",
      "Epoch:[ 1 ] Batch: 51 / 937 Main Model Loss: 0.02316824 Interpreter Loss: 25030.182\n",
      "Epoch:[ 1 ] Batch: 52 / 937 Main Model Loss: 0.0061630583 Interpreter Loss: 24326.262\n",
      "Epoch:[ 1 ] Batch: 53 / 937 Main Model Loss: 0.036907624 Interpreter Loss: 24052.48\n",
      "Epoch:[ 1 ] Batch: 54 / 937 Main Model Loss: 0.06149265 Interpreter Loss: 24306.799\n",
      "Epoch:[ 1 ] Batch: 55 / 937 Main Model Loss: 0.044943064 Interpreter Loss: 24464.984\n",
      "Epoch:[ 1 ] Batch: 56 / 937 Main Model Loss: 0.032132987 Interpreter Loss: 25251.152\n",
      "Epoch:[ 1 ] Batch: 57 / 937 Main Model Loss: 0.18174596 Interpreter Loss: 25399.883\n",
      "Epoch:[ 1 ] Batch: 58 / 937 Main Model Loss: 0.065598935 Interpreter Loss: 25204.094\n",
      "Epoch:[ 1 ] Batch: 59 / 937 Main Model Loss: 0.042070735 Interpreter Loss: 25296.355\n",
      "Epoch:[ 1 ] Batch: 60 / 937 Main Model Loss: 0.06246558 Interpreter Loss: 23399.516\n",
      "Epoch:[ 1 ] Batch: 61 / 937 Main Model Loss: 0.0072907964 Interpreter Loss: 23985.81\n",
      "Epoch:[ 1 ] Batch: 62 / 937 Main Model Loss: 0.049818836 Interpreter Loss: 24362.156\n",
      "Epoch:[ 1 ] Batch: 63 / 937 Main Model Loss: 0.017397147 Interpreter Loss: 24721.613\n",
      "Epoch:[ 1 ] Batch: 64 / 937 Main Model Loss: 0.017518612 Interpreter Loss: 24137.498\n",
      "Epoch:[ 1 ] Batch: 65 / 937 Main Model Loss: 0.0145494165 Interpreter Loss: 23871.746\n",
      "Epoch:[ 1 ] Batch: 66 / 937 Main Model Loss: 0.0401498 Interpreter Loss: 24908.137\n",
      "Epoch:[ 1 ] Batch: 67 / 937 Main Model Loss: 0.060706377 Interpreter Loss: 24726.902\n",
      "Epoch:[ 1 ] Batch: 68 / 937 Main Model Loss: 0.06875687 Interpreter Loss: 23669.184\n",
      "Epoch:[ 1 ] Batch: 69 / 937 Main Model Loss: 0.18091998 Interpreter Loss: 24160.402\n",
      "Epoch:[ 1 ] Batch: 70 / 937 Main Model Loss: 0.008935513 Interpreter Loss: 25038.49\n",
      "Epoch:[ 1 ] Batch: 71 / 937 Main Model Loss: 0.025624447 Interpreter Loss: 23901.562\n",
      "Epoch:[ 1 ] Batch: 72 / 937 Main Model Loss: 0.097670406 Interpreter Loss: 25684.47\n",
      "Epoch:[ 1 ] Batch: 73 / 937 Main Model Loss: 0.01551239 Interpreter Loss: 25140.543\n",
      "Epoch:[ 1 ] Batch: 74 / 937 Main Model Loss: 0.023084437 Interpreter Loss: 24244.75\n",
      "Epoch:[ 1 ] Batch: 75 / 937 Main Model Loss: 0.0334709 Interpreter Loss: 24613.55\n",
      "Epoch:[ 1 ] Batch: 76 / 937 Main Model Loss: 0.02336353 Interpreter Loss: 23991.79\n",
      "Epoch:[ 1 ] Batch: 77 / 937 Main Model Loss: 0.0876106 Interpreter Loss: 24049.14\n",
      "Epoch:[ 1 ] Batch: 78 / 937 Main Model Loss: 0.052694008 Interpreter Loss: 24171.338\n",
      "Epoch:[ 1 ] Batch: 79 / 937 Main Model Loss: 0.032507755 Interpreter Loss: 24543.256\n",
      "Epoch:[ 1 ] Batch: 80 / 937 Main Model Loss: 0.08278021 Interpreter Loss: 24803.678\n",
      "Epoch:[ 1 ] Batch: 81 / 937 Main Model Loss: 0.028017446 Interpreter Loss: 24242.0\n",
      "Epoch:[ 1 ] Batch: 82 / 937 Main Model Loss: 0.06851771 Interpreter Loss: 24009.887\n",
      "Epoch:[ 1 ] Batch: 83 / 937 Main Model Loss: 0.05303264 Interpreter Loss: 25301.607\n",
      "Epoch:[ 1 ] Batch: 84 / 937 Main Model Loss: 0.034742944 Interpreter Loss: 24719.754\n",
      "Epoch:[ 1 ] Batch: 85 / 937 Main Model Loss: 0.02217953 Interpreter Loss: 24274.06\n",
      "Epoch:[ 1 ] Batch: 86 / 937 Main Model Loss: 0.06398622 Interpreter Loss: 24803.234\n",
      "Epoch:[ 1 ] Batch: 87 / 937 Main Model Loss: 0.016077127 Interpreter Loss: 23807.855\n",
      "Epoch:[ 1 ] Batch: 88 / 937 Main Model Loss: 0.14248975 Interpreter Loss: 25051.824\n",
      "Epoch:[ 1 ] Batch: 89 / 937 Main Model Loss: 0.12607554 Interpreter Loss: 23761.383\n",
      "Epoch:[ 1 ] Batch: 90 / 937 Main Model Loss: 0.058570966 Interpreter Loss: 23426.602\n",
      "Epoch:[ 1 ] Batch: 91 / 937 Main Model Loss: 0.05290796 Interpreter Loss: 23653.025\n",
      "Epoch:[ 1 ] Batch: 92 / 937 Main Model Loss: 0.07177608 Interpreter Loss: 23172.281\n",
      "Epoch:[ 1 ] Batch: 93 / 937 Main Model Loss: 0.0147278905 Interpreter Loss: 24555.262\n",
      "Epoch:[ 1 ] Batch: 94 / 937 Main Model Loss: 0.09013706 Interpreter Loss: 24573.664\n",
      "Epoch:[ 1 ] Batch: 95 / 937 Main Model Loss: 0.15684222 Interpreter Loss: 24530.02\n",
      "Epoch:[ 1 ] Batch: 96 / 937 Main Model Loss: 0.015405841 Interpreter Loss: 24052.318\n",
      "Epoch:[ 1 ] Batch: 97 / 937 Main Model Loss: 0.05627131 Interpreter Loss: 24808.02\n",
      "Epoch:[ 1 ] Batch: 98 / 937 Main Model Loss: 0.04407207 Interpreter Loss: 23879.395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 1 ] Batch: 99 / 937 Main Model Loss: 0.04256729 Interpreter Loss: 23872.918\n",
      "Epoch:[ 1 ] Batch: 100 / 937 Main Model Loss: 0.120993584 Interpreter Loss: 23570.11\n",
      "Epoch:[ 1 ] Batch: 101 / 937 Main Model Loss: 0.030081531 Interpreter Loss: 22891.32\n",
      "Epoch:[ 1 ] Batch: 102 / 937 Main Model Loss: 0.015946122 Interpreter Loss: 22494.172\n",
      "Epoch:[ 1 ] Batch: 103 / 937 Main Model Loss: 0.023174595 Interpreter Loss: 23679.602\n",
      "Epoch:[ 1 ] Batch: 104 / 937 Main Model Loss: 0.048995435 Interpreter Loss: 22684.18\n",
      "Epoch:[ 1 ] Batch: 105 / 937 Main Model Loss: 0.024234755 Interpreter Loss: 22160.205\n",
      "Epoch:[ 1 ] Batch: 106 / 937 Main Model Loss: 0.119468346 Interpreter Loss: 22466.96\n",
      "Epoch:[ 1 ] Batch: 107 / 937 Main Model Loss: 0.13163926 Interpreter Loss: 24163.191\n",
      "Epoch:[ 1 ] Batch: 108 / 937 Main Model Loss: 0.029065717 Interpreter Loss: 24833.912\n",
      "Epoch:[ 1 ] Batch: 109 / 937 Main Model Loss: 0.13896284 Interpreter Loss: 24457.387\n",
      "Epoch:[ 1 ] Batch: 110 / 937 Main Model Loss: 0.042241566 Interpreter Loss: 22334.504\n",
      "Epoch:[ 1 ] Batch: 111 / 937 Main Model Loss: 0.047105238 Interpreter Loss: 22703.01\n",
      "Epoch:[ 1 ] Batch: 112 / 937 Main Model Loss: 0.05966628 Interpreter Loss: 22808.77\n",
      "Epoch:[ 1 ] Batch: 113 / 937 Main Model Loss: 0.20239279 Interpreter Loss: 23350.688\n",
      "Epoch:[ 1 ] Batch: 114 / 937 Main Model Loss: 0.032151155 Interpreter Loss: 22629.207\n",
      "Epoch:[ 1 ] Batch: 115 / 937 Main Model Loss: 0.011272484 Interpreter Loss: 21486.521\n",
      "Epoch:[ 1 ] Batch: 116 / 937 Main Model Loss: 0.024292877 Interpreter Loss: 22298.307\n",
      "Epoch:[ 1 ] Batch: 117 / 937 Main Model Loss: 0.04452898 Interpreter Loss: 22104.82\n",
      "Epoch:[ 1 ] Batch: 118 / 937 Main Model Loss: 0.09923929 Interpreter Loss: 22226.758\n",
      "Epoch:[ 1 ] Batch: 119 / 937 Main Model Loss: 0.06064497 Interpreter Loss: 22562.287\n",
      "Epoch:[ 1 ] Batch: 120 / 937 Main Model Loss: 0.041795373 Interpreter Loss: 23011.791\n",
      "Epoch:[ 1 ] Batch: 121 / 937 Main Model Loss: 0.040594332 Interpreter Loss: 23284.562\n",
      "Epoch:[ 1 ] Batch: 122 / 937 Main Model Loss: 0.05422449 Interpreter Loss: 23060.262\n",
      "Epoch:[ 1 ] Batch: 123 / 937 Main Model Loss: 0.06627623 Interpreter Loss: 24180.572\n",
      "Epoch:[ 1 ] Batch: 124 / 937 Main Model Loss: 0.06254629 Interpreter Loss: 23207.707\n",
      "Epoch:[ 1 ] Batch: 125 / 937 Main Model Loss: 0.035266243 Interpreter Loss: 23064.834\n",
      "Epoch:[ 1 ] Batch: 126 / 937 Main Model Loss: 0.14216271 Interpreter Loss: 24001.057\n",
      "Epoch:[ 1 ] Batch: 127 / 937 Main Model Loss: 0.0195219 Interpreter Loss: 21562.12\n",
      "Epoch:[ 1 ] Batch: 128 / 937 Main Model Loss: 0.27411333 Interpreter Loss: 23516.988\n",
      "Epoch:[ 1 ] Batch: 129 / 937 Main Model Loss: 0.04810752 Interpreter Loss: 23561.39\n",
      "Epoch:[ 1 ] Batch: 130 / 937 Main Model Loss: 0.023701768 Interpreter Loss: 22299.688\n",
      "Epoch:[ 1 ] Batch: 131 / 937 Main Model Loss: 0.029868925 Interpreter Loss: 22133.328\n",
      "Epoch:[ 1 ] Batch: 132 / 937 Main Model Loss: 0.087703586 Interpreter Loss: 24947.684\n",
      "Epoch:[ 1 ] Batch: 133 / 937 Main Model Loss: 0.012098234 Interpreter Loss: 23145.473\n",
      "Epoch:[ 1 ] Batch: 134 / 937 Main Model Loss: 0.013087222 Interpreter Loss: 23675.367\n",
      "Epoch:[ 1 ] Batch: 135 / 937 Main Model Loss: 0.06622542 Interpreter Loss: 25154.2\n",
      "Epoch:[ 1 ] Batch: 136 / 937 Main Model Loss: 0.29656768 Interpreter Loss: 24030.559\n",
      "Epoch:[ 1 ] Batch: 137 / 937 Main Model Loss: 0.05765669 Interpreter Loss: 23072.508\n",
      "Epoch:[ 1 ] Batch: 138 / 937 Main Model Loss: 0.2145272 Interpreter Loss: 24058.723\n",
      "Epoch:[ 1 ] Batch: 139 / 937 Main Model Loss: 0.05102843 Interpreter Loss: 22582.566\n",
      "Epoch:[ 1 ] Batch: 140 / 937 Main Model Loss: 0.055926293 Interpreter Loss: 21791.932\n",
      "Epoch:[ 1 ] Batch: 141 / 937 Main Model Loss: 0.019233067 Interpreter Loss: 21702.371\n",
      "Epoch:[ 1 ] Batch: 142 / 937 Main Model Loss: 0.032035418 Interpreter Loss: 21928.102\n",
      "Epoch:[ 1 ] Batch: 143 / 937 Main Model Loss: 0.022191608 Interpreter Loss: 21808.566\n",
      "Epoch:[ 1 ] Batch: 144 / 937 Main Model Loss: 0.08379459 Interpreter Loss: 21500.465\n",
      "Epoch:[ 1 ] Batch: 145 / 937 Main Model Loss: 0.040934637 Interpreter Loss: 22186.996\n",
      "Epoch:[ 1 ] Batch: 146 / 937 Main Model Loss: 0.10237602 Interpreter Loss: 24187.348\n",
      "Epoch:[ 1 ] Batch: 147 / 937 Main Model Loss: 0.07457189 Interpreter Loss: 23197.918\n",
      "Epoch:[ 1 ] Batch: 148 / 937 Main Model Loss: 0.050730694 Interpreter Loss: 23379.625\n",
      "Epoch:[ 1 ] Batch: 149 / 937 Main Model Loss: 0.025845133 Interpreter Loss: 21607.223\n",
      "Epoch:[ 1 ] Batch: 150 / 937 Main Model Loss: 0.102337316 Interpreter Loss: 22786.002\n",
      "Epoch:[ 1 ] Batch: 151 / 937 Main Model Loss: 0.011298976 Interpreter Loss: 22040.137\n",
      "Epoch:[ 1 ] Batch: 152 / 937 Main Model Loss: 0.100008175 Interpreter Loss: 23494.61\n",
      "Epoch:[ 1 ] Batch: 153 / 937 Main Model Loss: 0.011974438 Interpreter Loss: 21285.54\n",
      "Epoch:[ 1 ] Batch: 154 / 937 Main Model Loss: 0.006672102 Interpreter Loss: 21439.352\n",
      "Epoch:[ 1 ] Batch: 155 / 937 Main Model Loss: 0.014220632 Interpreter Loss: 21974.896\n",
      "Epoch:[ 1 ] Batch: 156 / 937 Main Model Loss: 0.06854602 Interpreter Loss: 22109.621\n",
      "Epoch:[ 1 ] Batch: 157 / 937 Main Model Loss: 0.13985915 Interpreter Loss: 21785.127\n",
      "Epoch:[ 1 ] Batch: 158 / 937 Main Model Loss: 0.09193672 Interpreter Loss: 20815.865\n",
      "Epoch:[ 1 ] Batch: 159 / 937 Main Model Loss: 0.1424423 Interpreter Loss: 25014.797\n",
      "Epoch:[ 1 ] Batch: 160 / 937 Main Model Loss: 0.24021728 Interpreter Loss: 25216.383\n",
      "Epoch:[ 1 ] Batch: 161 / 937 Main Model Loss: 0.020073557 Interpreter Loss: 22400.445\n",
      "Epoch:[ 1 ] Batch: 162 / 937 Main Model Loss: 0.023563072 Interpreter Loss: 21846.14\n",
      "Epoch:[ 1 ] Batch: 163 / 937 Main Model Loss: 0.00824606 Interpreter Loss: 22191.527\n",
      "Epoch:[ 1 ] Batch: 164 / 937 Main Model Loss: 0.015548822 Interpreter Loss: 21802.053\n",
      "Epoch:[ 1 ] Batch: 165 / 937 Main Model Loss: 0.0055516837 Interpreter Loss: 21018.033\n",
      "Epoch:[ 1 ] Batch: 166 / 937 Main Model Loss: 0.0052391123 Interpreter Loss: 20679.562\n",
      "Epoch:[ 1 ] Batch: 167 / 937 Main Model Loss: 0.024197286 Interpreter Loss: 21742.785\n",
      "Epoch:[ 1 ] Batch: 168 / 937 Main Model Loss: 0.13979414 Interpreter Loss: 22633.477\n",
      "Epoch:[ 1 ] Batch: 169 / 937 Main Model Loss: 0.08777353 Interpreter Loss: 21862.938\n",
      "Epoch:[ 1 ] Batch: 170 / 937 Main Model Loss: 0.03967243 Interpreter Loss: 21653.8\n",
      "Epoch:[ 1 ] Batch: 171 / 937 Main Model Loss: 0.13799632 Interpreter Loss: 22559.473\n",
      "Epoch:[ 1 ] Batch: 172 / 937 Main Model Loss: 0.056075007 Interpreter Loss: 22010.402\n",
      "Epoch:[ 1 ] Batch: 173 / 937 Main Model Loss: 0.03174866 Interpreter Loss: 21638.125\n",
      "Epoch:[ 1 ] Batch: 174 / 937 Main Model Loss: 0.036435794 Interpreter Loss: 21268.725\n",
      "Epoch:[ 1 ] Batch: 175 / 937 Main Model Loss: 0.107341796 Interpreter Loss: 21335.787\n",
      "Epoch:[ 1 ] Batch: 176 / 937 Main Model Loss: 0.0076173875 Interpreter Loss: 20677.773\n",
      "Epoch:[ 1 ] Batch: 177 / 937 Main Model Loss: 0.03852247 Interpreter Loss: 21675.318\n",
      "Epoch:[ 1 ] Batch: 178 / 937 Main Model Loss: 0.025951987 Interpreter Loss: 21129.398\n",
      "Epoch:[ 1 ] Batch: 179 / 937 Main Model Loss: 0.018374551 Interpreter Loss: 21072.797\n",
      "Epoch:[ 1 ] Batch: 180 / 937 Main Model Loss: 0.048421677 Interpreter Loss: 22257.102\n",
      "Epoch:[ 1 ] Batch: 181 / 937 Main Model Loss: 0.115212396 Interpreter Loss: 21848.508\n",
      "Epoch:[ 1 ] Batch: 182 / 937 Main Model Loss: 0.08002027 Interpreter Loss: 21691.361\n",
      "Epoch:[ 1 ] Batch: 183 / 937 Main Model Loss: 0.076856524 Interpreter Loss: 21733.55\n",
      "Epoch:[ 1 ] Batch: 184 / 937 Main Model Loss: 0.04961127 Interpreter Loss: 21734.324\n",
      "Epoch:[ 1 ] Batch: 185 / 937 Main Model Loss: 0.08061127 Interpreter Loss: 21683.645\n",
      "Epoch:[ 1 ] Batch: 186 / 937 Main Model Loss: 0.035262764 Interpreter Loss: 20862.434\n",
      "Epoch:[ 1 ] Batch: 187 / 937 Main Model Loss: 0.041979942 Interpreter Loss: 21873.23\n",
      "Epoch:[ 1 ] Batch: 188 / 937 Main Model Loss: 0.036848526 Interpreter Loss: 21812.967\n",
      "Epoch:[ 1 ] Batch: 189 / 937 Main Model Loss: 0.021361869 Interpreter Loss: 21096.59\n",
      "Epoch:[ 1 ] Batch: 190 / 937 Main Model Loss: 0.053778354 Interpreter Loss: 21177.355\n",
      "Epoch:[ 1 ] Batch: 191 / 937 Main Model Loss: 0.065625235 Interpreter Loss: 22084.861\n",
      "Epoch:[ 1 ] Batch: 192 / 937 Main Model Loss: 0.08962738 Interpreter Loss: 21489.953\n",
      "Epoch:[ 1 ] Batch: 193 / 937 Main Model Loss: 0.02380324 Interpreter Loss: 21636.414\n",
      "Epoch:[ 1 ] Batch: 194 / 937 Main Model Loss: 0.02702764 Interpreter Loss: 21586.48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 1 ] Batch: 195 / 937 Main Model Loss: 0.011604855 Interpreter Loss: 21116.871\n",
      "Epoch:[ 1 ] Batch: 196 / 937 Main Model Loss: 0.13463861 Interpreter Loss: 22058.617\n",
      "Epoch:[ 1 ] Batch: 197 / 937 Main Model Loss: 0.102165155 Interpreter Loss: 21936.729\n",
      "Epoch:[ 1 ] Batch: 198 / 937 Main Model Loss: 0.15181908 Interpreter Loss: 21062.79\n",
      "Epoch:[ 1 ] Batch: 199 / 937 Main Model Loss: 0.042141873 Interpreter Loss: 20594.066\n",
      "Epoch:[ 1 ] Batch: 200 / 937 Main Model Loss: 0.045547344 Interpreter Loss: 20495.084\n",
      "Epoch:[ 1 ] Batch: 201 / 937 Main Model Loss: 0.070393905 Interpreter Loss: 20806.914\n",
      "Epoch:[ 1 ] Batch: 202 / 937 Main Model Loss: 0.065543845 Interpreter Loss: 22392.656\n",
      "Epoch:[ 1 ] Batch: 203 / 937 Main Model Loss: 0.10371567 Interpreter Loss: 22131.754\n",
      "Epoch:[ 1 ] Batch: 204 / 937 Main Model Loss: 0.035735134 Interpreter Loss: 22953.889\n",
      "Epoch:[ 1 ] Batch: 205 / 937 Main Model Loss: 0.034591272 Interpreter Loss: 21918.45\n",
      "Epoch:[ 1 ] Batch: 206 / 937 Main Model Loss: 0.020888828 Interpreter Loss: 21544.385\n",
      "Epoch:[ 1 ] Batch: 207 / 937 Main Model Loss: 0.026272986 Interpreter Loss: 21119.34\n",
      "Epoch:[ 1 ] Batch: 208 / 937 Main Model Loss: 0.019481223 Interpreter Loss: 20996.805\n",
      "Epoch:[ 1 ] Batch: 209 / 937 Main Model Loss: 0.10515297 Interpreter Loss: 21155.426\n",
      "Epoch:[ 1 ] Batch: 210 / 937 Main Model Loss: 0.014575683 Interpreter Loss: 21038.238\n",
      "Epoch:[ 1 ] Batch: 211 / 937 Main Model Loss: 0.12572625 Interpreter Loss: 21765.156\n",
      "Epoch:[ 1 ] Batch: 212 / 937 Main Model Loss: 0.014795253 Interpreter Loss: 20759.79\n",
      "Epoch:[ 1 ] Batch: 213 / 937 Main Model Loss: 0.08028242 Interpreter Loss: 20782.988\n",
      "Epoch:[ 1 ] Batch: 214 / 937 Main Model Loss: 0.025997771 Interpreter Loss: 20216.469\n",
      "Epoch:[ 1 ] Batch: 215 / 937 Main Model Loss: 0.03212605 Interpreter Loss: 20146.922\n",
      "Epoch:[ 1 ] Batch: 216 / 937 Main Model Loss: 0.10536613 Interpreter Loss: 20863.586\n",
      "Epoch:[ 1 ] Batch: 217 / 937 Main Model Loss: 0.05401338 Interpreter Loss: 21419.105\n",
      "Epoch:[ 1 ] Batch: 218 / 937 Main Model Loss: 0.22785163 Interpreter Loss: 20095.352\n",
      "Epoch:[ 1 ] Batch: 219 / 937 Main Model Loss: 0.010382625 Interpreter Loss: 21257.527\n",
      "Epoch:[ 1 ] Batch: 220 / 937 Main Model Loss: 0.017862216 Interpreter Loss: 21711.75\n",
      "Epoch:[ 1 ] Batch: 221 / 937 Main Model Loss: 0.02062532 Interpreter Loss: 22016.373\n",
      "Epoch:[ 1 ] Batch: 222 / 937 Main Model Loss: 0.10225727 Interpreter Loss: 21131.773\n",
      "Epoch:[ 1 ] Batch: 223 / 937 Main Model Loss: 0.051493756 Interpreter Loss: 21635.77\n",
      "Epoch:[ 1 ] Batch: 224 / 937 Main Model Loss: 0.16545817 Interpreter Loss: 21955.477\n",
      "Epoch:[ 1 ] Batch: 225 / 937 Main Model Loss: 0.0530875 Interpreter Loss: 19942.71\n",
      "Epoch:[ 1 ] Batch: 226 / 937 Main Model Loss: 0.020277988 Interpreter Loss: 19874.922\n",
      "Epoch:[ 1 ] Batch: 227 / 937 Main Model Loss: 0.1533683 Interpreter Loss: 20181.154\n",
      "Epoch:[ 1 ] Batch: 228 / 937 Main Model Loss: 0.028719064 Interpreter Loss: 20564.926\n",
      "Epoch:[ 1 ] Batch: 229 / 937 Main Model Loss: 0.045941237 Interpreter Loss: 21446.033\n",
      "Epoch:[ 1 ] Batch: 230 / 937 Main Model Loss: 0.065247804 Interpreter Loss: 21284.81\n",
      "Epoch:[ 1 ] Batch: 231 / 937 Main Model Loss: 0.08327313 Interpreter Loss: 20396.95\n",
      "Epoch:[ 1 ] Batch: 232 / 937 Main Model Loss: 0.0335376 Interpreter Loss: 20583.873\n",
      "Epoch:[ 1 ] Batch: 233 / 937 Main Model Loss: 0.029722616 Interpreter Loss: 19923.281\n",
      "Epoch:[ 1 ] Batch: 234 / 937 Main Model Loss: 0.004677858 Interpreter Loss: 18918.582\n",
      "Epoch:[ 1 ] Batch: 235 / 937 Main Model Loss: 0.016998537 Interpreter Loss: 20058.34\n",
      "Epoch:[ 1 ] Batch: 236 / 937 Main Model Loss: 0.12217326 Interpreter Loss: 19858.89\n",
      "Epoch:[ 1 ] Batch: 237 / 937 Main Model Loss: 0.034496956 Interpreter Loss: 19729.852\n",
      "Epoch:[ 1 ] Batch: 238 / 937 Main Model Loss: 0.06687552 Interpreter Loss: 19926.545\n",
      "Epoch:[ 1 ] Batch: 239 / 937 Main Model Loss: 0.060284983 Interpreter Loss: 19490.43\n",
      "Epoch:[ 1 ] Batch: 240 / 937 Main Model Loss: 0.025540594 Interpreter Loss: 19819.234\n",
      "Epoch:[ 1 ] Batch: 241 / 937 Main Model Loss: 0.076754466 Interpreter Loss: 18800.756\n",
      "Epoch:[ 1 ] Batch: 242 / 937 Main Model Loss: 0.03908155 Interpreter Loss: 20919.465\n",
      "Epoch:[ 1 ] Batch: 243 / 937 Main Model Loss: 0.022410803 Interpreter Loss: 20094.4\n",
      "Epoch:[ 1 ] Batch: 244 / 937 Main Model Loss: 0.017375749 Interpreter Loss: 19822.959\n",
      "Epoch:[ 1 ] Batch: 245 / 937 Main Model Loss: 0.044267252 Interpreter Loss: 20369.506\n",
      "Epoch:[ 1 ] Batch: 246 / 937 Main Model Loss: 0.14135316 Interpreter Loss: 21042.062\n",
      "Epoch:[ 1 ] Batch: 247 / 937 Main Model Loss: 0.04047218 Interpreter Loss: 20195.32\n",
      "Epoch:[ 1 ] Batch: 248 / 937 Main Model Loss: 0.030623583 Interpreter Loss: 20547.984\n",
      "Epoch:[ 1 ] Batch: 249 / 937 Main Model Loss: 0.060251553 Interpreter Loss: 20613.98\n",
      "Epoch:[ 1 ] Batch: 250 / 937 Main Model Loss: 0.04128577 Interpreter Loss: 21202.24\n",
      "Epoch:[ 1 ] Batch: 251 / 937 Main Model Loss: 0.018577911 Interpreter Loss: 20516.254\n",
      "Epoch:[ 1 ] Batch: 252 / 937 Main Model Loss: 0.03337176 Interpreter Loss: 19926.941\n",
      "Epoch:[ 1 ] Batch: 253 / 937 Main Model Loss: 0.02027186 Interpreter Loss: 19956.693\n",
      "Epoch:[ 1 ] Batch: 254 / 937 Main Model Loss: 0.03042529 Interpreter Loss: 19859.938\n",
      "Epoch:[ 1 ] Batch: 255 / 937 Main Model Loss: 0.022560786 Interpreter Loss: 19767.416\n",
      "Epoch:[ 1 ] Batch: 256 / 937 Main Model Loss: 0.01766455 Interpreter Loss: 19470.55\n",
      "Epoch:[ 1 ] Batch: 257 / 937 Main Model Loss: 0.058494944 Interpreter Loss: 19797.73\n",
      "Epoch:[ 1 ] Batch: 258 / 937 Main Model Loss: 0.08914364 Interpreter Loss: 19615.953\n",
      "Epoch:[ 1 ] Batch: 259 / 937 Main Model Loss: 0.007245767 Interpreter Loss: 18871.234\n",
      "Epoch:[ 1 ] Batch: 260 / 937 Main Model Loss: 0.08267591 Interpreter Loss: 20428.893\n",
      "Epoch:[ 1 ] Batch: 261 / 937 Main Model Loss: 0.067873545 Interpreter Loss: 19985.4\n",
      "Epoch:[ 1 ] Batch: 262 / 937 Main Model Loss: 0.020018702 Interpreter Loss: 19698.613\n",
      "Epoch:[ 1 ] Batch: 263 / 937 Main Model Loss: 0.053858675 Interpreter Loss: 19369.57\n",
      "Epoch:[ 1 ] Batch: 264 / 937 Main Model Loss: 0.02131182 Interpreter Loss: 19422.625\n",
      "Epoch:[ 1 ] Batch: 265 / 937 Main Model Loss: 0.09166833 Interpreter Loss: 20140.902\n",
      "Epoch:[ 1 ] Batch: 266 / 937 Main Model Loss: 0.0731346 Interpreter Loss: 19479.004\n",
      "Epoch:[ 1 ] Batch: 267 / 937 Main Model Loss: 0.102681056 Interpreter Loss: 20017.63\n",
      "Epoch:[ 1 ] Batch: 268 / 937 Main Model Loss: 0.08467208 Interpreter Loss: 20508.87\n",
      "Epoch:[ 1 ] Batch: 269 / 937 Main Model Loss: 0.051963273 Interpreter Loss: 20390.736\n",
      "Epoch:[ 1 ] Batch: 270 / 937 Main Model Loss: 0.015506656 Interpreter Loss: 20086.457\n",
      "Epoch:[ 1 ] Batch: 271 / 937 Main Model Loss: 0.032955945 Interpreter Loss: 19451.354\n",
      "Epoch:[ 1 ] Batch: 272 / 937 Main Model Loss: 0.06950365 Interpreter Loss: 20791.254\n",
      "Epoch:[ 1 ] Batch: 273 / 937 Main Model Loss: 0.04103855 Interpreter Loss: 19609.336\n",
      "Epoch:[ 1 ] Batch: 274 / 937 Main Model Loss: 0.1392331 Interpreter Loss: 19436.637\n",
      "Epoch:[ 1 ] Batch: 275 / 937 Main Model Loss: 0.020515714 Interpreter Loss: 18882.521\n",
      "Epoch:[ 1 ] Batch: 276 / 937 Main Model Loss: 0.06708812 Interpreter Loss: 19486.84\n",
      "Epoch:[ 1 ] Batch: 277 / 937 Main Model Loss: 0.0732949 Interpreter Loss: 20820.877\n",
      "Epoch:[ 1 ] Batch: 278 / 937 Main Model Loss: 0.114856474 Interpreter Loss: 18987.3\n",
      "Epoch:[ 1 ] Batch: 279 / 937 Main Model Loss: 0.029186677 Interpreter Loss: 18603.932\n",
      "Epoch:[ 1 ] Batch: 280 / 937 Main Model Loss: 0.028303657 Interpreter Loss: 19472.754\n",
      "Epoch:[ 1 ] Batch: 281 / 937 Main Model Loss: 0.09514166 Interpreter Loss: 19035.846\n",
      "Epoch:[ 1 ] Batch: 282 / 937 Main Model Loss: 0.05143566 Interpreter Loss: 18782.426\n",
      "Epoch:[ 1 ] Batch: 283 / 937 Main Model Loss: 0.12476459 Interpreter Loss: 19405.139\n",
      "Epoch:[ 1 ] Batch: 284 / 937 Main Model Loss: 0.023685396 Interpreter Loss: 19510.777\n",
      "Epoch:[ 1 ] Batch: 285 / 937 Main Model Loss: 0.01175976 Interpreter Loss: 18828.988\n",
      "Epoch:[ 1 ] Batch: 286 / 937 Main Model Loss: 0.13688223 Interpreter Loss: 18396.809\n",
      "Epoch:[ 1 ] Batch: 287 / 937 Main Model Loss: 0.046054594 Interpreter Loss: 19376.848\n",
      "Epoch:[ 1 ] Batch: 288 / 937 Main Model Loss: 0.062967464 Interpreter Loss: 19148.346\n",
      "Epoch:[ 1 ] Batch: 289 / 937 Main Model Loss: 0.028830864 Interpreter Loss: 19093.762\n",
      "Epoch:[ 1 ] Batch: 290 / 937 Main Model Loss: 0.07950239 Interpreter Loss: 19852.844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 1 ] Batch: 291 / 937 Main Model Loss: 0.0282553 Interpreter Loss: 18947.904\n",
      "Epoch:[ 1 ] Batch: 292 / 937 Main Model Loss: 0.041235644 Interpreter Loss: 18932.506\n",
      "Epoch:[ 1 ] Batch: 293 / 937 Main Model Loss: 0.012303619 Interpreter Loss: 18683.715\n",
      "Epoch:[ 1 ] Batch: 294 / 937 Main Model Loss: 0.02127012 Interpreter Loss: 19275.293\n",
      "Epoch:[ 1 ] Batch: 295 / 937 Main Model Loss: 0.007146788 Interpreter Loss: 18425.508\n",
      "Epoch:[ 1 ] Batch: 296 / 937 Main Model Loss: 0.02372254 Interpreter Loss: 18587.195\n",
      "Epoch:[ 1 ] Batch: 297 / 937 Main Model Loss: 0.03228046 Interpreter Loss: 17850.111\n",
      "Epoch:[ 1 ] Batch: 298 / 937 Main Model Loss: 0.1787382 Interpreter Loss: 18307.102\n",
      "Epoch:[ 1 ] Batch: 299 / 937 Main Model Loss: 0.013895784 Interpreter Loss: 18097.914\n",
      "Epoch:[ 1 ] Batch: 300 / 937 Main Model Loss: 0.042885166 Interpreter Loss: 20314.152\n",
      "Epoch:[ 1 ] Batch: 301 / 937 Main Model Loss: 0.022730425 Interpreter Loss: 19102.873\n",
      "Epoch:[ 1 ] Batch: 302 / 937 Main Model Loss: 0.1467475 Interpreter Loss: 20638.691\n",
      "Epoch:[ 1 ] Batch: 303 / 937 Main Model Loss: 0.073443204 Interpreter Loss: 20820.11\n",
      "Epoch:[ 1 ] Batch: 304 / 937 Main Model Loss: 0.06693784 Interpreter Loss: 19871.625\n",
      "Epoch:[ 1 ] Batch: 305 / 937 Main Model Loss: 0.03387413 Interpreter Loss: 20704.203\n",
      "Epoch:[ 1 ] Batch: 306 / 937 Main Model Loss: 0.024100421 Interpreter Loss: 19713.604\n",
      "Epoch:[ 1 ] Batch: 307 / 937 Main Model Loss: 0.017800275 Interpreter Loss: 19157.031\n",
      "Epoch:[ 1 ] Batch: 308 / 937 Main Model Loss: 0.02519446 Interpreter Loss: 19235.861\n",
      "Epoch:[ 1 ] Batch: 309 / 937 Main Model Loss: 0.020328466 Interpreter Loss: 19710.523\n",
      "Epoch:[ 1 ] Batch: 310 / 937 Main Model Loss: 0.05254389 Interpreter Loss: 19672.078\n",
      "Epoch:[ 1 ] Batch: 311 / 937 Main Model Loss: 0.020317847 Interpreter Loss: 19438.543\n",
      "Epoch:[ 1 ] Batch: 312 / 937 Main Model Loss: 0.040107153 Interpreter Loss: 19784.04\n",
      "Epoch:[ 1 ] Batch: 313 / 937 Main Model Loss: 0.059439093 Interpreter Loss: 19495.844\n",
      "Epoch:[ 1 ] Batch: 314 / 937 Main Model Loss: 0.03806853 Interpreter Loss: 19632.459\n",
      "Epoch:[ 1 ] Batch: 315 / 937 Main Model Loss: 0.046341836 Interpreter Loss: 20029.445\n",
      "Epoch:[ 1 ] Batch: 316 / 937 Main Model Loss: 0.025122363 Interpreter Loss: 18937.508\n",
      "Epoch:[ 1 ] Batch: 317 / 937 Main Model Loss: 0.07249436 Interpreter Loss: 18199.852\n",
      "Epoch:[ 1 ] Batch: 318 / 937 Main Model Loss: 0.0052127377 Interpreter Loss: 18733.047\n",
      "Epoch:[ 1 ] Batch: 319 / 937 Main Model Loss: 0.037130494 Interpreter Loss: 18115.402\n",
      "Epoch:[ 1 ] Batch: 320 / 937 Main Model Loss: 0.0076974398 Interpreter Loss: 18925.592\n",
      "Epoch:[ 1 ] Batch: 321 / 937 Main Model Loss: 0.027001536 Interpreter Loss: 18700.664\n",
      "Epoch:[ 1 ] Batch: 322 / 937 Main Model Loss: 0.039863624 Interpreter Loss: 19471.93\n",
      "Epoch:[ 1 ] Batch: 323 / 937 Main Model Loss: 0.22276846 Interpreter Loss: 19131.66\n",
      "Epoch:[ 1 ] Batch: 324 / 937 Main Model Loss: 0.119792484 Interpreter Loss: 18544.11\n",
      "Epoch:[ 1 ] Batch: 325 / 937 Main Model Loss: 0.06786347 Interpreter Loss: 20020.86\n",
      "Epoch:[ 1 ] Batch: 326 / 937 Main Model Loss: 0.0853118 Interpreter Loss: 19533.771\n",
      "Epoch:[ 1 ] Batch: 327 / 937 Main Model Loss: 0.034200486 Interpreter Loss: 20736.621\n",
      "Epoch:[ 1 ] Batch: 328 / 937 Main Model Loss: 0.06769434 Interpreter Loss: 18848.434\n",
      "Epoch:[ 1 ] Batch: 329 / 937 Main Model Loss: 0.01526878 Interpreter Loss: 17495.402\n",
      "Epoch:[ 1 ] Batch: 330 / 937 Main Model Loss: 0.090528384 Interpreter Loss: 18779.055\n",
      "Epoch:[ 1 ] Batch: 331 / 937 Main Model Loss: 0.032019466 Interpreter Loss: 18319.156\n",
      "Epoch:[ 1 ] Batch: 332 / 937 Main Model Loss: 0.030953035 Interpreter Loss: 18942.44\n",
      "Epoch:[ 1 ] Batch: 333 / 937 Main Model Loss: 0.041555338 Interpreter Loss: 19122.152\n",
      "Epoch:[ 1 ] Batch: 334 / 937 Main Model Loss: 0.024875443 Interpreter Loss: 19404.838\n",
      "Epoch:[ 1 ] Batch: 335 / 937 Main Model Loss: 0.026412979 Interpreter Loss: 19185.75\n",
      "Epoch:[ 1 ] Batch: 336 / 937 Main Model Loss: 0.03217568 Interpreter Loss: 19143.463\n",
      "Epoch:[ 1 ] Batch: 337 / 937 Main Model Loss: 0.09572855 Interpreter Loss: 18031.348\n",
      "Epoch:[ 1 ] Batch: 338 / 937 Main Model Loss: 0.019867163 Interpreter Loss: 18610.203\n",
      "Epoch:[ 1 ] Batch: 339 / 937 Main Model Loss: 0.03570509 Interpreter Loss: 17481.879\n",
      "Epoch:[ 1 ] Batch: 340 / 937 Main Model Loss: 0.033579085 Interpreter Loss: 19954.938\n",
      "Epoch:[ 1 ] Batch: 341 / 937 Main Model Loss: 0.011260797 Interpreter Loss: 19306.777\n",
      "Epoch:[ 1 ] Batch: 342 / 937 Main Model Loss: 0.050382648 Interpreter Loss: 19990.63\n",
      "Epoch:[ 1 ] Batch: 343 / 937 Main Model Loss: 0.021697372 Interpreter Loss: 19481.832\n",
      "Epoch:[ 1 ] Batch: 344 / 937 Main Model Loss: 0.019660357 Interpreter Loss: 18361.277\n",
      "Epoch:[ 1 ] Batch: 345 / 937 Main Model Loss: 0.014793487 Interpreter Loss: 18827.86\n",
      "Epoch:[ 1 ] Batch: 346 / 937 Main Model Loss: 0.0808712 Interpreter Loss: 18527.547\n",
      "Epoch:[ 1 ] Batch: 347 / 937 Main Model Loss: 0.051136672 Interpreter Loss: 18243.922\n",
      "Epoch:[ 1 ] Batch: 348 / 937 Main Model Loss: 0.027596932 Interpreter Loss: 18140.654\n",
      "Epoch:[ 1 ] Batch: 349 / 937 Main Model Loss: 0.014986123 Interpreter Loss: 17948.678\n",
      "Epoch:[ 1 ] Batch: 350 / 937 Main Model Loss: 0.03705707 Interpreter Loss: 18602.86\n",
      "Epoch:[ 1 ] Batch: 351 / 937 Main Model Loss: 0.06832168 Interpreter Loss: 19700.82\n",
      "Epoch:[ 1 ] Batch: 352 / 937 Main Model Loss: 0.042093612 Interpreter Loss: 19845.139\n",
      "Epoch:[ 1 ] Batch: 353 / 937 Main Model Loss: 0.053005673 Interpreter Loss: 20391.715\n",
      "Epoch:[ 1 ] Batch: 354 / 937 Main Model Loss: 0.020776426 Interpreter Loss: 19553.605\n",
      "Epoch:[ 1 ] Batch: 355 / 937 Main Model Loss: 0.020909682 Interpreter Loss: 19300.91\n",
      "Epoch:[ 1 ] Batch: 356 / 937 Main Model Loss: 0.012100596 Interpreter Loss: 18838.441\n",
      "Epoch:[ 1 ] Batch: 357 / 937 Main Model Loss: 0.04470931 Interpreter Loss: 18674.156\n",
      "Epoch:[ 1 ] Batch: 358 / 937 Main Model Loss: 0.003488571 Interpreter Loss: 18513.736\n",
      "Epoch:[ 1 ] Batch: 359 / 937 Main Model Loss: 0.011488736 Interpreter Loss: 18609.973\n",
      "Epoch:[ 1 ] Batch: 360 / 937 Main Model Loss: 0.04306125 Interpreter Loss: 20124.516\n",
      "Epoch:[ 1 ] Batch: 361 / 937 Main Model Loss: 0.014406871 Interpreter Loss: 18744.32\n",
      "Epoch:[ 1 ] Batch: 362 / 937 Main Model Loss: 0.060961362 Interpreter Loss: 18462.934\n",
      "Epoch:[ 1 ] Batch: 363 / 937 Main Model Loss: 0.006782323 Interpreter Loss: 17991.498\n",
      "Epoch:[ 1 ] Batch: 364 / 937 Main Model Loss: 0.016975204 Interpreter Loss: 18114.129\n",
      "Epoch:[ 1 ] Batch: 365 / 937 Main Model Loss: 0.04490644 Interpreter Loss: 18517.48\n",
      "Epoch:[ 1 ] Batch: 366 / 937 Main Model Loss: 0.024591275 Interpreter Loss: 18013.275\n",
      "Epoch:[ 1 ] Batch: 367 / 937 Main Model Loss: 0.040679373 Interpreter Loss: 18013.43\n",
      "Epoch:[ 1 ] Batch: 368 / 937 Main Model Loss: 0.053151127 Interpreter Loss: 17664.102\n",
      "Epoch:[ 1 ] Batch: 369 / 937 Main Model Loss: 0.06733524 Interpreter Loss: 17273.332\n",
      "Epoch:[ 1 ] Batch: 370 / 937 Main Model Loss: 0.031175002 Interpreter Loss: 18741.857\n",
      "Epoch:[ 1 ] Batch: 371 / 937 Main Model Loss: 0.0078987675 Interpreter Loss: 18543.852\n",
      "Epoch:[ 1 ] Batch: 372 / 937 Main Model Loss: 0.073160835 Interpreter Loss: 18570.77\n",
      "Epoch:[ 1 ] Batch: 373 / 937 Main Model Loss: 0.09315329 Interpreter Loss: 17724.701\n",
      "Epoch:[ 1 ] Batch: 374 / 937 Main Model Loss: 0.055604648 Interpreter Loss: 18215.09\n",
      "Epoch:[ 1 ] Batch: 375 / 937 Main Model Loss: 0.04618766 Interpreter Loss: 18361.56\n",
      "Epoch:[ 1 ] Batch: 376 / 937 Main Model Loss: 0.020298101 Interpreter Loss: 18912.627\n",
      "Epoch:[ 1 ] Batch: 377 / 937 Main Model Loss: 0.012741598 Interpreter Loss: 17705.488\n",
      "Epoch:[ 1 ] Batch: 378 / 937 Main Model Loss: 0.027213503 Interpreter Loss: 18471.639\n",
      "Epoch:[ 1 ] Batch: 379 / 937 Main Model Loss: 0.022245366 Interpreter Loss: 19283.701\n",
      "Epoch:[ 1 ] Batch: 380 / 937 Main Model Loss: 0.0048500346 Interpreter Loss: 16779.535\n",
      "Epoch:[ 1 ] Batch: 381 / 937 Main Model Loss: 0.013447176 Interpreter Loss: 18449.227\n",
      "Epoch:[ 1 ] Batch: 382 / 937 Main Model Loss: 0.012823449 Interpreter Loss: 18207.555\n",
      "Epoch:[ 1 ] Batch: 383 / 937 Main Model Loss: 0.07185202 Interpreter Loss: 17615.03\n",
      "Epoch:[ 1 ] Batch: 384 / 937 Main Model Loss: 0.034453176 Interpreter Loss: 19453.387\n",
      "Epoch:[ 1 ] Batch: 385 / 937 Main Model Loss: 0.03789305 Interpreter Loss: 18982.398\n",
      "Epoch:[ 1 ] Batch: 386 / 937 Main Model Loss: 0.025528662 Interpreter Loss: 18743.494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 1 ] Batch: 387 / 937 Main Model Loss: 0.02082717 Interpreter Loss: 18321.148\n",
      "Epoch:[ 1 ] Batch: 388 / 937 Main Model Loss: 0.011990545 Interpreter Loss: 17505.145\n",
      "Epoch:[ 1 ] Batch: 389 / 937 Main Model Loss: 0.11044503 Interpreter Loss: 16939.648\n",
      "Epoch:[ 1 ] Batch: 390 / 937 Main Model Loss: 0.0048520663 Interpreter Loss: 17508.223\n",
      "Epoch:[ 1 ] Batch: 391 / 937 Main Model Loss: 0.017134406 Interpreter Loss: 17141.16\n",
      "Epoch:[ 1 ] Batch: 392 / 937 Main Model Loss: 0.04694394 Interpreter Loss: 17568.25\n",
      "Epoch:[ 1 ] Batch: 393 / 937 Main Model Loss: 0.12148229 Interpreter Loss: 18006.078\n",
      "Epoch:[ 1 ] Batch: 394 / 937 Main Model Loss: 0.028185908 Interpreter Loss: 17992.412\n",
      "Epoch:[ 1 ] Batch: 395 / 937 Main Model Loss: 0.02253407 Interpreter Loss: 19889.492\n",
      "Epoch:[ 1 ] Batch: 396 / 937 Main Model Loss: 0.003786406 Interpreter Loss: 18571.59\n",
      "Epoch:[ 1 ] Batch: 397 / 937 Main Model Loss: 0.0024769313 Interpreter Loss: 17951.443\n",
      "Epoch:[ 1 ] Batch: 398 / 937 Main Model Loss: 0.037821062 Interpreter Loss: 18832.93\n",
      "Epoch:[ 1 ] Batch: 399 / 937 Main Model Loss: 0.18932235 Interpreter Loss: 17493.582\n",
      "Epoch:[ 1 ] Batch: 400 / 937 Main Model Loss: 0.037516978 Interpreter Loss: 18101.053\n",
      "Epoch:[ 1 ] Batch: 401 / 937 Main Model Loss: 0.07442006 Interpreter Loss: 17814.393\n",
      "Epoch:[ 1 ] Batch: 402 / 937 Main Model Loss: 0.01654742 Interpreter Loss: 17178.793\n",
      "Epoch:[ 1 ] Batch: 403 / 937 Main Model Loss: 0.08349797 Interpreter Loss: 17146.781\n",
      "Epoch:[ 1 ] Batch: 404 / 937 Main Model Loss: 0.013544861 Interpreter Loss: 16636.137\n",
      "Epoch:[ 1 ] Batch: 405 / 937 Main Model Loss: 0.011541899 Interpreter Loss: 17257.79\n",
      "Epoch:[ 1 ] Batch: 406 / 937 Main Model Loss: 0.009234324 Interpreter Loss: 18719.777\n",
      "Epoch:[ 1 ] Batch: 407 / 937 Main Model Loss: 0.042240784 Interpreter Loss: 18076.469\n",
      "Epoch:[ 1 ] Batch: 408 / 937 Main Model Loss: 0.059866484 Interpreter Loss: 17515.691\n",
      "Epoch:[ 1 ] Batch: 409 / 937 Main Model Loss: 0.019575145 Interpreter Loss: 18179.959\n",
      "Epoch:[ 1 ] Batch: 410 / 937 Main Model Loss: 0.022650884 Interpreter Loss: 17256.484\n",
      "Epoch:[ 1 ] Batch: 411 / 937 Main Model Loss: 0.037686475 Interpreter Loss: 17298.684\n",
      "Epoch:[ 1 ] Batch: 412 / 937 Main Model Loss: 0.18802491 Interpreter Loss: 17932.734\n",
      "Epoch:[ 1 ] Batch: 413 / 937 Main Model Loss: 0.055201642 Interpreter Loss: 17722.027\n",
      "Epoch:[ 1 ] Batch: 414 / 937 Main Model Loss: 0.10240003 Interpreter Loss: 17672.988\n",
      "Epoch:[ 1 ] Batch: 415 / 937 Main Model Loss: 0.11328727 Interpreter Loss: 16583.88\n",
      "Epoch:[ 1 ] Batch: 416 / 937 Main Model Loss: 0.21940593 Interpreter Loss: 18106.047\n",
      "Epoch:[ 1 ] Batch: 417 / 937 Main Model Loss: 0.22729212 Interpreter Loss: 19098.736\n",
      "Epoch:[ 1 ] Batch: 418 / 937 Main Model Loss: 0.042206008 Interpreter Loss: 18288.281\n",
      "Epoch:[ 1 ] Batch: 419 / 937 Main Model Loss: 0.111333594 Interpreter Loss: 19350.865\n",
      "Epoch:[ 1 ] Batch: 420 / 937 Main Model Loss: 0.21173528 Interpreter Loss: 17156.719\n",
      "Epoch:[ 1 ] Batch: 421 / 937 Main Model Loss: 0.0037971218 Interpreter Loss: 16453.967\n",
      "Epoch:[ 1 ] Batch: 422 / 937 Main Model Loss: 0.013312759 Interpreter Loss: 17043.14\n",
      "Epoch:[ 1 ] Batch: 423 / 937 Main Model Loss: 0.043337673 Interpreter Loss: 19226.76\n",
      "Epoch:[ 1 ] Batch: 424 / 937 Main Model Loss: 0.09532122 Interpreter Loss: 19438.252\n",
      "Epoch:[ 1 ] Batch: 425 / 937 Main Model Loss: 0.06625296 Interpreter Loss: 18895.785\n",
      "Epoch:[ 1 ] Batch: 426 / 937 Main Model Loss: 0.019369628 Interpreter Loss: 18194.07\n",
      "Epoch:[ 1 ] Batch: 427 / 937 Main Model Loss: 0.015114161 Interpreter Loss: 17556.848\n",
      "Epoch:[ 1 ] Batch: 428 / 937 Main Model Loss: 0.015054012 Interpreter Loss: 17786.344\n",
      "Epoch:[ 1 ] Batch: 429 / 937 Main Model Loss: 0.056884162 Interpreter Loss: 17263.986\n",
      "Epoch:[ 1 ] Batch: 430 / 937 Main Model Loss: 0.063020274 Interpreter Loss: 17025.75\n",
      "Epoch:[ 1 ] Batch: 431 / 937 Main Model Loss: 0.028494107 Interpreter Loss: 17550.734\n",
      "Epoch:[ 1 ] Batch: 432 / 937 Main Model Loss: 0.047355432 Interpreter Loss: 17965.666\n",
      "Epoch:[ 1 ] Batch: 433 / 937 Main Model Loss: 0.03127585 Interpreter Loss: 16753.344\n",
      "Epoch:[ 1 ] Batch: 434 / 937 Main Model Loss: 0.060828306 Interpreter Loss: 17384.846\n",
      "Epoch:[ 1 ] Batch: 435 / 937 Main Model Loss: 0.15259898 Interpreter Loss: 18114.812\n",
      "Epoch:[ 1 ] Batch: 436 / 937 Main Model Loss: 0.025593977 Interpreter Loss: 18755.57\n",
      "Epoch:[ 1 ] Batch: 437 / 937 Main Model Loss: 0.052556347 Interpreter Loss: 18115.162\n",
      "Epoch:[ 1 ] Batch: 438 / 937 Main Model Loss: 0.008537625 Interpreter Loss: 17632.38\n",
      "Epoch:[ 1 ] Batch: 439 / 937 Main Model Loss: 0.023890149 Interpreter Loss: 18649.764\n",
      "Epoch:[ 1 ] Batch: 440 / 937 Main Model Loss: 0.028782014 Interpreter Loss: 18641.832\n",
      "Epoch:[ 1 ] Batch: 441 / 937 Main Model Loss: 0.027441468 Interpreter Loss: 18217.164\n",
      "Epoch:[ 1 ] Batch: 442 / 937 Main Model Loss: 0.02323897 Interpreter Loss: 17878.45\n",
      "Epoch:[ 1 ] Batch: 443 / 937 Main Model Loss: 0.14529759 Interpreter Loss: 19389.361\n",
      "Epoch:[ 1 ] Batch: 444 / 937 Main Model Loss: 0.015186921 Interpreter Loss: 18377.104\n",
      "Epoch:[ 1 ] Batch: 445 / 937 Main Model Loss: 0.010722792 Interpreter Loss: 18028.088\n",
      "Epoch:[ 1 ] Batch: 446 / 937 Main Model Loss: 0.020505242 Interpreter Loss: 17765.86\n",
      "Epoch:[ 1 ] Batch: 447 / 937 Main Model Loss: 0.17520724 Interpreter Loss: 18082.8\n",
      "Epoch:[ 1 ] Batch: 448 / 937 Main Model Loss: 0.11451026 Interpreter Loss: 17086.516\n",
      "Epoch:[ 1 ] Batch: 449 / 937 Main Model Loss: 0.06527129 Interpreter Loss: 17275.537\n",
      "Epoch:[ 1 ] Batch: 450 / 937 Main Model Loss: 0.013971103 Interpreter Loss: 17338.115\n",
      "Epoch:[ 1 ] Batch: 451 / 937 Main Model Loss: 0.0030464903 Interpreter Loss: 17545.684\n",
      "Epoch:[ 1 ] Batch: 452 / 937 Main Model Loss: 0.045211267 Interpreter Loss: 18420.715\n",
      "Epoch:[ 1 ] Batch: 453 / 937 Main Model Loss: 0.026685437 Interpreter Loss: 17554.168\n",
      "Epoch:[ 1 ] Batch: 454 / 937 Main Model Loss: 0.012084838 Interpreter Loss: 16410.111\n",
      "Epoch:[ 1 ] Batch: 455 / 937 Main Model Loss: 0.07293759 Interpreter Loss: 18120.5\n",
      "Epoch:[ 1 ] Batch: 456 / 937 Main Model Loss: 0.1125871 Interpreter Loss: 17491.965\n",
      "Epoch:[ 1 ] Batch: 457 / 937 Main Model Loss: 0.08608337 Interpreter Loss: 18943.973\n",
      "Epoch:[ 1 ] Batch: 458 / 937 Main Model Loss: 0.0507542 Interpreter Loss: 18775.215\n",
      "Epoch:[ 1 ] Batch: 459 / 937 Main Model Loss: 0.031974707 Interpreter Loss: 18242.678\n",
      "Epoch:[ 1 ] Batch: 460 / 937 Main Model Loss: 0.044130363 Interpreter Loss: 18305.637\n",
      "Epoch:[ 1 ] Batch: 461 / 937 Main Model Loss: 0.013227283 Interpreter Loss: 16391.29\n",
      "Epoch:[ 1 ] Batch: 462 / 937 Main Model Loss: 0.048794538 Interpreter Loss: 16595.486\n",
      "Epoch:[ 1 ] Batch: 463 / 937 Main Model Loss: 0.02028748 Interpreter Loss: 16793.375\n",
      "Epoch:[ 1 ] Batch: 464 / 937 Main Model Loss: 0.03184749 Interpreter Loss: 17027.84\n",
      "Epoch:[ 1 ] Batch: 465 / 937 Main Model Loss: 0.018705929 Interpreter Loss: 16156.754\n",
      "Epoch:[ 1 ] Batch: 466 / 937 Main Model Loss: 0.038792994 Interpreter Loss: 17350.232\n",
      "Epoch:[ 1 ] Batch: 467 / 937 Main Model Loss: 0.019594952 Interpreter Loss: 16930.668\n",
      "Epoch:[ 1 ] Batch: 468 / 937 Main Model Loss: 0.030212618 Interpreter Loss: 16428.482\n",
      "Epoch:[ 1 ] Batch: 469 / 937 Main Model Loss: 0.06778723 Interpreter Loss: 17349.184\n",
      "Epoch:[ 1 ] Batch: 470 / 937 Main Model Loss: 0.02143425 Interpreter Loss: 17664.451\n",
      "Epoch:[ 1 ] Batch: 471 / 937 Main Model Loss: 0.079299234 Interpreter Loss: 17501.57\n",
      "Epoch:[ 1 ] Batch: 472 / 937 Main Model Loss: 0.019257266 Interpreter Loss: 16213.563\n",
      "Epoch:[ 1 ] Batch: 473 / 937 Main Model Loss: 0.0072768484 Interpreter Loss: 16184.213\n",
      "Epoch:[ 1 ] Batch: 474 / 937 Main Model Loss: 0.0035511288 Interpreter Loss: 16886.68\n",
      "Epoch:[ 1 ] Batch: 475 / 937 Main Model Loss: 0.009540439 Interpreter Loss: 17539.172\n",
      "Epoch:[ 1 ] Batch: 476 / 937 Main Model Loss: 0.13038197 Interpreter Loss: 17814.766\n",
      "Epoch:[ 1 ] Batch: 477 / 937 Main Model Loss: 0.018720295 Interpreter Loss: 16736.105\n",
      "Epoch:[ 1 ] Batch: 478 / 937 Main Model Loss: 0.08616486 Interpreter Loss: 15504.324\n",
      "Epoch:[ 1 ] Batch: 479 / 937 Main Model Loss: 0.032818332 Interpreter Loss: 16065.108\n",
      "Epoch:[ 1 ] Batch: 480 / 937 Main Model Loss: 0.023699505 Interpreter Loss: 16178.486\n",
      "Epoch:[ 1 ] Batch: 481 / 937 Main Model Loss: 0.03467385 Interpreter Loss: 17644.092\n",
      "Epoch:[ 1 ] Batch: 482 / 937 Main Model Loss: 0.047631778 Interpreter Loss: 17468.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 1 ] Batch: 483 / 937 Main Model Loss: 0.024146482 Interpreter Loss: 17094.197\n",
      "Epoch:[ 1 ] Batch: 484 / 937 Main Model Loss: 0.050756846 Interpreter Loss: 16775.44\n",
      "Epoch:[ 1 ] Batch: 485 / 937 Main Model Loss: 0.03735323 Interpreter Loss: 16771.348\n",
      "Epoch:[ 1 ] Batch: 486 / 937 Main Model Loss: 0.018215822 Interpreter Loss: 16389.78\n",
      "Epoch:[ 1 ] Batch: 487 / 937 Main Model Loss: 0.021602247 Interpreter Loss: 16746.158\n",
      "Epoch:[ 1 ] Batch: 488 / 937 Main Model Loss: 0.059010975 Interpreter Loss: 17315.217\n",
      "Epoch:[ 1 ] Batch: 489 / 937 Main Model Loss: 0.055758484 Interpreter Loss: 16974.303\n",
      "Epoch:[ 1 ] Batch: 490 / 937 Main Model Loss: 0.05125448 Interpreter Loss: 16811.477\n",
      "Epoch:[ 1 ] Batch: 491 / 937 Main Model Loss: 0.019466586 Interpreter Loss: 16734.639\n",
      "Epoch:[ 1 ] Batch: 492 / 937 Main Model Loss: 0.07171971 Interpreter Loss: 15685.799\n",
      "Epoch:[ 1 ] Batch: 493 / 937 Main Model Loss: 0.08098323 Interpreter Loss: 16372.829\n",
      "Epoch:[ 1 ] Batch: 494 / 937 Main Model Loss: 0.043497276 Interpreter Loss: 16782.07\n",
      "Epoch:[ 1 ] Batch: 495 / 937 Main Model Loss: 0.18542698 Interpreter Loss: 16519.0\n",
      "Epoch:[ 1 ] Batch: 496 / 937 Main Model Loss: 0.08179788 Interpreter Loss: 16908.883\n",
      "Epoch:[ 1 ] Batch: 497 / 937 Main Model Loss: 0.116543874 Interpreter Loss: 16563.555\n",
      "Epoch:[ 1 ] Batch: 498 / 937 Main Model Loss: 0.0047772545 Interpreter Loss: 15883.277\n",
      "Epoch:[ 1 ] Batch: 499 / 937 Main Model Loss: 0.08261718 Interpreter Loss: 17013.096\n",
      "Epoch:[ 1 ] Batch: 500 / 937 Main Model Loss: 0.117883526 Interpreter Loss: 18006.54\n",
      "Epoch:[ 1 ] Batch: 501 / 937 Main Model Loss: 0.09716227 Interpreter Loss: 17590.393\n",
      "Epoch:[ 1 ] Batch: 502 / 937 Main Model Loss: 0.00977473 Interpreter Loss: 17052.414\n",
      "Epoch:[ 1 ] Batch: 503 / 937 Main Model Loss: 0.043197095 Interpreter Loss: 16479.4\n",
      "Epoch:[ 1 ] Batch: 504 / 937 Main Model Loss: 0.07404826 Interpreter Loss: 17872.535\n",
      "Epoch:[ 1 ] Batch: 505 / 937 Main Model Loss: 0.13060609 Interpreter Loss: 17956.959\n",
      "Epoch:[ 1 ] Batch: 506 / 937 Main Model Loss: 0.05770276 Interpreter Loss: 19754.646\n",
      "Epoch:[ 1 ] Batch: 507 / 937 Main Model Loss: 0.05017557 Interpreter Loss: 18809.21\n",
      "Epoch:[ 1 ] Batch: 508 / 937 Main Model Loss: 0.051459145 Interpreter Loss: 16839.916\n",
      "Epoch:[ 1 ] Batch: 509 / 937 Main Model Loss: 0.006378242 Interpreter Loss: 16204.571\n",
      "Epoch:[ 1 ] Batch: 510 / 937 Main Model Loss: 0.06842358 Interpreter Loss: 17076.84\n",
      "Epoch:[ 1 ] Batch: 511 / 937 Main Model Loss: 0.10390714 Interpreter Loss: 16063.701\n",
      "Epoch:[ 1 ] Batch: 512 / 937 Main Model Loss: 0.028171115 Interpreter Loss: 16882.21\n",
      "Epoch:[ 1 ] Batch: 513 / 937 Main Model Loss: 0.055661276 Interpreter Loss: 16832.062\n",
      "Epoch:[ 1 ] Batch: 514 / 937 Main Model Loss: 0.034542263 Interpreter Loss: 16786.318\n",
      "Epoch:[ 1 ] Batch: 515 / 937 Main Model Loss: 0.0030458677 Interpreter Loss: 16644.732\n",
      "Epoch:[ 1 ] Batch: 516 / 937 Main Model Loss: 0.049924362 Interpreter Loss: 17723.855\n",
      "Epoch:[ 1 ] Batch: 517 / 937 Main Model Loss: 0.011394607 Interpreter Loss: 17348.457\n",
      "Epoch:[ 1 ] Batch: 518 / 937 Main Model Loss: 0.014113525 Interpreter Loss: 17305.75\n",
      "Epoch:[ 1 ] Batch: 519 / 937 Main Model Loss: 0.014152555 Interpreter Loss: 16941.004\n",
      "Epoch:[ 1 ] Batch: 520 / 937 Main Model Loss: 0.07310254 Interpreter Loss: 17401.273\n",
      "Epoch:[ 1 ] Batch: 521 / 937 Main Model Loss: 0.017237127 Interpreter Loss: 16626.057\n",
      "Epoch:[ 1 ] Batch: 522 / 937 Main Model Loss: 0.051683597 Interpreter Loss: 16411.11\n",
      "Epoch:[ 1 ] Batch: 523 / 937 Main Model Loss: 0.047516275 Interpreter Loss: 15869.797\n",
      "Epoch:[ 1 ] Batch: 524 / 937 Main Model Loss: 0.0136429705 Interpreter Loss: 15602.227\n",
      "Epoch:[ 1 ] Batch: 525 / 937 Main Model Loss: 0.030053556 Interpreter Loss: 16030.551\n",
      "Epoch:[ 1 ] Batch: 526 / 937 Main Model Loss: 0.007611072 Interpreter Loss: 16551.219\n",
      "Epoch:[ 1 ] Batch: 527 / 937 Main Model Loss: 0.09983789 Interpreter Loss: 17045.672\n",
      "Epoch:[ 1 ] Batch: 528 / 937 Main Model Loss: 0.0060652914 Interpreter Loss: 17141.043\n",
      "Epoch:[ 1 ] Batch: 529 / 937 Main Model Loss: 0.0073645897 Interpreter Loss: 16490.258\n",
      "Epoch:[ 1 ] Batch: 530 / 937 Main Model Loss: 0.0054444475 Interpreter Loss: 16061.656\n",
      "Epoch:[ 1 ] Batch: 531 / 937 Main Model Loss: 0.040163763 Interpreter Loss: 15598.113\n",
      "Epoch:[ 1 ] Batch: 532 / 937 Main Model Loss: 0.051484957 Interpreter Loss: 16955.541\n",
      "Epoch:[ 1 ] Batch: 533 / 937 Main Model Loss: 0.012319947 Interpreter Loss: 16369.47\n",
      "Epoch:[ 1 ] Batch: 534 / 937 Main Model Loss: 0.009027409 Interpreter Loss: 16005.754\n",
      "Epoch:[ 1 ] Batch: 535 / 937 Main Model Loss: 0.005725021 Interpreter Loss: 15566.1\n",
      "Epoch:[ 1 ] Batch: 536 / 937 Main Model Loss: 0.04197979 Interpreter Loss: 17426.611\n",
      "Epoch:[ 1 ] Batch: 537 / 937 Main Model Loss: 0.23786591 Interpreter Loss: 17315.342\n",
      "Epoch:[ 1 ] Batch: 538 / 937 Main Model Loss: 0.009811793 Interpreter Loss: 17181.094\n",
      "Epoch:[ 1 ] Batch: 539 / 937 Main Model Loss: 0.071051106 Interpreter Loss: 16924.11\n",
      "Epoch:[ 1 ] Batch: 540 / 937 Main Model Loss: 0.020096812 Interpreter Loss: 16985.354\n",
      "Epoch:[ 1 ] Batch: 541 / 937 Main Model Loss: 0.16964741 Interpreter Loss: 17657.621\n",
      "Epoch:[ 1 ] Batch: 542 / 937 Main Model Loss: 0.10846341 Interpreter Loss: 17925.115\n",
      "Epoch:[ 1 ] Batch: 543 / 937 Main Model Loss: 0.097936705 Interpreter Loss: 17442.326\n",
      "Epoch:[ 1 ] Batch: 544 / 937 Main Model Loss: 0.1049054 Interpreter Loss: 17746.766\n",
      "Epoch:[ 1 ] Batch: 545 / 937 Main Model Loss: 0.09069401 Interpreter Loss: 17083.156\n",
      "Epoch:[ 1 ] Batch: 546 / 937 Main Model Loss: 0.009639351 Interpreter Loss: 16294.74\n",
      "Epoch:[ 1 ] Batch: 547 / 937 Main Model Loss: 0.11729717 Interpreter Loss: 17446.496\n",
      "Epoch:[ 1 ] Batch: 548 / 937 Main Model Loss: 0.0057501025 Interpreter Loss: 16173.058\n",
      "Epoch:[ 1 ] Batch: 549 / 937 Main Model Loss: 0.056986347 Interpreter Loss: 15656.34\n",
      "Epoch:[ 1 ] Batch: 550 / 937 Main Model Loss: 0.14306568 Interpreter Loss: 16453.783\n",
      "Epoch:[ 1 ] Batch: 551 / 937 Main Model Loss: 0.036139946 Interpreter Loss: 16179.08\n",
      "Epoch:[ 1 ] Batch: 552 / 937 Main Model Loss: 0.04048545 Interpreter Loss: 16539.082\n",
      "Epoch:[ 1 ] Batch: 553 / 937 Main Model Loss: 0.019242583 Interpreter Loss: 17082.504\n",
      "Epoch:[ 1 ] Batch: 554 / 937 Main Model Loss: 0.166551 Interpreter Loss: 17088.098\n",
      "Epoch:[ 1 ] Batch: 555 / 937 Main Model Loss: 0.01887982 Interpreter Loss: 16044.643\n",
      "Epoch:[ 1 ] Batch: 556 / 937 Main Model Loss: 0.09966007 Interpreter Loss: 16288.436\n",
      "Epoch:[ 1 ] Batch: 557 / 937 Main Model Loss: 0.08378984 Interpreter Loss: 17282.738\n",
      "Epoch:[ 1 ] Batch: 558 / 937 Main Model Loss: 0.03272333 Interpreter Loss: 16578.084\n",
      "Epoch:[ 1 ] Batch: 559 / 937 Main Model Loss: 0.005334379 Interpreter Loss: 15871.583\n",
      "Epoch:[ 1 ] Batch: 560 / 937 Main Model Loss: 0.06163077 Interpreter Loss: 15552.949\n",
      "Epoch:[ 1 ] Batch: 561 / 937 Main Model Loss: 0.05379858 Interpreter Loss: 16312.955\n",
      "Epoch:[ 1 ] Batch: 562 / 937 Main Model Loss: 0.048449334 Interpreter Loss: 15864.328\n",
      "Epoch:[ 1 ] Batch: 563 / 937 Main Model Loss: 0.046842664 Interpreter Loss: 15954.83\n",
      "Epoch:[ 1 ] Batch: 564 / 937 Main Model Loss: 0.13434911 Interpreter Loss: 17014.18\n",
      "Epoch:[ 1 ] Batch: 565 / 937 Main Model Loss: 0.071565874 Interpreter Loss: 17789.348\n",
      "Epoch:[ 1 ] Batch: 566 / 937 Main Model Loss: 0.017712815 Interpreter Loss: 17433.951\n",
      "Epoch:[ 1 ] Batch: 567 / 937 Main Model Loss: 0.016557591 Interpreter Loss: 17217.738\n",
      "Epoch:[ 1 ] Batch: 568 / 937 Main Model Loss: 0.019551713 Interpreter Loss: 16139.824\n",
      "Epoch:[ 1 ] Batch: 569 / 937 Main Model Loss: 0.06332917 Interpreter Loss: 16656.072\n",
      "Epoch:[ 1 ] Batch: 570 / 937 Main Model Loss: 0.01662989 Interpreter Loss: 16116.781\n",
      "Epoch:[ 1 ] Batch: 571 / 937 Main Model Loss: 0.025831148 Interpreter Loss: 17893.229\n",
      "Epoch:[ 1 ] Batch: 572 / 937 Main Model Loss: 0.010268515 Interpreter Loss: 17541.87\n",
      "Epoch:[ 1 ] Batch: 573 / 937 Main Model Loss: 0.06230849 Interpreter Loss: 17805.469\n",
      "Epoch:[ 1 ] Batch: 574 / 937 Main Model Loss: 0.11705704 Interpreter Loss: 18428.842\n",
      "Epoch:[ 1 ] Batch: 575 / 937 Main Model Loss: 0.03834734 Interpreter Loss: 17293.514\n",
      "Epoch:[ 1 ] Batch: 576 / 937 Main Model Loss: 0.05166615 Interpreter Loss: 17183.488\n",
      "Epoch:[ 1 ] Batch: 577 / 937 Main Model Loss: 0.03024512 Interpreter Loss: 16253.641\n",
      "Epoch:[ 1 ] Batch: 578 / 937 Main Model Loss: 0.23985201 Interpreter Loss: 16032.215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 1 ] Batch: 579 / 937 Main Model Loss: 0.057579134 Interpreter Loss: 18256.299\n",
      "Epoch:[ 1 ] Batch: 580 / 937 Main Model Loss: 0.034724552 Interpreter Loss: 17691.469\n",
      "Epoch:[ 1 ] Batch: 581 / 937 Main Model Loss: 0.020099629 Interpreter Loss: 17511.0\n",
      "Epoch:[ 1 ] Batch: 582 / 937 Main Model Loss: 0.076728106 Interpreter Loss: 17138.887\n",
      "Epoch:[ 1 ] Batch: 583 / 937 Main Model Loss: 0.06960161 Interpreter Loss: 17743.201\n",
      "Epoch:[ 1 ] Batch: 584 / 937 Main Model Loss: 0.08903272 Interpreter Loss: 17069.879\n",
      "Epoch:[ 1 ] Batch: 585 / 937 Main Model Loss: 0.10895559 Interpreter Loss: 16994.072\n",
      "Epoch:[ 1 ] Batch: 586 / 937 Main Model Loss: 0.016599337 Interpreter Loss: 15888.879\n",
      "Epoch:[ 1 ] Batch: 587 / 937 Main Model Loss: 0.005998687 Interpreter Loss: 15617.224\n",
      "Epoch:[ 1 ] Batch: 588 / 937 Main Model Loss: 0.0474335 Interpreter Loss: 15656.268\n",
      "Epoch:[ 1 ] Batch: 589 / 937 Main Model Loss: 0.057632346 Interpreter Loss: 17343.148\n",
      "Epoch:[ 1 ] Batch: 590 / 937 Main Model Loss: 0.10723124 Interpreter Loss: 16517.902\n",
      "Epoch:[ 1 ] Batch: 591 / 937 Main Model Loss: 0.114558786 Interpreter Loss: 16162.205\n",
      "Epoch:[ 1 ] Batch: 592 / 937 Main Model Loss: 0.016785141 Interpreter Loss: 16045.486\n",
      "Epoch:[ 1 ] Batch: 593 / 937 Main Model Loss: 0.024662174 Interpreter Loss: 16051.426\n",
      "Epoch:[ 1 ] Batch: 594 / 937 Main Model Loss: 0.050518665 Interpreter Loss: 15220.699\n",
      "Epoch:[ 1 ] Batch: 595 / 937 Main Model Loss: 0.009615427 Interpreter Loss: 16205.514\n",
      "Epoch:[ 1 ] Batch: 596 / 937 Main Model Loss: 0.010988025 Interpreter Loss: 16492.3\n",
      "Epoch:[ 1 ] Batch: 597 / 937 Main Model Loss: 0.020694675 Interpreter Loss: 16399.281\n",
      "Epoch:[ 1 ] Batch: 598 / 937 Main Model Loss: 0.055440146 Interpreter Loss: 16043.939\n",
      "Epoch:[ 1 ] Batch: 599 / 937 Main Model Loss: 0.042533774 Interpreter Loss: 16386.193\n",
      "Epoch:[ 1 ] Batch: 600 / 937 Main Model Loss: 0.06396538 Interpreter Loss: 15884.692\n",
      "Epoch:[ 1 ] Batch: 601 / 937 Main Model Loss: 0.037517473 Interpreter Loss: 15514.865\n",
      "Epoch:[ 1 ] Batch: 602 / 937 Main Model Loss: 0.02627946 Interpreter Loss: 15954.969\n",
      "Epoch:[ 1 ] Batch: 603 / 937 Main Model Loss: 0.12171135 Interpreter Loss: 17528.402\n",
      "Epoch:[ 1 ] Batch: 604 / 937 Main Model Loss: 0.09138138 Interpreter Loss: 16063.262\n",
      "Epoch:[ 1 ] Batch: 605 / 937 Main Model Loss: 0.0542027 Interpreter Loss: 16407.969\n",
      "Epoch:[ 1 ] Batch: 606 / 937 Main Model Loss: 0.01763362 Interpreter Loss: 15701.925\n",
      "Epoch:[ 1 ] Batch: 607 / 937 Main Model Loss: 0.01066901 Interpreter Loss: 15965.07\n",
      "Epoch:[ 1 ] Batch: 608 / 937 Main Model Loss: 0.03576816 Interpreter Loss: 16056.066\n",
      "Epoch:[ 1 ] Batch: 609 / 937 Main Model Loss: 0.07026716 Interpreter Loss: 15458.491\n",
      "Epoch:[ 1 ] Batch: 610 / 937 Main Model Loss: 0.006868981 Interpreter Loss: 15955.412\n",
      "Epoch:[ 1 ] Batch: 611 / 937 Main Model Loss: 0.015351631 Interpreter Loss: 17033.934\n",
      "Epoch:[ 1 ] Batch: 612 / 937 Main Model Loss: 0.08764267 Interpreter Loss: 16632.844\n",
      "Epoch:[ 1 ] Batch: 613 / 937 Main Model Loss: 0.044371832 Interpreter Loss: 16769.824\n",
      "Epoch:[ 1 ] Batch: 614 / 937 Main Model Loss: 0.06314418 Interpreter Loss: 17610.746\n",
      "Epoch:[ 1 ] Batch: 615 / 937 Main Model Loss: 0.12438139 Interpreter Loss: 17634.633\n",
      "Epoch:[ 1 ] Batch: 616 / 937 Main Model Loss: 0.029968748 Interpreter Loss: 17738.787\n",
      "Epoch:[ 1 ] Batch: 617 / 937 Main Model Loss: 0.022866052 Interpreter Loss: 16213.407\n",
      "Epoch:[ 1 ] Batch: 618 / 937 Main Model Loss: 0.017071288 Interpreter Loss: 16593.992\n",
      "Epoch:[ 1 ] Batch: 619 / 937 Main Model Loss: 0.04079037 Interpreter Loss: 17059.89\n",
      "Epoch:[ 1 ] Batch: 620 / 937 Main Model Loss: 0.052004267 Interpreter Loss: 15636.996\n",
      "Epoch:[ 1 ] Batch: 621 / 937 Main Model Loss: 0.051460896 Interpreter Loss: 15139.645\n",
      "Epoch:[ 1 ] Batch: 622 / 937 Main Model Loss: 0.03543225 Interpreter Loss: 15775.541\n",
      "Epoch:[ 1 ] Batch: 623 / 937 Main Model Loss: 0.018869491 Interpreter Loss: 15359.901\n",
      "Epoch:[ 1 ] Batch: 624 / 937 Main Model Loss: 0.027417313 Interpreter Loss: 17439.498\n",
      "Epoch:[ 1 ] Batch: 625 / 937 Main Model Loss: 0.015021077 Interpreter Loss: 15885.962\n",
      "Epoch:[ 1 ] Batch: 626 / 937 Main Model Loss: 0.05392182 Interpreter Loss: 16215.856\n",
      "Epoch:[ 1 ] Batch: 627 / 937 Main Model Loss: 0.048553694 Interpreter Loss: 15829.095\n",
      "Epoch:[ 1 ] Batch: 628 / 937 Main Model Loss: 0.047607396 Interpreter Loss: 15952.152\n",
      "Epoch:[ 1 ] Batch: 629 / 937 Main Model Loss: 0.05797632 Interpreter Loss: 16273.342\n",
      "Epoch:[ 1 ] Batch: 630 / 937 Main Model Loss: 0.066906735 Interpreter Loss: 15235.837\n",
      "Epoch:[ 1 ] Batch: 631 / 937 Main Model Loss: 0.04934312 Interpreter Loss: 16146.6\n",
      "Epoch:[ 1 ] Batch: 632 / 937 Main Model Loss: 0.025817845 Interpreter Loss: 16964.773\n",
      "Epoch:[ 1 ] Batch: 633 / 937 Main Model Loss: 0.0114219915 Interpreter Loss: 16619.271\n",
      "Epoch:[ 1 ] Batch: 634 / 937 Main Model Loss: 0.04727415 Interpreter Loss: 16113.893\n",
      "Epoch:[ 1 ] Batch: 635 / 937 Main Model Loss: 0.009389122 Interpreter Loss: 15556.738\n",
      "Epoch:[ 1 ] Batch: 636 / 937 Main Model Loss: 0.07543252 Interpreter Loss: 15791.22\n",
      "Epoch:[ 1 ] Batch: 637 / 937 Main Model Loss: 0.03533372 Interpreter Loss: 15000.035\n",
      "Epoch:[ 1 ] Batch: 638 / 937 Main Model Loss: 0.038965262 Interpreter Loss: 16063.609\n",
      "Epoch:[ 1 ] Batch: 639 / 937 Main Model Loss: 0.022400456 Interpreter Loss: 15487.678\n",
      "Epoch:[ 1 ] Batch: 640 / 937 Main Model Loss: 0.056443226 Interpreter Loss: 16102.793\n",
      "Epoch:[ 1 ] Batch: 641 / 937 Main Model Loss: 0.057479702 Interpreter Loss: 15878.124\n",
      "Epoch:[ 1 ] Batch: 642 / 937 Main Model Loss: 0.020756472 Interpreter Loss: 15513.832\n",
      "Epoch:[ 1 ] Batch: 643 / 937 Main Model Loss: 0.033442654 Interpreter Loss: 16746.965\n",
      "Epoch:[ 1 ] Batch: 644 / 937 Main Model Loss: 0.044831626 Interpreter Loss: 15619.539\n",
      "Epoch:[ 1 ] Batch: 645 / 937 Main Model Loss: 0.14098327 Interpreter Loss: 17386.316\n",
      "Epoch:[ 1 ] Batch: 646 / 937 Main Model Loss: 0.1195841 Interpreter Loss: 17180.104\n",
      "Epoch:[ 1 ] Batch: 647 / 937 Main Model Loss: 0.089803934 Interpreter Loss: 16459.54\n",
      "Epoch:[ 1 ] Batch: 648 / 937 Main Model Loss: 0.017802112 Interpreter Loss: 15116.052\n",
      "Epoch:[ 1 ] Batch: 649 / 937 Main Model Loss: 0.06854358 Interpreter Loss: 16699.04\n",
      "Epoch:[ 1 ] Batch: 650 / 937 Main Model Loss: 0.024861028 Interpreter Loss: 15626.025\n",
      "Epoch:[ 1 ] Batch: 651 / 937 Main Model Loss: 0.00744786 Interpreter Loss: 14303.141\n",
      "Epoch:[ 1 ] Batch: 652 / 937 Main Model Loss: 0.029653557 Interpreter Loss: 14212.044\n",
      "Epoch:[ 1 ] Batch: 653 / 937 Main Model Loss: 0.029227495 Interpreter Loss: 15129.371\n",
      "Epoch:[ 1 ] Batch: 654 / 937 Main Model Loss: 0.08484639 Interpreter Loss: 16238.414\n",
      "Epoch:[ 1 ] Batch: 655 / 937 Main Model Loss: 0.01404414 Interpreter Loss: 16166.885\n",
      "Epoch:[ 1 ] Batch: 656 / 937 Main Model Loss: 0.043844674 Interpreter Loss: 17362.617\n",
      "Epoch:[ 1 ] Batch: 657 / 937 Main Model Loss: 0.009157353 Interpreter Loss: 16044.299\n",
      "Epoch:[ 1 ] Batch: 658 / 937 Main Model Loss: 0.021540966 Interpreter Loss: 15933.873\n",
      "Epoch:[ 1 ] Batch: 659 / 937 Main Model Loss: 0.05419322 Interpreter Loss: 16209.56\n",
      "Epoch:[ 1 ] Batch: 660 / 937 Main Model Loss: 0.01663889 Interpreter Loss: 16042.891\n",
      "Epoch:[ 1 ] Batch: 661 / 937 Main Model Loss: 0.072289936 Interpreter Loss: 16002.965\n",
      "Epoch:[ 1 ] Batch: 662 / 937 Main Model Loss: 0.037562273 Interpreter Loss: 16457.09\n",
      "Epoch:[ 1 ] Batch: 663 / 937 Main Model Loss: 0.07720197 Interpreter Loss: 16034.246\n",
      "Epoch:[ 1 ] Batch: 664 / 937 Main Model Loss: 0.035093978 Interpreter Loss: 16239.595\n",
      "Epoch:[ 1 ] Batch: 665 / 937 Main Model Loss: 0.09977365 Interpreter Loss: 16224.447\n",
      "Epoch:[ 1 ] Batch: 666 / 937 Main Model Loss: 0.017325042 Interpreter Loss: 17042.148\n",
      "Epoch:[ 1 ] Batch: 667 / 937 Main Model Loss: 0.019132178 Interpreter Loss: 16426.37\n",
      "Epoch:[ 1 ] Batch: 668 / 937 Main Model Loss: 0.03238208 Interpreter Loss: 16676.666\n",
      "Epoch:[ 1 ] Batch: 669 / 937 Main Model Loss: 0.12084546 Interpreter Loss: 16164.836\n",
      "Epoch:[ 1 ] Batch: 670 / 937 Main Model Loss: 0.082425736 Interpreter Loss: 15857.195\n",
      "Epoch:[ 1 ] Batch: 671 / 937 Main Model Loss: 0.043635968 Interpreter Loss: 15315.791\n",
      "Epoch:[ 1 ] Batch: 672 / 937 Main Model Loss: 0.047928303 Interpreter Loss: 15718.711\n",
      "Epoch:[ 1 ] Batch: 673 / 937 Main Model Loss: 0.11674434 Interpreter Loss: 15095.025\n",
      "Epoch:[ 1 ] Batch: 674 / 937 Main Model Loss: 0.037435282 Interpreter Loss: 16051.227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 1 ] Batch: 675 / 937 Main Model Loss: 0.015238065 Interpreter Loss: 16066.167\n",
      "Epoch:[ 1 ] Batch: 676 / 937 Main Model Loss: 0.007351374 Interpreter Loss: 15221.935\n",
      "Epoch:[ 1 ] Batch: 677 / 937 Main Model Loss: 0.01532291 Interpreter Loss: 15607.573\n",
      "Epoch:[ 1 ] Batch: 678 / 937 Main Model Loss: 0.12479495 Interpreter Loss: 15322.694\n",
      "Epoch:[ 1 ] Batch: 679 / 937 Main Model Loss: 0.028007485 Interpreter Loss: 15945.554\n",
      "Epoch:[ 1 ] Batch: 680 / 937 Main Model Loss: 0.030444656 Interpreter Loss: 15990.18\n",
      "Epoch:[ 1 ] Batch: 681 / 937 Main Model Loss: 0.036874916 Interpreter Loss: 16199.3955\n",
      "Epoch:[ 1 ] Batch: 682 / 937 Main Model Loss: 0.07791273 Interpreter Loss: 15699.262\n",
      "Epoch:[ 1 ] Batch: 683 / 937 Main Model Loss: 0.003567786 Interpreter Loss: 15120.365\n",
      "Epoch:[ 1 ] Batch: 684 / 937 Main Model Loss: 0.010032343 Interpreter Loss: 15357.864\n",
      "Epoch:[ 1 ] Batch: 685 / 937 Main Model Loss: 0.061356492 Interpreter Loss: 15801.363\n",
      "Epoch:[ 1 ] Batch: 686 / 937 Main Model Loss: 0.05085735 Interpreter Loss: 15638.748\n",
      "Epoch:[ 1 ] Batch: 687 / 937 Main Model Loss: 0.02247767 Interpreter Loss: 15028.015\n",
      "Epoch:[ 1 ] Batch: 688 / 937 Main Model Loss: 0.06660502 Interpreter Loss: 15899.186\n",
      "Epoch:[ 1 ] Batch: 689 / 937 Main Model Loss: 0.034416188 Interpreter Loss: 15874.1\n",
      "Epoch:[ 1 ] Batch: 690 / 937 Main Model Loss: 0.010070104 Interpreter Loss: 15269.711\n",
      "Epoch:[ 1 ] Batch: 691 / 937 Main Model Loss: 0.036690857 Interpreter Loss: 15874.187\n",
      "Epoch:[ 1 ] Batch: 692 / 937 Main Model Loss: 0.0098073315 Interpreter Loss: 15534.189\n",
      "Epoch:[ 1 ] Batch: 693 / 937 Main Model Loss: 0.079814196 Interpreter Loss: 14999.507\n",
      "Epoch:[ 1 ] Batch: 694 / 937 Main Model Loss: 0.19981349 Interpreter Loss: 15850.793\n",
      "Epoch:[ 1 ] Batch: 695 / 937 Main Model Loss: 0.028076507 Interpreter Loss: 15221.0625\n",
      "Epoch:[ 1 ] Batch: 696 / 937 Main Model Loss: 0.011957329 Interpreter Loss: 15205.033\n",
      "Epoch:[ 1 ] Batch: 697 / 937 Main Model Loss: 0.015065163 Interpreter Loss: 15149.923\n",
      "Epoch:[ 1 ] Batch: 698 / 937 Main Model Loss: 0.012969477 Interpreter Loss: 14838.769\n",
      "Epoch:[ 1 ] Batch: 699 / 937 Main Model Loss: 0.016991334 Interpreter Loss: 15106.524\n",
      "Epoch:[ 1 ] Batch: 700 / 937 Main Model Loss: 0.09825991 Interpreter Loss: 16248.538\n",
      "Epoch:[ 1 ] Batch: 701 / 937 Main Model Loss: 0.018208057 Interpreter Loss: 15826.823\n",
      "Epoch:[ 1 ] Batch: 702 / 937 Main Model Loss: 0.06649325 Interpreter Loss: 16014.846\n",
      "Epoch:[ 1 ] Batch: 703 / 937 Main Model Loss: 0.013441687 Interpreter Loss: 15677.463\n",
      "Epoch:[ 1 ] Batch: 704 / 937 Main Model Loss: 0.014782073 Interpreter Loss: 16193.494\n",
      "Epoch:[ 1 ] Batch: 705 / 937 Main Model Loss: 0.08088772 Interpreter Loss: 15395.662\n",
      "Epoch:[ 1 ] Batch: 706 / 937 Main Model Loss: 0.034676638 Interpreter Loss: 15890.521\n",
      "Epoch:[ 1 ] Batch: 707 / 937 Main Model Loss: 0.040838867 Interpreter Loss: 15876.63\n",
      "Epoch:[ 1 ] Batch: 708 / 937 Main Model Loss: 0.05138256 Interpreter Loss: 15060.78\n",
      "Epoch:[ 1 ] Batch: 709 / 937 Main Model Loss: 0.044794794 Interpreter Loss: 15557.393\n",
      "Epoch:[ 1 ] Batch: 710 / 937 Main Model Loss: 0.02998671 Interpreter Loss: 15155.405\n",
      "Epoch:[ 1 ] Batch: 711 / 937 Main Model Loss: 0.079475164 Interpreter Loss: 15880.18\n",
      "Epoch:[ 1 ] Batch: 712 / 937 Main Model Loss: 0.07662547 Interpreter Loss: 16136.857\n",
      "Epoch:[ 1 ] Batch: 713 / 937 Main Model Loss: 0.0160797 Interpreter Loss: 15671.283\n",
      "Epoch:[ 1 ] Batch: 714 / 937 Main Model Loss: 0.02056408 Interpreter Loss: 15438.027\n",
      "Epoch:[ 1 ] Batch: 715 / 937 Main Model Loss: 0.032030568 Interpreter Loss: 16297.114\n",
      "Epoch:[ 1 ] Batch: 716 / 937 Main Model Loss: 0.08557296 Interpreter Loss: 15660.227\n",
      "Epoch:[ 1 ] Batch: 717 / 937 Main Model Loss: 0.023449207 Interpreter Loss: 14771.467\n",
      "Epoch:[ 1 ] Batch: 718 / 937 Main Model Loss: 0.030800678 Interpreter Loss: 14816.785\n",
      "Epoch:[ 1 ] Batch: 719 / 937 Main Model Loss: 0.05155535 Interpreter Loss: 15174.933\n",
      "Epoch:[ 1 ] Batch: 720 / 937 Main Model Loss: 0.075647116 Interpreter Loss: 15008.076\n",
      "Epoch:[ 1 ] Batch: 721 / 937 Main Model Loss: 0.0060184505 Interpreter Loss: 14975.248\n",
      "Epoch:[ 1 ] Batch: 722 / 937 Main Model Loss: 0.1402474 Interpreter Loss: 17043.676\n",
      "Epoch:[ 1 ] Batch: 723 / 937 Main Model Loss: 0.10152944 Interpreter Loss: 15688.15\n",
      "Epoch:[ 1 ] Batch: 724 / 937 Main Model Loss: 0.01583812 Interpreter Loss: 16077.404\n",
      "Epoch:[ 1 ] Batch: 725 / 937 Main Model Loss: 0.038391195 Interpreter Loss: 15926.608\n",
      "Epoch:[ 1 ] Batch: 726 / 937 Main Model Loss: 0.053160407 Interpreter Loss: 15252.215\n",
      "Epoch:[ 1 ] Batch: 727 / 937 Main Model Loss: 0.0150749795 Interpreter Loss: 15276.948\n",
      "Epoch:[ 1 ] Batch: 728 / 937 Main Model Loss: 0.010680536 Interpreter Loss: 15387.677\n",
      "Epoch:[ 1 ] Batch: 729 / 937 Main Model Loss: 0.03420751 Interpreter Loss: 16110.813\n",
      "Epoch:[ 1 ] Batch: 730 / 937 Main Model Loss: 0.12200562 Interpreter Loss: 16374.459\n",
      "Epoch:[ 1 ] Batch: 731 / 937 Main Model Loss: 0.032437913 Interpreter Loss: 16000.69\n",
      "Epoch:[ 1 ] Batch: 732 / 937 Main Model Loss: 0.071975425 Interpreter Loss: 15654.007\n",
      "Epoch:[ 1 ] Batch: 733 / 937 Main Model Loss: 0.018907964 Interpreter Loss: 15513.025\n",
      "Epoch:[ 1 ] Batch: 734 / 937 Main Model Loss: 0.05328464 Interpreter Loss: 16106.6\n",
      "Epoch:[ 1 ] Batch: 735 / 937 Main Model Loss: 0.041497312 Interpreter Loss: 15159.799\n",
      "Epoch:[ 1 ] Batch: 736 / 937 Main Model Loss: 0.10608795 Interpreter Loss: 15198.099\n",
      "Epoch:[ 1 ] Batch: 737 / 937 Main Model Loss: 0.009194137 Interpreter Loss: 15330.454\n",
      "Epoch:[ 1 ] Batch: 738 / 937 Main Model Loss: 0.077193335 Interpreter Loss: 15377.372\n",
      "Epoch:[ 1 ] Batch: 739 / 937 Main Model Loss: 0.07140908 Interpreter Loss: 14400.04\n",
      "Epoch:[ 1 ] Batch: 740 / 937 Main Model Loss: 0.033980206 Interpreter Loss: 16236.288\n",
      "Epoch:[ 1 ] Batch: 741 / 937 Main Model Loss: 0.19425602 Interpreter Loss: 17310.723\n",
      "Epoch:[ 1 ] Batch: 742 / 937 Main Model Loss: 0.081340015 Interpreter Loss: 15508.887\n",
      "Epoch:[ 1 ] Batch: 743 / 937 Main Model Loss: 0.09881522 Interpreter Loss: 17379.137\n",
      "Epoch:[ 1 ] Batch: 744 / 937 Main Model Loss: 0.023990875 Interpreter Loss: 16586.414\n",
      "Epoch:[ 1 ] Batch: 745 / 937 Main Model Loss: 0.0434824 Interpreter Loss: 16529.672\n",
      "Epoch:[ 1 ] Batch: 746 / 937 Main Model Loss: 0.06864801 Interpreter Loss: 15710.506\n",
      "Epoch:[ 1 ] Batch: 747 / 937 Main Model Loss: 0.024020575 Interpreter Loss: 16213.646\n",
      "Epoch:[ 1 ] Batch: 748 / 937 Main Model Loss: 0.04790078 Interpreter Loss: 16289.662\n",
      "Epoch:[ 1 ] Batch: 749 / 937 Main Model Loss: 0.03172618 Interpreter Loss: 16019.455\n",
      "Epoch:[ 1 ] Batch: 750 / 937 Main Model Loss: 0.023171378 Interpreter Loss: 16554.23\n",
      "Epoch:[ 1 ] Batch: 751 / 937 Main Model Loss: 0.11298738 Interpreter Loss: 16584.756\n",
      "Epoch:[ 1 ] Batch: 752 / 937 Main Model Loss: 0.012121967 Interpreter Loss: 16237.578\n",
      "Epoch:[ 1 ] Batch: 753 / 937 Main Model Loss: 0.030624503 Interpreter Loss: 16166.21\n",
      "Epoch:[ 1 ] Batch: 754 / 937 Main Model Loss: 0.022258177 Interpreter Loss: 16746.844\n",
      "Epoch:[ 1 ] Batch: 755 / 937 Main Model Loss: 0.06520093 Interpreter Loss: 16710.383\n",
      "Epoch:[ 1 ] Batch: 756 / 937 Main Model Loss: 0.033923723 Interpreter Loss: 16122.762\n",
      "Epoch:[ 1 ] Batch: 757 / 937 Main Model Loss: 0.028064579 Interpreter Loss: 16041.406\n",
      "Epoch:[ 1 ] Batch: 758 / 937 Main Model Loss: 0.07016142 Interpreter Loss: 16214.92\n",
      "Epoch:[ 1 ] Batch: 759 / 937 Main Model Loss: 0.047749855 Interpreter Loss: 15682.096\n",
      "Epoch:[ 1 ] Batch: 760 / 937 Main Model Loss: 0.04010441 Interpreter Loss: 15434.613\n",
      "Epoch:[ 1 ] Batch: 761 / 937 Main Model Loss: 0.0063144 Interpreter Loss: 15571.553\n",
      "Epoch:[ 1 ] Batch: 762 / 937 Main Model Loss: 0.016312117 Interpreter Loss: 16218.141\n",
      "Epoch:[ 1 ] Batch: 763 / 937 Main Model Loss: 0.035529308 Interpreter Loss: 15367.463\n",
      "Epoch:[ 1 ] Batch: 764 / 937 Main Model Loss: 0.034613267 Interpreter Loss: 15562.13\n",
      "Epoch:[ 1 ] Batch: 765 / 937 Main Model Loss: 0.09135927 Interpreter Loss: 16690.24\n",
      "Epoch:[ 1 ] Batch: 766 / 937 Main Model Loss: 0.11136849 Interpreter Loss: 15850.91\n",
      "Epoch:[ 1 ] Batch: 767 / 937 Main Model Loss: 0.02474625 Interpreter Loss: 15439.831\n",
      "Epoch:[ 1 ] Batch: 768 / 937 Main Model Loss: 0.06827502 Interpreter Loss: 15584.704\n",
      "Epoch:[ 1 ] Batch: 769 / 937 Main Model Loss: 0.041075204 Interpreter Loss: 15548.367\n",
      "Epoch:[ 1 ] Batch: 770 / 937 Main Model Loss: 0.021794097 Interpreter Loss: 15482.667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 1 ] Batch: 771 / 937 Main Model Loss: 0.00744666 Interpreter Loss: 14759.51\n",
      "Epoch:[ 1 ] Batch: 772 / 937 Main Model Loss: 0.065882415 Interpreter Loss: 15212.827\n",
      "Epoch:[ 1 ] Batch: 773 / 937 Main Model Loss: 0.13590896 Interpreter Loss: 16556.656\n",
      "Epoch:[ 1 ] Batch: 774 / 937 Main Model Loss: 0.17798054 Interpreter Loss: 16706.66\n",
      "Epoch:[ 1 ] Batch: 775 / 937 Main Model Loss: 0.017561715 Interpreter Loss: 15738.606\n",
      "Epoch:[ 1 ] Batch: 776 / 937 Main Model Loss: 0.008743236 Interpreter Loss: 14687.235\n",
      "Epoch:[ 1 ] Batch: 777 / 937 Main Model Loss: 0.04250226 Interpreter Loss: 16106.192\n",
      "Epoch:[ 1 ] Batch: 778 / 937 Main Model Loss: 0.027658053 Interpreter Loss: 14888.677\n",
      "Epoch:[ 1 ] Batch: 779 / 937 Main Model Loss: 0.1069743 Interpreter Loss: 16463.508\n",
      "Epoch:[ 1 ] Batch: 780 / 937 Main Model Loss: 0.04961756 Interpreter Loss: 14625.024\n",
      "Epoch:[ 1 ] Batch: 781 / 937 Main Model Loss: 0.0331093 Interpreter Loss: 14751.943\n",
      "Epoch:[ 1 ] Batch: 782 / 937 Main Model Loss: 0.010210819 Interpreter Loss: 14842.2705\n",
      "Epoch:[ 1 ] Batch: 783 / 937 Main Model Loss: 0.046219915 Interpreter Loss: 15472.033\n",
      "Epoch:[ 1 ] Batch: 784 / 937 Main Model Loss: 0.09764494 Interpreter Loss: 15434.872\n",
      "Epoch:[ 1 ] Batch: 785 / 937 Main Model Loss: 0.045272365 Interpreter Loss: 14556.297\n",
      "Epoch:[ 1 ] Batch: 786 / 937 Main Model Loss: 0.06779049 Interpreter Loss: 16042.149\n",
      "Epoch:[ 1 ] Batch: 787 / 937 Main Model Loss: 0.16119894 Interpreter Loss: 16689.58\n",
      "Epoch:[ 1 ] Batch: 788 / 937 Main Model Loss: 0.015221338 Interpreter Loss: 15107.816\n",
      "Epoch:[ 1 ] Batch: 789 / 937 Main Model Loss: 0.12439958 Interpreter Loss: 15669.031\n",
      "Epoch:[ 1 ] Batch: 790 / 937 Main Model Loss: 0.010425219 Interpreter Loss: 15039.677\n",
      "Epoch:[ 1 ] Batch: 791 / 937 Main Model Loss: 0.0076582823 Interpreter Loss: 14528.867\n",
      "Epoch:[ 1 ] Batch: 792 / 937 Main Model Loss: 0.03787382 Interpreter Loss: 15954.615\n",
      "Epoch:[ 1 ] Batch: 793 / 937 Main Model Loss: 0.0041196416 Interpreter Loss: 15380.732\n",
      "Epoch:[ 1 ] Batch: 794 / 937 Main Model Loss: 0.0109892115 Interpreter Loss: 15120.196\n",
      "Epoch:[ 1 ] Batch: 795 / 937 Main Model Loss: 0.10154241 Interpreter Loss: 16396.285\n",
      "Epoch:[ 1 ] Batch: 796 / 937 Main Model Loss: 0.046044648 Interpreter Loss: 15747.521\n",
      "Epoch:[ 1 ] Batch: 797 / 937 Main Model Loss: 0.008081898 Interpreter Loss: 14780.087\n",
      "Epoch:[ 1 ] Batch: 798 / 937 Main Model Loss: 0.0090222545 Interpreter Loss: 14979.95\n",
      "Epoch:[ 1 ] Batch: 799 / 937 Main Model Loss: 0.011975242 Interpreter Loss: 15912.982\n",
      "Epoch:[ 1 ] Batch: 800 / 937 Main Model Loss: 0.11971575 Interpreter Loss: 16569.432\n",
      "Epoch:[ 1 ] Batch: 801 / 937 Main Model Loss: 0.052499875 Interpreter Loss: 16779.445\n",
      "Epoch:[ 1 ] Batch: 802 / 937 Main Model Loss: 0.035011664 Interpreter Loss: 15553.914\n",
      "Epoch:[ 1 ] Batch: 803 / 937 Main Model Loss: 0.034348734 Interpreter Loss: 14893.451\n",
      "Epoch:[ 1 ] Batch: 804 / 937 Main Model Loss: 0.03662209 Interpreter Loss: 16058.319\n",
      "Epoch:[ 1 ] Batch: 805 / 937 Main Model Loss: 0.032748066 Interpreter Loss: 14715.2705\n",
      "Epoch:[ 1 ] Batch: 806 / 937 Main Model Loss: 0.03921004 Interpreter Loss: 15546.279\n",
      "Epoch:[ 1 ] Batch: 807 / 937 Main Model Loss: 0.06792024 Interpreter Loss: 14553.257\n",
      "Epoch:[ 1 ] Batch: 808 / 937 Main Model Loss: 0.019004935 Interpreter Loss: 15347.061\n",
      "Epoch:[ 1 ] Batch: 809 / 937 Main Model Loss: 0.041592866 Interpreter Loss: 14865.01\n",
      "Epoch:[ 1 ] Batch: 810 / 937 Main Model Loss: 0.012582002 Interpreter Loss: 14617.613\n",
      "Epoch:[ 1 ] Batch: 811 / 937 Main Model Loss: 0.10340751 Interpreter Loss: 15186.74\n",
      "Epoch:[ 1 ] Batch: 812 / 937 Main Model Loss: 0.1110512 Interpreter Loss: 15140.8125\n",
      "Epoch:[ 1 ] Batch: 813 / 937 Main Model Loss: 0.049287193 Interpreter Loss: 14806.717\n",
      "Epoch:[ 1 ] Batch: 814 / 937 Main Model Loss: 0.10345753 Interpreter Loss: 15584.405\n",
      "Epoch:[ 1 ] Batch: 815 / 937 Main Model Loss: 0.0417184 Interpreter Loss: 14624.48\n",
      "Epoch:[ 1 ] Batch: 816 / 937 Main Model Loss: 0.11653771 Interpreter Loss: 14631.293\n",
      "Epoch:[ 1 ] Batch: 817 / 937 Main Model Loss: 0.035752006 Interpreter Loss: 14860.343\n",
      "Epoch:[ 1 ] Batch: 818 / 937 Main Model Loss: 0.037712708 Interpreter Loss: 14736.343\n",
      "Epoch:[ 1 ] Batch: 819 / 937 Main Model Loss: 0.03025883 Interpreter Loss: 15848.66\n",
      "Epoch:[ 1 ] Batch: 820 / 937 Main Model Loss: 0.01680443 Interpreter Loss: 14984.2\n",
      "Epoch:[ 1 ] Batch: 821 / 937 Main Model Loss: 0.010324625 Interpreter Loss: 15173.263\n",
      "Epoch:[ 1 ] Batch: 822 / 937 Main Model Loss: 0.008789345 Interpreter Loss: 14677.908\n",
      "Epoch:[ 1 ] Batch: 823 / 937 Main Model Loss: 0.05455514 Interpreter Loss: 15350.074\n",
      "Epoch:[ 1 ] Batch: 824 / 937 Main Model Loss: 0.039519712 Interpreter Loss: 14860.478\n",
      "Epoch:[ 1 ] Batch: 825 / 937 Main Model Loss: 0.119824074 Interpreter Loss: 15642.471\n",
      "Epoch:[ 1 ] Batch: 826 / 937 Main Model Loss: 0.084291235 Interpreter Loss: 16228.783\n",
      "Epoch:[ 1 ] Batch: 827 / 937 Main Model Loss: 0.22487758 Interpreter Loss: 16474.879\n",
      "Epoch:[ 1 ] Batch: 828 / 937 Main Model Loss: 0.035300564 Interpreter Loss: 16277.141\n",
      "Epoch:[ 1 ] Batch: 829 / 937 Main Model Loss: 0.02133545 Interpreter Loss: 15847.455\n",
      "Epoch:[ 1 ] Batch: 830 / 937 Main Model Loss: 0.05244897 Interpreter Loss: 14886.868\n",
      "Epoch:[ 1 ] Batch: 831 / 937 Main Model Loss: 0.046480764 Interpreter Loss: 15013.339\n",
      "Epoch:[ 1 ] Batch: 832 / 937 Main Model Loss: 0.004320132 Interpreter Loss: 14350.309\n",
      "Epoch:[ 1 ] Batch: 833 / 937 Main Model Loss: 0.00628823 Interpreter Loss: 14107.62\n",
      "Epoch:[ 1 ] Batch: 834 / 937 Main Model Loss: 0.061885603 Interpreter Loss: 14789.778\n",
      "Epoch:[ 1 ] Batch: 835 / 937 Main Model Loss: 0.01629603 Interpreter Loss: 14595.068\n",
      "Epoch:[ 1 ] Batch: 836 / 937 Main Model Loss: 0.014541227 Interpreter Loss: 14568.45\n",
      "Epoch:[ 1 ] Batch: 837 / 937 Main Model Loss: 0.012978356 Interpreter Loss: 14430.194\n",
      "Epoch:[ 1 ] Batch: 838 / 937 Main Model Loss: 0.11826836 Interpreter Loss: 14990.384\n",
      "Epoch:[ 1 ] Batch: 839 / 937 Main Model Loss: 0.030294977 Interpreter Loss: 14802.746\n",
      "Epoch:[ 1 ] Batch: 840 / 937 Main Model Loss: 0.0069901543 Interpreter Loss: 13746.841\n",
      "Epoch:[ 1 ] Batch: 841 / 937 Main Model Loss: 0.053563464 Interpreter Loss: 15837.42\n",
      "Epoch:[ 1 ] Batch: 842 / 937 Main Model Loss: 0.02686527 Interpreter Loss: 15724.257\n",
      "Epoch:[ 1 ] Batch: 843 / 937 Main Model Loss: 0.035712622 Interpreter Loss: 15858.008\n",
      "Epoch:[ 1 ] Batch: 844 / 937 Main Model Loss: 0.047710687 Interpreter Loss: 15204.141\n",
      "Epoch:[ 1 ] Batch: 845 / 937 Main Model Loss: 0.008160239 Interpreter Loss: 14626.184\n",
      "Epoch:[ 1 ] Batch: 846 / 937 Main Model Loss: 0.008499118 Interpreter Loss: 15471.648\n",
      "Epoch:[ 1 ] Batch: 847 / 937 Main Model Loss: 0.050562352 Interpreter Loss: 13702.688\n",
      "Epoch:[ 1 ] Batch: 848 / 937 Main Model Loss: 0.022826534 Interpreter Loss: 14312.771\n",
      "Epoch:[ 1 ] Batch: 849 / 937 Main Model Loss: 0.009370441 Interpreter Loss: 15126.85\n",
      "Epoch:[ 1 ] Batch: 850 / 937 Main Model Loss: 0.019763844 Interpreter Loss: 15115.143\n",
      "Epoch:[ 1 ] Batch: 851 / 937 Main Model Loss: 0.009592397 Interpreter Loss: 15725.436\n",
      "Epoch:[ 1 ] Batch: 852 / 937 Main Model Loss: 0.065603 Interpreter Loss: 15608.15\n",
      "Epoch:[ 1 ] Batch: 853 / 937 Main Model Loss: 0.05318432 Interpreter Loss: 14942.996\n",
      "Epoch:[ 1 ] Batch: 854 / 937 Main Model Loss: 0.0046398477 Interpreter Loss: 14975.77\n",
      "Epoch:[ 1 ] Batch: 855 / 937 Main Model Loss: 0.024099862 Interpreter Loss: 15915.834\n",
      "Epoch:[ 1 ] Batch: 856 / 937 Main Model Loss: 0.015381178 Interpreter Loss: 15223.361\n",
      "Epoch:[ 1 ] Batch: 857 / 937 Main Model Loss: 0.05783805 Interpreter Loss: 15372.609\n",
      "Epoch:[ 1 ] Batch: 858 / 937 Main Model Loss: 0.024382938 Interpreter Loss: 15862.741\n",
      "Epoch:[ 1 ] Batch: 859 / 937 Main Model Loss: 0.015939586 Interpreter Loss: 15635.861\n",
      "Epoch:[ 1 ] Batch: 860 / 937 Main Model Loss: 0.013897537 Interpreter Loss: 14738.568\n",
      "Epoch:[ 1 ] Batch: 861 / 937 Main Model Loss: 0.0037859008 Interpreter Loss: 14807.28\n",
      "Epoch:[ 1 ] Batch: 862 / 937 Main Model Loss: 0.02499314 Interpreter Loss: 15066.645\n",
      "Epoch:[ 1 ] Batch: 863 / 937 Main Model Loss: 0.017322121 Interpreter Loss: 15243.295\n",
      "Epoch:[ 1 ] Batch: 864 / 937 Main Model Loss: 0.085768744 Interpreter Loss: 15041.488\n",
      "Epoch:[ 1 ] Batch: 865 / 937 Main Model Loss: 0.032034047 Interpreter Loss: 14711.359\n",
      "Epoch:[ 1 ] Batch: 866 / 937 Main Model Loss: 0.012160799 Interpreter Loss: 15038.098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 1 ] Batch: 867 / 937 Main Model Loss: 0.050139207 Interpreter Loss: 15718.445\n",
      "Epoch:[ 1 ] Batch: 868 / 937 Main Model Loss: 0.044425063 Interpreter Loss: 15475.466\n",
      "Epoch:[ 1 ] Batch: 869 / 937 Main Model Loss: 0.03469241 Interpreter Loss: 16365.013\n",
      "Epoch:[ 1 ] Batch: 870 / 937 Main Model Loss: 0.068868235 Interpreter Loss: 16042.35\n",
      "Epoch:[ 1 ] Batch: 871 / 937 Main Model Loss: 0.01521012 Interpreter Loss: 16077.989\n",
      "Epoch:[ 1 ] Batch: 872 / 937 Main Model Loss: 0.03536977 Interpreter Loss: 15323.647\n",
      "Epoch:[ 1 ] Batch: 873 / 937 Main Model Loss: 0.015150682 Interpreter Loss: 14855.289\n",
      "Epoch:[ 1 ] Batch: 874 / 937 Main Model Loss: 0.010942334 Interpreter Loss: 14582.489\n",
      "Epoch:[ 1 ] Batch: 875 / 937 Main Model Loss: 0.07997902 Interpreter Loss: 14868.639\n",
      "Epoch:[ 1 ] Batch: 876 / 937 Main Model Loss: 0.023523109 Interpreter Loss: 14845.143\n",
      "Epoch:[ 1 ] Batch: 877 / 937 Main Model Loss: 0.06517231 Interpreter Loss: 15415.763\n",
      "Epoch:[ 1 ] Batch: 878 / 937 Main Model Loss: 0.061998196 Interpreter Loss: 15126.477\n",
      "Epoch:[ 1 ] Batch: 879 / 937 Main Model Loss: 0.022099772 Interpreter Loss: 14996.637\n",
      "Epoch:[ 1 ] Batch: 880 / 937 Main Model Loss: 0.014867723 Interpreter Loss: 14421.493\n",
      "Epoch:[ 1 ] Batch: 881 / 937 Main Model Loss: 0.034683187 Interpreter Loss: 13837.223\n",
      "Epoch:[ 1 ] Batch: 882 / 937 Main Model Loss: 0.08149657 Interpreter Loss: 15294.836\n",
      "Epoch:[ 1 ] Batch: 883 / 937 Main Model Loss: 0.011584222 Interpreter Loss: 14769.014\n",
      "Epoch:[ 1 ] Batch: 884 / 937 Main Model Loss: 0.039032977 Interpreter Loss: 14652.068\n",
      "Epoch:[ 1 ] Batch: 885 / 937 Main Model Loss: 0.01391077 Interpreter Loss: 14502.928\n",
      "Epoch:[ 1 ] Batch: 886 / 937 Main Model Loss: 0.013355722 Interpreter Loss: 15470.143\n",
      "Epoch:[ 1 ] Batch: 887 / 937 Main Model Loss: 0.095112 Interpreter Loss: 15407.653\n",
      "Epoch:[ 1 ] Batch: 888 / 937 Main Model Loss: 0.016941732 Interpreter Loss: 15038.553\n",
      "Epoch:[ 1 ] Batch: 889 / 937 Main Model Loss: 0.0075413007 Interpreter Loss: 14110.645\n",
      "Epoch:[ 1 ] Batch: 890 / 937 Main Model Loss: 0.007756757 Interpreter Loss: 13990.039\n",
      "Epoch:[ 1 ] Batch: 891 / 937 Main Model Loss: 0.025224175 Interpreter Loss: 13641.059\n",
      "Epoch:[ 1 ] Batch: 892 / 937 Main Model Loss: 0.0018188704 Interpreter Loss: 13494.047\n",
      "Epoch:[ 1 ] Batch: 893 / 937 Main Model Loss: 0.021188723 Interpreter Loss: 14271.66\n",
      "Epoch:[ 1 ] Batch: 894 / 937 Main Model Loss: 0.062261518 Interpreter Loss: 15179.314\n",
      "Epoch:[ 1 ] Batch: 895 / 937 Main Model Loss: 0.010232009 Interpreter Loss: 15209.912\n",
      "Epoch:[ 1 ] Batch: 896 / 937 Main Model Loss: 0.011384639 Interpreter Loss: 14692.752\n",
      "Epoch:[ 1 ] Batch: 897 / 937 Main Model Loss: 0.012224549 Interpreter Loss: 14462.095\n",
      "Epoch:[ 1 ] Batch: 898 / 937 Main Model Loss: 0.058878124 Interpreter Loss: 15383.059\n",
      "Epoch:[ 1 ] Batch: 899 / 937 Main Model Loss: 0.011213176 Interpreter Loss: 14701.172\n",
      "Epoch:[ 1 ] Batch: 900 / 937 Main Model Loss: 0.05892323 Interpreter Loss: 15059.775\n",
      "Epoch:[ 1 ] Batch: 901 / 937 Main Model Loss: 0.016767465 Interpreter Loss: 14073.632\n",
      "Epoch:[ 1 ] Batch: 902 / 937 Main Model Loss: 0.12564123 Interpreter Loss: 14450.981\n",
      "Epoch:[ 1 ] Batch: 903 / 937 Main Model Loss: 0.010426596 Interpreter Loss: 13529.66\n",
      "Epoch:[ 1 ] Batch: 904 / 937 Main Model Loss: 0.048246507 Interpreter Loss: 14060.389\n",
      "Epoch:[ 1 ] Batch: 905 / 937 Main Model Loss: 0.0169168 Interpreter Loss: 14392.116\n",
      "Epoch:[ 1 ] Batch: 906 / 937 Main Model Loss: 0.040949296 Interpreter Loss: 14269.135\n",
      "Epoch:[ 1 ] Batch: 907 / 937 Main Model Loss: 0.0650117 Interpreter Loss: 14510.764\n",
      "Epoch:[ 1 ] Batch: 908 / 937 Main Model Loss: 0.0010554123 Interpreter Loss: 13005.441\n",
      "Epoch:[ 1 ] Batch: 909 / 937 Main Model Loss: 0.005270969 Interpreter Loss: 14072.219\n",
      "Epoch:[ 1 ] Batch: 910 / 937 Main Model Loss: 0.002248346 Interpreter Loss: 14409.587\n",
      "Epoch:[ 1 ] Batch: 911 / 937 Main Model Loss: 0.005771316 Interpreter Loss: 14630.608\n",
      "Epoch:[ 1 ] Batch: 912 / 937 Main Model Loss: 0.019561008 Interpreter Loss: 15301.268\n",
      "Epoch:[ 1 ] Batch: 913 / 937 Main Model Loss: 0.015345119 Interpreter Loss: 15100.504\n",
      "Epoch:[ 1 ] Batch: 914 / 937 Main Model Loss: 0.0032331776 Interpreter Loss: 13479.059\n",
      "Epoch:[ 1 ] Batch: 915 / 937 Main Model Loss: 0.0027158696 Interpreter Loss: 12943.93\n",
      "Epoch:[ 1 ] Batch: 916 / 937 Main Model Loss: 0.017131863 Interpreter Loss: 12868.6875\n",
      "Epoch:[ 1 ] Batch: 917 / 937 Main Model Loss: 0.0016627049 Interpreter Loss: 12472.74\n",
      "Epoch:[ 1 ] Batch: 918 / 937 Main Model Loss: 0.054115072 Interpreter Loss: 14156.945\n",
      "Epoch:[ 1 ] Batch: 919 / 937 Main Model Loss: 0.026601534 Interpreter Loss: 15151.529\n",
      "Epoch:[ 1 ] Batch: 920 / 937 Main Model Loss: 0.0021160578 Interpreter Loss: 14152.763\n",
      "Epoch:[ 1 ] Batch: 921 / 937 Main Model Loss: 0.00035422348 Interpreter Loss: 14140.004\n",
      "Epoch:[ 1 ] Batch: 922 / 937 Main Model Loss: 0.0012975135 Interpreter Loss: 13679.061\n",
      "Epoch:[ 1 ] Batch: 923 / 937 Main Model Loss: 0.001584007 Interpreter Loss: 13587.572\n",
      "Epoch:[ 1 ] Batch: 924 / 937 Main Model Loss: 0.00046128157 Interpreter Loss: 13982.351\n",
      "Epoch:[ 1 ] Batch: 925 / 937 Main Model Loss: 0.0050786836 Interpreter Loss: 14437.198\n",
      "Epoch:[ 1 ] Batch: 926 / 937 Main Model Loss: 0.008701554 Interpreter Loss: 15493.209\n",
      "Epoch:[ 1 ] Batch: 927 / 937 Main Model Loss: 0.046593595 Interpreter Loss: 17963.113\n",
      "Epoch:[ 1 ] Batch: 928 / 937 Main Model Loss: 0.039640952 Interpreter Loss: 18813.162\n",
      "Epoch:[ 1 ] Batch: 929 / 937 Main Model Loss: 0.0047554728 Interpreter Loss: 15224.577\n",
      "Epoch:[ 1 ] Batch: 930 / 937 Main Model Loss: 0.00454687 Interpreter Loss: 13392.03\n",
      "Epoch:[ 1 ] Batch: 931 / 937 Main Model Loss: 0.00392266 Interpreter Loss: 13992.438\n",
      "Epoch:[ 1 ] Batch: 932 / 937 Main Model Loss: 0.100048095 Interpreter Loss: 15671.147\n",
      "Epoch:[ 1 ] Batch: 933 / 937 Main Model Loss: 0.3276036 Interpreter Loss: 16039.879\n",
      "Epoch:[ 1 ] Batch: 934 / 937 Main Model Loss: 0.004533226 Interpreter Loss: 14818.19\n",
      "Epoch:[ 1 ] Batch: 935 / 937 Main Model Loss: 0.0020152964 Interpreter Loss: 14851.279\n",
      "Epoch:[ 1 ] Batch: 936 / 937 Main Model Loss: 0.2464131 Interpreter Loss: 13361.939\n",
      " Main Model Acc:  0.984375 Interpreter Acc:  0.5625\n",
      "INFO:tensorflow:Assets written to: checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 2 ] Batch: 0 / 937 Main Model Loss: 0.035283074 Interpreter Loss: 14685.544\n",
      "Epoch:[ 2 ] Batch: 1 / 937 Main Model Loss: 0.08336418 Interpreter Loss: 14837.084\n",
      "Epoch:[ 2 ] Batch: 2 / 937 Main Model Loss: 0.13215755 Interpreter Loss: 14562.756\n",
      "Epoch:[ 2 ] Batch: 3 / 937 Main Model Loss: 0.02573736 Interpreter Loss: 14914.54\n",
      "Epoch:[ 2 ] Batch: 4 / 937 Main Model Loss: 0.013807533 Interpreter Loss: 14028.422\n",
      "Epoch:[ 2 ] Batch: 5 / 937 Main Model Loss: 0.008007969 Interpreter Loss: 14025.156\n",
      "Epoch:[ 2 ] Batch: 6 / 937 Main Model Loss: 0.0544623 Interpreter Loss: 14889.824\n",
      "Epoch:[ 2 ] Batch: 7 / 937 Main Model Loss: 0.065157525 Interpreter Loss: 14426.581\n",
      "Epoch:[ 2 ] Batch: 8 / 937 Main Model Loss: 0.011177156 Interpreter Loss: 14342.378\n",
      "Epoch:[ 2 ] Batch: 9 / 937 Main Model Loss: 0.040804952 Interpreter Loss: 14101.08\n",
      "Epoch:[ 2 ] Batch: 10 / 937 Main Model Loss: 0.009006472 Interpreter Loss: 14485.722\n",
      "Epoch:[ 2 ] Batch: 11 / 937 Main Model Loss: 0.07847708 Interpreter Loss: 15634.215\n",
      "Epoch:[ 2 ] Batch: 12 / 937 Main Model Loss: 0.052941874 Interpreter Loss: 14980.324\n",
      "Epoch:[ 2 ] Batch: 13 / 937 Main Model Loss: 0.047639202 Interpreter Loss: 15673.158\n",
      "Epoch:[ 2 ] Batch: 14 / 937 Main Model Loss: 0.05016762 Interpreter Loss: 14997.566\n",
      "Epoch:[ 2 ] Batch: 15 / 937 Main Model Loss: 0.04373671 Interpreter Loss: 15182.441\n",
      "Epoch:[ 2 ] Batch: 16 / 937 Main Model Loss: 0.024766091 Interpreter Loss: 15169.955\n",
      "Epoch:[ 2 ] Batch: 17 / 937 Main Model Loss: 0.06502509 Interpreter Loss: 14831.949\n",
      "Epoch:[ 2 ] Batch: 18 / 937 Main Model Loss: 0.03790067 Interpreter Loss: 15362.991\n",
      "Epoch:[ 2 ] Batch: 19 / 937 Main Model Loss: 0.019357283 Interpreter Loss: 17432.26\n",
      "Epoch:[ 2 ] Batch: 20 / 937 Main Model Loss: 0.014830256 Interpreter Loss: 15995.71\n",
      "Epoch:[ 2 ] Batch: 21 / 937 Main Model Loss: 0.08507921 Interpreter Loss: 17430.297\n",
      "Epoch:[ 2 ] Batch: 22 / 937 Main Model Loss: 0.008500416 Interpreter Loss: 14248.178\n",
      "Epoch:[ 2 ] Batch: 23 / 937 Main Model Loss: 0.010860956 Interpreter Loss: 14786.102\n",
      "Epoch:[ 2 ] Batch: 24 / 937 Main Model Loss: 0.0051789614 Interpreter Loss: 14434.828\n",
      "Epoch:[ 2 ] Batch: 25 / 937 Main Model Loss: 0.06728419 Interpreter Loss: 13926.2295\n",
      "Epoch:[ 2 ] Batch: 26 / 937 Main Model Loss: 0.0075604715 Interpreter Loss: 13899.66\n",
      "Epoch:[ 2 ] Batch: 27 / 937 Main Model Loss: 0.02219143 Interpreter Loss: 14361.815\n",
      "Epoch:[ 2 ] Batch: 28 / 937 Main Model Loss: 0.0077157207 Interpreter Loss: 13947.434\n",
      "Epoch:[ 2 ] Batch: 29 / 937 Main Model Loss: 0.033185717 Interpreter Loss: 15285.693\n",
      "Epoch:[ 2 ] Batch: 30 / 937 Main Model Loss: 0.11095015 Interpreter Loss: 15579.182\n",
      "Epoch:[ 2 ] Batch: 31 / 937 Main Model Loss: 0.053957574 Interpreter Loss: 15539.23\n",
      "Epoch:[ 2 ] Batch: 32 / 937 Main Model Loss: 0.0037900642 Interpreter Loss: 14678.003\n",
      "Epoch:[ 2 ] Batch: 33 / 937 Main Model Loss: 0.009630717 Interpreter Loss: 14296.581\n",
      "Epoch:[ 2 ] Batch: 34 / 937 Main Model Loss: 0.017851327 Interpreter Loss: 14501.879\n",
      "Epoch:[ 2 ] Batch: 35 / 937 Main Model Loss: 0.024185354 Interpreter Loss: 15215.728\n",
      "Epoch:[ 2 ] Batch: 36 / 937 Main Model Loss: 0.0071008964 Interpreter Loss: 14099.736\n",
      "Epoch:[ 2 ] Batch: 37 / 937 Main Model Loss: 0.036929976 Interpreter Loss: 14770.119\n",
      "Epoch:[ 2 ] Batch: 38 / 937 Main Model Loss: 0.012785518 Interpreter Loss: 14182.536\n",
      "Epoch:[ 2 ] Batch: 39 / 937 Main Model Loss: 0.006111557 Interpreter Loss: 14485.768\n",
      "Epoch:[ 2 ] Batch: 40 / 937 Main Model Loss: 0.018869359 Interpreter Loss: 14832.407\n",
      "Epoch:[ 2 ] Batch: 41 / 937 Main Model Loss: 0.15513696 Interpreter Loss: 14808.641\n",
      "Epoch:[ 2 ] Batch: 42 / 937 Main Model Loss: 0.06291465 Interpreter Loss: 14246.258\n",
      "Epoch:[ 2 ] Batch: 43 / 937 Main Model Loss: 0.019360825 Interpreter Loss: 14910.125\n",
      "Epoch:[ 2 ] Batch: 44 / 937 Main Model Loss: 0.009246213 Interpreter Loss: 15219.022\n",
      "Epoch:[ 2 ] Batch: 45 / 937 Main Model Loss: 0.029668992 Interpreter Loss: 14759.02\n",
      "Epoch:[ 2 ] Batch: 46 / 937 Main Model Loss: 0.010748403 Interpreter Loss: 13581.886\n",
      "Epoch:[ 2 ] Batch: 47 / 937 Main Model Loss: 0.06909 Interpreter Loss: 14689.534\n",
      "Epoch:[ 2 ] Batch: 48 / 937 Main Model Loss: 0.007993984 Interpreter Loss: 13700.1455\n",
      "Epoch:[ 2 ] Batch: 49 / 937 Main Model Loss: 0.0010138177 Interpreter Loss: 13386.997\n",
      "Epoch:[ 2 ] Batch: 50 / 937 Main Model Loss: 0.033537824 Interpreter Loss: 13928.495\n",
      "Epoch:[ 2 ] Batch: 51 / 937 Main Model Loss: 0.0103598 Interpreter Loss: 13975.706\n",
      "Epoch:[ 2 ] Batch: 52 / 937 Main Model Loss: 0.0027596229 Interpreter Loss: 14014.143\n",
      "Epoch:[ 2 ] Batch: 53 / 937 Main Model Loss: 0.016371032 Interpreter Loss: 13807.316\n",
      "Epoch:[ 2 ] Batch: 54 / 937 Main Model Loss: 0.017277028 Interpreter Loss: 14414.981\n",
      "Epoch:[ 2 ] Batch: 55 / 937 Main Model Loss: 0.021239568 Interpreter Loss: 14226.488\n",
      "Epoch:[ 2 ] Batch: 56 / 937 Main Model Loss: 0.031712893 Interpreter Loss: 14895.796\n",
      "Epoch:[ 2 ] Batch: 57 / 937 Main Model Loss: 0.099146225 Interpreter Loss: 15140.612\n",
      "Epoch:[ 2 ] Batch: 58 / 937 Main Model Loss: 0.018854957 Interpreter Loss: 14637.697\n",
      "Epoch:[ 2 ] Batch: 59 / 937 Main Model Loss: 0.026358053 Interpreter Loss: 14584.971\n",
      "Epoch:[ 2 ] Batch: 60 / 937 Main Model Loss: 0.0034266906 Interpreter Loss: 14144.741\n",
      "Epoch:[ 2 ] Batch: 61 / 937 Main Model Loss: 0.0061892387 Interpreter Loss: 13937.826\n",
      "Epoch:[ 2 ] Batch: 62 / 937 Main Model Loss: 0.033103596 Interpreter Loss: 14380.3545\n",
      "Epoch:[ 2 ] Batch: 63 / 937 Main Model Loss: 0.006156493 Interpreter Loss: 14986.873\n",
      "Epoch:[ 2 ] Batch: 64 / 937 Main Model Loss: 0.017050203 Interpreter Loss: 14329.173\n",
      "Epoch:[ 2 ] Batch: 65 / 937 Main Model Loss: 0.008742789 Interpreter Loss: 13883.144\n",
      "Epoch:[ 2 ] Batch: 66 / 937 Main Model Loss: 0.010718093 Interpreter Loss: 14585.889\n",
      "Epoch:[ 2 ] Batch: 67 / 937 Main Model Loss: 0.036300495 Interpreter Loss: 14315.075\n",
      "Epoch:[ 2 ] Batch: 68 / 937 Main Model Loss: 0.018711181 Interpreter Loss: 13644.127\n",
      "Epoch:[ 2 ] Batch: 69 / 937 Main Model Loss: 0.1565306 Interpreter Loss: 14139.123\n",
      "Epoch:[ 2 ] Batch: 70 / 937 Main Model Loss: 0.0062671206 Interpreter Loss: 15043.102\n",
      "Epoch:[ 2 ] Batch: 71 / 937 Main Model Loss: 0.03381673 Interpreter Loss: 14419.327\n",
      "Epoch:[ 2 ] Batch: 72 / 937 Main Model Loss: 0.05463334 Interpreter Loss: 15831.63\n",
      "Epoch:[ 2 ] Batch: 73 / 937 Main Model Loss: 0.018120501 Interpreter Loss: 15658.939\n",
      "Epoch:[ 2 ] Batch: 74 / 937 Main Model Loss: 0.01743678 Interpreter Loss: 15149.282\n",
      "Epoch:[ 2 ] Batch: 75 / 937 Main Model Loss: 0.01478424 Interpreter Loss: 15071.898\n",
      "Epoch:[ 2 ] Batch: 76 / 937 Main Model Loss: 0.002550624 Interpreter Loss: 14293.394\n",
      "Epoch:[ 2 ] Batch: 77 / 937 Main Model Loss: 0.02520504 Interpreter Loss: 14695.275\n",
      "Epoch:[ 2 ] Batch: 78 / 937 Main Model Loss: 0.033003714 Interpreter Loss: 14795.869\n",
      "Epoch:[ 2 ] Batch: 79 / 937 Main Model Loss: 0.022950904 Interpreter Loss: 15233.153\n",
      "Epoch:[ 2 ] Batch: 80 / 937 Main Model Loss: 0.03540928 Interpreter Loss: 15360.45\n",
      "Epoch:[ 2 ] Batch: 81 / 937 Main Model Loss: 0.012512363 Interpreter Loss: 14736.427\n",
      "Epoch:[ 2 ] Batch: 82 / 937 Main Model Loss: 0.016315227 Interpreter Loss: 14877.678\n",
      "Epoch:[ 2 ] Batch: 83 / 937 Main Model Loss: 0.04204331 Interpreter Loss: 15879.07\n",
      "Epoch:[ 2 ] Batch: 84 / 937 Main Model Loss: 0.03001476 Interpreter Loss: 15299.798\n",
      "Epoch:[ 2 ] Batch: 85 / 937 Main Model Loss: 0.01654734 Interpreter Loss: 15073.962\n",
      "Epoch:[ 2 ] Batch: 86 / 937 Main Model Loss: 0.032227635 Interpreter Loss: 15118.292\n",
      "Epoch:[ 2 ] Batch: 87 / 937 Main Model Loss: 0.010060559 Interpreter Loss: 14465.741\n",
      "Epoch:[ 2 ] Batch: 88 / 937 Main Model Loss: 0.037277587 Interpreter Loss: 15054.193\n",
      "Epoch:[ 2 ] Batch: 89 / 937 Main Model Loss: 0.090852484 Interpreter Loss: 15194.446\n",
      "Epoch:[ 2 ] Batch: 90 / 937 Main Model Loss: 0.026038637 Interpreter Loss: 14138.763\n",
      "Epoch:[ 2 ] Batch: 91 / 937 Main Model Loss: 0.02256846 Interpreter Loss: 14220.644\n",
      "Epoch:[ 2 ] Batch: 92 / 937 Main Model Loss: 0.066400036 Interpreter Loss: 14243.942\n",
      "Epoch:[ 2 ] Batch: 93 / 937 Main Model Loss: 0.0046211793 Interpreter Loss: 15399.601\n",
      "Epoch:[ 2 ] Batch: 94 / 937 Main Model Loss: 0.032808773 Interpreter Loss: 15725.109\n",
      "Epoch:[ 2 ] Batch: 95 / 937 Main Model Loss: 0.064101286 Interpreter Loss: 15571.698\n",
      "Epoch:[ 2 ] Batch: 96 / 937 Main Model Loss: 0.008667007 Interpreter Loss: 15215.162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 2 ] Batch: 97 / 937 Main Model Loss: 0.03439462 Interpreter Loss: 15314.537\n",
      "Epoch:[ 2 ] Batch: 98 / 937 Main Model Loss: 0.024905631 Interpreter Loss: 15076.747\n",
      "Epoch:[ 2 ] Batch: 99 / 937 Main Model Loss: 0.049578577 Interpreter Loss: 14848.293\n",
      "Epoch:[ 2 ] Batch: 100 / 937 Main Model Loss: 0.048435494 Interpreter Loss: 15229.096\n",
      "Epoch:[ 2 ] Batch: 101 / 937 Main Model Loss: 0.023126876 Interpreter Loss: 14301.453\n",
      "Epoch:[ 2 ] Batch: 102 / 937 Main Model Loss: 0.0023416928 Interpreter Loss: 13327.178\n",
      "Epoch:[ 2 ] Batch: 103 / 937 Main Model Loss: 0.018073106 Interpreter Loss: 14508.811\n",
      "Epoch:[ 2 ] Batch: 104 / 937 Main Model Loss: 0.035326738 Interpreter Loss: 13411.916\n",
      "Epoch:[ 2 ] Batch: 105 / 937 Main Model Loss: 0.005595193 Interpreter Loss: 13016.5625\n",
      "Epoch:[ 2 ] Batch: 106 / 937 Main Model Loss: 0.0761162 Interpreter Loss: 13433.154\n",
      "Epoch:[ 2 ] Batch: 107 / 937 Main Model Loss: 0.06625022 Interpreter Loss: 15248.572\n",
      "Epoch:[ 2 ] Batch: 108 / 937 Main Model Loss: 0.010767123 Interpreter Loss: 15263.716\n",
      "Epoch:[ 2 ] Batch: 109 / 937 Main Model Loss: 0.091363415 Interpreter Loss: 14590.996\n",
      "Epoch:[ 2 ] Batch: 110 / 937 Main Model Loss: 0.03785416 Interpreter Loss: 13960.869\n",
      "Epoch:[ 2 ] Batch: 111 / 937 Main Model Loss: 0.010619406 Interpreter Loss: 13849.184\n",
      "Epoch:[ 2 ] Batch: 112 / 937 Main Model Loss: 0.015059088 Interpreter Loss: 13448.973\n",
      "Epoch:[ 2 ] Batch: 113 / 937 Main Model Loss: 0.11587626 Interpreter Loss: 14944.009\n",
      "Epoch:[ 2 ] Batch: 114 / 937 Main Model Loss: 0.016587786 Interpreter Loss: 12914.012\n",
      "Epoch:[ 2 ] Batch: 115 / 937 Main Model Loss: 0.0076220143 Interpreter Loss: 12905.196\n",
      "Epoch:[ 2 ] Batch: 116 / 937 Main Model Loss: 0.00752653 Interpreter Loss: 13524.747\n",
      "Epoch:[ 2 ] Batch: 117 / 937 Main Model Loss: 0.009230745 Interpreter Loss: 13474.816\n",
      "Epoch:[ 2 ] Batch: 118 / 937 Main Model Loss: 0.050364174 Interpreter Loss: 13885.047\n",
      "Epoch:[ 2 ] Batch: 119 / 937 Main Model Loss: 0.018742131 Interpreter Loss: 14301.559\n",
      "Epoch:[ 2 ] Batch: 120 / 937 Main Model Loss: 0.025773438 Interpreter Loss: 14498.767\n",
      "Epoch:[ 2 ] Batch: 121 / 937 Main Model Loss: 0.02957493 Interpreter Loss: 14650.084\n",
      "Epoch:[ 2 ] Batch: 122 / 937 Main Model Loss: 0.007970307 Interpreter Loss: 15266.895\n",
      "Epoch:[ 2 ] Batch: 123 / 937 Main Model Loss: 0.018536674 Interpreter Loss: 15640.982\n",
      "Epoch:[ 2 ] Batch: 124 / 937 Main Model Loss: 0.070731245 Interpreter Loss: 14994.641\n",
      "Epoch:[ 2 ] Batch: 125 / 937 Main Model Loss: 0.01428549 Interpreter Loss: 14761.43\n",
      "Epoch:[ 2 ] Batch: 126 / 937 Main Model Loss: 0.11117168 Interpreter Loss: 15455.41\n",
      "Epoch:[ 2 ] Batch: 127 / 937 Main Model Loss: 0.006059534 Interpreter Loss: 13182.524\n",
      "Epoch:[ 2 ] Batch: 128 / 937 Main Model Loss: 0.19624734 Interpreter Loss: 14529.685\n",
      "Epoch:[ 2 ] Batch: 129 / 937 Main Model Loss: 0.03589372 Interpreter Loss: 15530.241\n",
      "Epoch:[ 2 ] Batch: 130 / 937 Main Model Loss: 0.034110434 Interpreter Loss: 14597.146\n",
      "Epoch:[ 2 ] Batch: 131 / 937 Main Model Loss: 0.016301846 Interpreter Loss: 14233.755\n",
      "Epoch:[ 2 ] Batch: 132 / 937 Main Model Loss: 0.06695343 Interpreter Loss: 16622.75\n",
      "Epoch:[ 2 ] Batch: 133 / 937 Main Model Loss: 0.012874812 Interpreter Loss: 15435.146\n",
      "Epoch:[ 2 ] Batch: 134 / 937 Main Model Loss: 0.016956594 Interpreter Loss: 15117.818\n",
      "Epoch:[ 2 ] Batch: 135 / 937 Main Model Loss: 0.026242811 Interpreter Loss: 16332.389\n",
      "Epoch:[ 2 ] Batch: 136 / 937 Main Model Loss: 0.1879406 Interpreter Loss: 15329.537\n",
      "Epoch:[ 2 ] Batch: 137 / 937 Main Model Loss: 0.009121256 Interpreter Loss: 14857.953\n",
      "Epoch:[ 2 ] Batch: 138 / 937 Main Model Loss: 0.08287941 Interpreter Loss: 15293.345\n",
      "Epoch:[ 2 ] Batch: 139 / 937 Main Model Loss: 0.018688908 Interpreter Loss: 14339.757\n",
      "Epoch:[ 2 ] Batch: 140 / 937 Main Model Loss: 0.04158984 Interpreter Loss: 13847.219\n",
      "Epoch:[ 2 ] Batch: 141 / 937 Main Model Loss: 0.023932941 Interpreter Loss: 13918.777\n",
      "Epoch:[ 2 ] Batch: 142 / 937 Main Model Loss: 0.027230617 Interpreter Loss: 13533.896\n",
      "Epoch:[ 2 ] Batch: 143 / 937 Main Model Loss: 0.012625908 Interpreter Loss: 13926.909\n",
      "Epoch:[ 2 ] Batch: 144 / 937 Main Model Loss: 0.029033806 Interpreter Loss: 13474.278\n",
      "Epoch:[ 2 ] Batch: 145 / 937 Main Model Loss: 0.013618058 Interpreter Loss: 14582.486\n",
      "Epoch:[ 2 ] Batch: 146 / 937 Main Model Loss: 0.034750856 Interpreter Loss: 15594.998\n",
      "Epoch:[ 2 ] Batch: 147 / 937 Main Model Loss: 0.048904724 Interpreter Loss: 15329.543\n",
      "Epoch:[ 2 ] Batch: 148 / 937 Main Model Loss: 0.016671566 Interpreter Loss: 14884.059\n",
      "Epoch:[ 2 ] Batch: 149 / 937 Main Model Loss: 0.024240613 Interpreter Loss: 13509.163\n",
      "Epoch:[ 2 ] Batch: 150 / 937 Main Model Loss: 0.017220028 Interpreter Loss: 14566.242\n",
      "Epoch:[ 2 ] Batch: 151 / 937 Main Model Loss: 0.008279391 Interpreter Loss: 14446.663\n",
      "Epoch:[ 2 ] Batch: 152 / 937 Main Model Loss: 0.085553326 Interpreter Loss: 14848.225\n",
      "Epoch:[ 2 ] Batch: 153 / 937 Main Model Loss: 0.004602784 Interpreter Loss: 13762.186\n",
      "Epoch:[ 2 ] Batch: 154 / 937 Main Model Loss: 0.00095740356 Interpreter Loss: 13603.222\n",
      "Epoch:[ 2 ] Batch: 155 / 937 Main Model Loss: 0.0033060673 Interpreter Loss: 13978.35\n",
      "Epoch:[ 2 ] Batch: 156 / 937 Main Model Loss: 0.01728682 Interpreter Loss: 14801.696\n",
      "Epoch:[ 2 ] Batch: 157 / 937 Main Model Loss: 0.06688253 Interpreter Loss: 13873.747\n",
      "Epoch:[ 2 ] Batch: 158 / 937 Main Model Loss: 0.016791368 Interpreter Loss: 13330.064\n",
      "Epoch:[ 2 ] Batch: 159 / 937 Main Model Loss: 0.020612007 Interpreter Loss: 17684.723\n",
      "Epoch:[ 2 ] Batch: 160 / 937 Main Model Loss: 0.14965849 Interpreter Loss: 17239.021\n",
      "Epoch:[ 2 ] Batch: 161 / 937 Main Model Loss: 0.017693158 Interpreter Loss: 14958.763\n",
      "Epoch:[ 2 ] Batch: 162 / 937 Main Model Loss: 0.020873819 Interpreter Loss: 14799.72\n",
      "Epoch:[ 2 ] Batch: 163 / 937 Main Model Loss: 0.0019004839 Interpreter Loss: 14707.662\n",
      "Epoch:[ 2 ] Batch: 164 / 937 Main Model Loss: 0.0035113392 Interpreter Loss: 14275.6875\n",
      "Epoch:[ 2 ] Batch: 165 / 937 Main Model Loss: 0.004590332 Interpreter Loss: 13852.346\n",
      "Epoch:[ 2 ] Batch: 166 / 937 Main Model Loss: 0.0056168204 Interpreter Loss: 13231.27\n",
      "Epoch:[ 2 ] Batch: 167 / 937 Main Model Loss: 0.009660208 Interpreter Loss: 14049.886\n",
      "Epoch:[ 2 ] Batch: 168 / 937 Main Model Loss: 0.1043838 Interpreter Loss: 15827.953\n",
      "Epoch:[ 2 ] Batch: 169 / 937 Main Model Loss: 0.04090643 Interpreter Loss: 14384.676\n",
      "Epoch:[ 2 ] Batch: 170 / 937 Main Model Loss: 0.011066474 Interpreter Loss: 14288.233\n",
      "Epoch:[ 2 ] Batch: 171 / 937 Main Model Loss: 0.11165683 Interpreter Loss: 15050.588\n",
      "Epoch:[ 2 ] Batch: 172 / 937 Main Model Loss: 0.033303812 Interpreter Loss: 14992.549\n",
      "Epoch:[ 2 ] Batch: 173 / 937 Main Model Loss: 0.0089711845 Interpreter Loss: 13981.528\n",
      "Epoch:[ 2 ] Batch: 174 / 937 Main Model Loss: 0.02958079 Interpreter Loss: 14781.865\n",
      "Epoch:[ 2 ] Batch: 175 / 937 Main Model Loss: 0.060184166 Interpreter Loss: 14209.764\n",
      "Epoch:[ 2 ] Batch: 176 / 937 Main Model Loss: 0.0048768846 Interpreter Loss: 13529.861\n",
      "Epoch:[ 2 ] Batch: 177 / 937 Main Model Loss: 0.03189715 Interpreter Loss: 14561.181\n",
      "Epoch:[ 2 ] Batch: 178 / 937 Main Model Loss: 0.012233476 Interpreter Loss: 13900.883\n",
      "Epoch:[ 2 ] Batch: 179 / 937 Main Model Loss: 0.008873847 Interpreter Loss: 14032.195\n",
      "Epoch:[ 2 ] Batch: 180 / 937 Main Model Loss: 0.017274579 Interpreter Loss: 14481.215\n",
      "Epoch:[ 2 ] Batch: 181 / 937 Main Model Loss: 0.02242559 Interpreter Loss: 14937.693\n",
      "Epoch:[ 2 ] Batch: 182 / 937 Main Model Loss: 0.012798002 Interpreter Loss: 14865.358\n",
      "Epoch:[ 2 ] Batch: 183 / 937 Main Model Loss: 0.026966207 Interpreter Loss: 14586.538\n",
      "Epoch:[ 2 ] Batch: 184 / 937 Main Model Loss: 0.044973657 Interpreter Loss: 14673.621\n",
      "Epoch:[ 2 ] Batch: 185 / 937 Main Model Loss: 0.039241746 Interpreter Loss: 14435.437\n",
      "Epoch:[ 2 ] Batch: 186 / 937 Main Model Loss: 0.017591424 Interpreter Loss: 14206.398\n",
      "Epoch:[ 2 ] Batch: 187 / 937 Main Model Loss: 0.04400414 Interpreter Loss: 15169.941\n",
      "Epoch:[ 2 ] Batch: 188 / 937 Main Model Loss: 0.008493321 Interpreter Loss: 14957.744\n",
      "Epoch:[ 2 ] Batch: 189 / 937 Main Model Loss: 0.013468156 Interpreter Loss: 14272.3125\n",
      "Epoch:[ 2 ] Batch: 190 / 937 Main Model Loss: 0.008903097 Interpreter Loss: 14738.254\n",
      "Epoch:[ 2 ] Batch: 191 / 937 Main Model Loss: 0.025846269 Interpreter Loss: 15147.562\n",
      "Epoch:[ 2 ] Batch: 192 / 937 Main Model Loss: 0.028344303 Interpreter Loss: 14872.832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 2 ] Batch: 193 / 937 Main Model Loss: 0.023308773 Interpreter Loss: 15042.053\n",
      "Epoch:[ 2 ] Batch: 194 / 937 Main Model Loss: 0.018238619 Interpreter Loss: 14754.71\n",
      "Epoch:[ 2 ] Batch: 195 / 937 Main Model Loss: 0.008882061 Interpreter Loss: 14352.029\n",
      "Epoch:[ 2 ] Batch: 196 / 937 Main Model Loss: 0.037664432 Interpreter Loss: 15269.131\n",
      "Epoch:[ 2 ] Batch: 197 / 937 Main Model Loss: 0.030596405 Interpreter Loss: 15409.104\n",
      "Epoch:[ 2 ] Batch: 198 / 937 Main Model Loss: 0.018897094 Interpreter Loss: 14629.345\n",
      "Epoch:[ 2 ] Batch: 199 / 937 Main Model Loss: 0.038326923 Interpreter Loss: 13522.258\n",
      "Epoch:[ 2 ] Batch: 200 / 937 Main Model Loss: 0.025524184 Interpreter Loss: 13539.554\n",
      "Epoch:[ 2 ] Batch: 201 / 937 Main Model Loss: 0.022415763 Interpreter Loss: 14140.857\n",
      "Epoch:[ 2 ] Batch: 202 / 937 Main Model Loss: 0.026258312 Interpreter Loss: 15704.915\n",
      "Epoch:[ 2 ] Batch: 203 / 937 Main Model Loss: 0.064007215 Interpreter Loss: 15804.697\n",
      "Epoch:[ 2 ] Batch: 204 / 937 Main Model Loss: 0.03153263 Interpreter Loss: 16138.459\n",
      "Epoch:[ 2 ] Batch: 205 / 937 Main Model Loss: 0.016743783 Interpreter Loss: 14786.788\n",
      "Epoch:[ 2 ] Batch: 206 / 937 Main Model Loss: 0.013761226 Interpreter Loss: 15275.6\n",
      "Epoch:[ 2 ] Batch: 207 / 937 Main Model Loss: 0.0041771876 Interpreter Loss: 14604.916\n",
      "Epoch:[ 2 ] Batch: 208 / 937 Main Model Loss: 0.01252846 Interpreter Loss: 14548.604\n",
      "Epoch:[ 2 ] Batch: 209 / 937 Main Model Loss: 0.06025527 Interpreter Loss: 14585.1\n",
      "Epoch:[ 2 ] Batch: 210 / 937 Main Model Loss: 0.007062339 Interpreter Loss: 14566.115\n",
      "Epoch:[ 2 ] Batch: 211 / 937 Main Model Loss: 0.082109995 Interpreter Loss: 15594.217\n",
      "Epoch:[ 2 ] Batch: 212 / 937 Main Model Loss: 0.005993399 Interpreter Loss: 14285.773\n",
      "Epoch:[ 2 ] Batch: 213 / 937 Main Model Loss: 0.02374287 Interpreter Loss: 13664.473\n",
      "Epoch:[ 2 ] Batch: 214 / 937 Main Model Loss: 0.014142431 Interpreter Loss: 13329.287\n",
      "Epoch:[ 2 ] Batch: 215 / 937 Main Model Loss: 0.0082159005 Interpreter Loss: 13397.219\n",
      "Epoch:[ 2 ] Batch: 216 / 937 Main Model Loss: 0.029049905 Interpreter Loss: 14282.408\n",
      "Epoch:[ 2 ] Batch: 217 / 937 Main Model Loss: 0.010898329 Interpreter Loss: 14347.799\n",
      "Epoch:[ 2 ] Batch: 218 / 937 Main Model Loss: 0.075456224 Interpreter Loss: 13984.255\n",
      "Epoch:[ 2 ] Batch: 219 / 937 Main Model Loss: 0.012345832 Interpreter Loss: 15015.333\n",
      "Epoch:[ 2 ] Batch: 220 / 937 Main Model Loss: 0.00453943 Interpreter Loss: 15011.413\n",
      "Epoch:[ 2 ] Batch: 221 / 937 Main Model Loss: 0.00997135 Interpreter Loss: 15377.303\n",
      "Epoch:[ 2 ] Batch: 222 / 937 Main Model Loss: 0.019433016 Interpreter Loss: 15061.501\n",
      "Epoch:[ 2 ] Batch: 223 / 937 Main Model Loss: 0.01061628 Interpreter Loss: 15182.56\n",
      "Epoch:[ 2 ] Batch: 224 / 937 Main Model Loss: 0.06387144 Interpreter Loss: 15398.003\n",
      "Epoch:[ 2 ] Batch: 225 / 937 Main Model Loss: 0.031352144 Interpreter Loss: 13747.622\n",
      "Epoch:[ 2 ] Batch: 226 / 937 Main Model Loss: 0.0037302908 Interpreter Loss: 13389.317\n",
      "Epoch:[ 2 ] Batch: 227 / 937 Main Model Loss: 0.07359273 Interpreter Loss: 13900.066\n",
      "Epoch:[ 2 ] Batch: 228 / 937 Main Model Loss: 0.010286326 Interpreter Loss: 13970.341\n",
      "Epoch:[ 2 ] Batch: 229 / 937 Main Model Loss: 0.031488553 Interpreter Loss: 14646.199\n",
      "Epoch:[ 2 ] Batch: 230 / 937 Main Model Loss: 0.023696711 Interpreter Loss: 14936.301\n",
      "Epoch:[ 2 ] Batch: 231 / 937 Main Model Loss: 0.017134154 Interpreter Loss: 14614.109\n",
      "Epoch:[ 2 ] Batch: 232 / 937 Main Model Loss: 0.00900493 Interpreter Loss: 13896.504\n",
      "Epoch:[ 2 ] Batch: 233 / 937 Main Model Loss: 0.0064183385 Interpreter Loss: 13684.953\n",
      "Epoch:[ 2 ] Batch: 234 / 937 Main Model Loss: 0.0014227312 Interpreter Loss: 12854.295\n",
      "Epoch:[ 2 ] Batch: 235 / 937 Main Model Loss: 0.019083539 Interpreter Loss: 13812.812\n",
      "Epoch:[ 2 ] Batch: 236 / 937 Main Model Loss: 0.038971905 Interpreter Loss: 13927.691\n",
      "Epoch:[ 2 ] Batch: 237 / 937 Main Model Loss: 0.014404686 Interpreter Loss: 13498.928\n",
      "Epoch:[ 2 ] Batch: 238 / 937 Main Model Loss: 0.035441253 Interpreter Loss: 13587.842\n",
      "Epoch:[ 2 ] Batch: 239 / 937 Main Model Loss: 0.032214627 Interpreter Loss: 13394.07\n",
      "Epoch:[ 2 ] Batch: 240 / 937 Main Model Loss: 0.023173101 Interpreter Loss: 13717.744\n",
      "Epoch:[ 2 ] Batch: 241 / 937 Main Model Loss: 0.042709783 Interpreter Loss: 13201.758\n",
      "Epoch:[ 2 ] Batch: 242 / 937 Main Model Loss: 0.009363728 Interpreter Loss: 13848.43\n",
      "Epoch:[ 2 ] Batch: 243 / 937 Main Model Loss: 0.014065625 Interpreter Loss: 13662.355\n",
      "Epoch:[ 2 ] Batch: 244 / 937 Main Model Loss: 0.006304768 Interpreter Loss: 13862.556\n",
      "Epoch:[ 2 ] Batch: 245 / 937 Main Model Loss: 0.008772653 Interpreter Loss: 13815.7705\n",
      "Epoch:[ 2 ] Batch: 246 / 937 Main Model Loss: 0.07063685 Interpreter Loss: 14492.525\n",
      "Epoch:[ 2 ] Batch: 247 / 937 Main Model Loss: 0.013113702 Interpreter Loss: 14326.784\n",
      "Epoch:[ 2 ] Batch: 248 / 937 Main Model Loss: 0.01814557 Interpreter Loss: 14374.701\n",
      "Epoch:[ 2 ] Batch: 249 / 937 Main Model Loss: 0.028020924 Interpreter Loss: 14039.946\n",
      "Epoch:[ 2 ] Batch: 250 / 937 Main Model Loss: 0.055198163 Interpreter Loss: 15043.497\n",
      "Epoch:[ 2 ] Batch: 251 / 937 Main Model Loss: 0.0070651015 Interpreter Loss: 14563.613\n",
      "Epoch:[ 2 ] Batch: 252 / 937 Main Model Loss: 0.03154269 Interpreter Loss: 14343.079\n",
      "Epoch:[ 2 ] Batch: 253 / 937 Main Model Loss: 0.0097660255 Interpreter Loss: 14116.265\n",
      "Epoch:[ 2 ] Batch: 254 / 937 Main Model Loss: 0.009909916 Interpreter Loss: 13891.954\n",
      "Epoch:[ 2 ] Batch: 255 / 937 Main Model Loss: 0.011251238 Interpreter Loss: 14368.613\n",
      "Epoch:[ 2 ] Batch: 256 / 937 Main Model Loss: 0.0037221857 Interpreter Loss: 13515.08\n",
      "Epoch:[ 2 ] Batch: 257 / 937 Main Model Loss: 0.009402558 Interpreter Loss: 13948.858\n",
      "Epoch:[ 2 ] Batch: 258 / 937 Main Model Loss: 0.01978908 Interpreter Loss: 13707.829\n",
      "Epoch:[ 2 ] Batch: 259 / 937 Main Model Loss: 0.0041350545 Interpreter Loss: 13224.175\n",
      "Epoch:[ 2 ] Batch: 260 / 937 Main Model Loss: 0.01996056 Interpreter Loss: 14485.898\n",
      "Epoch:[ 2 ] Batch: 261 / 937 Main Model Loss: 0.016979957 Interpreter Loss: 14272.197\n",
      "Epoch:[ 2 ] Batch: 262 / 937 Main Model Loss: 0.0068251938 Interpreter Loss: 13642.904\n",
      "Epoch:[ 2 ] Batch: 263 / 937 Main Model Loss: 0.009361209 Interpreter Loss: 13802.81\n",
      "Epoch:[ 2 ] Batch: 264 / 937 Main Model Loss: 0.028805204 Interpreter Loss: 13672.871\n",
      "Epoch:[ 2 ] Batch: 265 / 937 Main Model Loss: 0.04153049 Interpreter Loss: 14537.382\n",
      "Epoch:[ 2 ] Batch: 266 / 937 Main Model Loss: 0.049520858 Interpreter Loss: 13966.217\n",
      "Epoch:[ 2 ] Batch: 267 / 937 Main Model Loss: 0.08034631 Interpreter Loss: 14389.211\n",
      "Epoch:[ 2 ] Batch: 268 / 937 Main Model Loss: 0.050476726 Interpreter Loss: 15093.279\n",
      "Epoch:[ 2 ] Batch: 269 / 937 Main Model Loss: 0.012557072 Interpreter Loss: 14729.275\n",
      "Epoch:[ 2 ] Batch: 270 / 937 Main Model Loss: 0.010597691 Interpreter Loss: 14533.0\n",
      "Epoch:[ 2 ] Batch: 271 / 937 Main Model Loss: 0.017704297 Interpreter Loss: 13743.719\n",
      "Epoch:[ 2 ] Batch: 272 / 937 Main Model Loss: 0.025743965 Interpreter Loss: 13806.705\n",
      "Epoch:[ 2 ] Batch: 273 / 937 Main Model Loss: 0.022920335 Interpreter Loss: 13900.147\n",
      "Epoch:[ 2 ] Batch: 274 / 937 Main Model Loss: 0.058668688 Interpreter Loss: 13966.797\n",
      "Epoch:[ 2 ] Batch: 275 / 937 Main Model Loss: 0.009997206 Interpreter Loss: 13323.566\n",
      "Epoch:[ 2 ] Batch: 276 / 937 Main Model Loss: 0.037258226 Interpreter Loss: 14099.789\n",
      "Epoch:[ 2 ] Batch: 277 / 937 Main Model Loss: 0.017404225 Interpreter Loss: 14101.051\n",
      "Epoch:[ 2 ] Batch: 278 / 937 Main Model Loss: 0.072012804 Interpreter Loss: 13418.57\n",
      "Epoch:[ 2 ] Batch: 279 / 937 Main Model Loss: 0.013880113 Interpreter Loss: 13084.26\n",
      "Epoch:[ 2 ] Batch: 280 / 937 Main Model Loss: 0.008080976 Interpreter Loss: 13925.195\n",
      "Epoch:[ 2 ] Batch: 281 / 937 Main Model Loss: 0.029956153 Interpreter Loss: 14476.439\n",
      "Epoch:[ 2 ] Batch: 282 / 937 Main Model Loss: 0.022486128 Interpreter Loss: 13458.15\n",
      "Epoch:[ 2 ] Batch: 283 / 937 Main Model Loss: 0.020318706 Interpreter Loss: 14125.871\n",
      "Epoch:[ 2 ] Batch: 284 / 937 Main Model Loss: 0.013027028 Interpreter Loss: 14229.59\n",
      "Epoch:[ 2 ] Batch: 285 / 937 Main Model Loss: 0.008614752 Interpreter Loss: 13565.266\n",
      "Epoch:[ 2 ] Batch: 286 / 937 Main Model Loss: 0.018728994 Interpreter Loss: 13888.134\n",
      "Epoch:[ 2 ] Batch: 287 / 937 Main Model Loss: 0.051769223 Interpreter Loss: 13955.844\n",
      "Epoch:[ 2 ] Batch: 288 / 937 Main Model Loss: 0.025643151 Interpreter Loss: 13566.181\n",
      "Epoch:[ 2 ] Batch: 289 / 937 Main Model Loss: 0.011812936 Interpreter Loss: 13589.5205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 2 ] Batch: 290 / 937 Main Model Loss: 0.01530531 Interpreter Loss: 14123.588\n",
      "Epoch:[ 2 ] Batch: 291 / 937 Main Model Loss: 0.007383938 Interpreter Loss: 13658.202\n",
      "Epoch:[ 2 ] Batch: 292 / 937 Main Model Loss: 0.027864624 Interpreter Loss: 13944.702\n",
      "Epoch:[ 2 ] Batch: 293 / 937 Main Model Loss: 0.005890782 Interpreter Loss: 13426.551\n",
      "Epoch:[ 2 ] Batch: 294 / 937 Main Model Loss: 0.01205854 Interpreter Loss: 13572.166\n",
      "Epoch:[ 2 ] Batch: 295 / 937 Main Model Loss: 0.0038474933 Interpreter Loss: 13402.0\n",
      "Epoch:[ 2 ] Batch: 296 / 937 Main Model Loss: 0.0042903186 Interpreter Loss: 13296.292\n",
      "Epoch:[ 2 ] Batch: 297 / 937 Main Model Loss: 0.0080832 Interpreter Loss: 12852.0\n",
      "Epoch:[ 2 ] Batch: 298 / 937 Main Model Loss: 0.08916622 Interpreter Loss: 13510.344\n",
      "Epoch:[ 2 ] Batch: 299 / 937 Main Model Loss: 0.0057903244 Interpreter Loss: 13335.427\n",
      "Epoch:[ 2 ] Batch: 300 / 937 Main Model Loss: 0.009254651 Interpreter Loss: 15223.068\n",
      "Epoch:[ 2 ] Batch: 301 / 937 Main Model Loss: 0.014317281 Interpreter Loss: 14353.409\n",
      "Epoch:[ 2 ] Batch: 302 / 937 Main Model Loss: 0.072603576 Interpreter Loss: 16313.931\n",
      "Epoch:[ 2 ] Batch: 303 / 937 Main Model Loss: 0.006001617 Interpreter Loss: 14527.285\n",
      "Epoch:[ 2 ] Batch: 304 / 937 Main Model Loss: 0.01904509 Interpreter Loss: 15247.246\n",
      "Epoch:[ 2 ] Batch: 305 / 937 Main Model Loss: 0.02052875 Interpreter Loss: 15197.836\n",
      "Epoch:[ 2 ] Batch: 306 / 937 Main Model Loss: 0.0115731815 Interpreter Loss: 14524.416\n",
      "Epoch:[ 2 ] Batch: 307 / 937 Main Model Loss: 0.0050661247 Interpreter Loss: 14324.287\n",
      "Epoch:[ 2 ] Batch: 308 / 937 Main Model Loss: 0.0033631471 Interpreter Loss: 14263.074\n",
      "Epoch:[ 2 ] Batch: 309 / 937 Main Model Loss: 0.005809429 Interpreter Loss: 14673.947\n",
      "Epoch:[ 2 ] Batch: 310 / 937 Main Model Loss: 0.015485314 Interpreter Loss: 14722.497\n",
      "Epoch:[ 2 ] Batch: 311 / 937 Main Model Loss: 0.0470835 Interpreter Loss: 14963.76\n",
      "Epoch:[ 2 ] Batch: 312 / 937 Main Model Loss: 0.026406856 Interpreter Loss: 14717.627\n",
      "Epoch:[ 2 ] Batch: 313 / 937 Main Model Loss: 0.022849172 Interpreter Loss: 14356.476\n",
      "Epoch:[ 2 ] Batch: 314 / 937 Main Model Loss: 0.0088298125 Interpreter Loss: 14370.854\n",
      "Epoch:[ 2 ] Batch: 315 / 937 Main Model Loss: 0.012199522 Interpreter Loss: 14844.983\n",
      "Epoch:[ 2 ] Batch: 316 / 937 Main Model Loss: 0.016349718 Interpreter Loss: 14044.793\n",
      "Epoch:[ 2 ] Batch: 317 / 937 Main Model Loss: 0.035843268 Interpreter Loss: 13499.854\n",
      "Epoch:[ 2 ] Batch: 318 / 937 Main Model Loss: 0.00359638 Interpreter Loss: 13889.744\n",
      "Epoch:[ 2 ] Batch: 319 / 937 Main Model Loss: 0.021160448 Interpreter Loss: 13406.087\n",
      "Epoch:[ 2 ] Batch: 320 / 937 Main Model Loss: 0.008718272 Interpreter Loss: 14088.734\n",
      "Epoch:[ 2 ] Batch: 321 / 937 Main Model Loss: 0.014593505 Interpreter Loss: 13941.963\n",
      "Epoch:[ 2 ] Batch: 322 / 937 Main Model Loss: 0.041271895 Interpreter Loss: 14887.706\n",
      "Epoch:[ 2 ] Batch: 323 / 937 Main Model Loss: 0.09563866 Interpreter Loss: 14360.312\n",
      "Epoch:[ 2 ] Batch: 324 / 937 Main Model Loss: 0.05213446 Interpreter Loss: 13844.193\n",
      "Epoch:[ 2 ] Batch: 325 / 937 Main Model Loss: 0.016843347 Interpreter Loss: 14471.488\n",
      "Epoch:[ 2 ] Batch: 326 / 937 Main Model Loss: 0.01225012 Interpreter Loss: 14991.502\n",
      "Epoch:[ 2 ] Batch: 327 / 937 Main Model Loss: 0.011042634 Interpreter Loss: 14855.552\n",
      "Epoch:[ 2 ] Batch: 328 / 937 Main Model Loss: 0.016260503 Interpreter Loss: 13804.11\n",
      "Epoch:[ 2 ] Batch: 329 / 937 Main Model Loss: 0.0034638438 Interpreter Loss: 12923.784\n",
      "Epoch:[ 2 ] Batch: 330 / 937 Main Model Loss: 0.03504826 Interpreter Loss: 14073.659\n",
      "Epoch:[ 2 ] Batch: 331 / 937 Main Model Loss: 0.033977717 Interpreter Loss: 13677.389\n",
      "Epoch:[ 2 ] Batch: 332 / 937 Main Model Loss: 0.0067944424 Interpreter Loss: 14042.078\n",
      "Epoch:[ 2 ] Batch: 333 / 937 Main Model Loss: 0.010688837 Interpreter Loss: 13706.521\n",
      "Epoch:[ 2 ] Batch: 334 / 937 Main Model Loss: 0.007153761 Interpreter Loss: 14105.814\n",
      "Epoch:[ 2 ] Batch: 335 / 937 Main Model Loss: 0.014493811 Interpreter Loss: 14574.101\n",
      "Epoch:[ 2 ] Batch: 336 / 937 Main Model Loss: 0.0024374975 Interpreter Loss: 14523.971\n",
      "Epoch:[ 2 ] Batch: 337 / 937 Main Model Loss: 0.021664431 Interpreter Loss: 13473.273\n",
      "Epoch:[ 2 ] Batch: 338 / 937 Main Model Loss: 0.018780299 Interpreter Loss: 14065.299\n",
      "Epoch:[ 2 ] Batch: 339 / 937 Main Model Loss: 0.008401833 Interpreter Loss: 12696.003\n",
      "Epoch:[ 2 ] Batch: 340 / 937 Main Model Loss: 0.020486299 Interpreter Loss: 15343.223\n",
      "Epoch:[ 2 ] Batch: 341 / 937 Main Model Loss: 0.005186654 Interpreter Loss: 14524.866\n",
      "Epoch:[ 2 ] Batch: 342 / 937 Main Model Loss: 0.019989248 Interpreter Loss: 15546.869\n",
      "Epoch:[ 2 ] Batch: 343 / 937 Main Model Loss: 0.012259498 Interpreter Loss: 14725.553\n",
      "Epoch:[ 2 ] Batch: 344 / 937 Main Model Loss: 0.013145235 Interpreter Loss: 13977.957\n",
      "Epoch:[ 2 ] Batch: 345 / 937 Main Model Loss: 0.017052934 Interpreter Loss: 13688.338\n",
      "Epoch:[ 2 ] Batch: 346 / 937 Main Model Loss: 0.010037296 Interpreter Loss: 14367.25\n",
      "Epoch:[ 2 ] Batch: 347 / 937 Main Model Loss: 0.021230299 Interpreter Loss: 14503.355\n",
      "Epoch:[ 2 ] Batch: 348 / 937 Main Model Loss: 0.008791952 Interpreter Loss: 13643.016\n",
      "Epoch:[ 2 ] Batch: 349 / 937 Main Model Loss: 0.010379867 Interpreter Loss: 13659.741\n",
      "Epoch:[ 2 ] Batch: 350 / 937 Main Model Loss: 0.014203109 Interpreter Loss: 13883.29\n",
      "Epoch:[ 2 ] Batch: 351 / 937 Main Model Loss: 0.01803957 Interpreter Loss: 14930.912\n",
      "Epoch:[ 2 ] Batch: 352 / 937 Main Model Loss: 0.03207735 Interpreter Loss: 14972.846\n",
      "Epoch:[ 2 ] Batch: 353 / 937 Main Model Loss: 0.037437864 Interpreter Loss: 15309.769\n",
      "Epoch:[ 2 ] Batch: 354 / 937 Main Model Loss: 0.014694112 Interpreter Loss: 15175.836\n",
      "Epoch:[ 2 ] Batch: 355 / 937 Main Model Loss: 0.017396325 Interpreter Loss: 14943.362\n",
      "Epoch:[ 2 ] Batch: 356 / 937 Main Model Loss: 0.0073454836 Interpreter Loss: 14120.854\n",
      "Epoch:[ 2 ] Batch: 357 / 937 Main Model Loss: 0.01254321 Interpreter Loss: 14433.216\n",
      "Epoch:[ 2 ] Batch: 358 / 937 Main Model Loss: 0.0007524628 Interpreter Loss: 14154.58\n",
      "Epoch:[ 2 ] Batch: 359 / 937 Main Model Loss: 0.006331975 Interpreter Loss: 14151.966\n",
      "Epoch:[ 2 ] Batch: 360 / 937 Main Model Loss: 0.023267396 Interpreter Loss: 15628.454\n",
      "Epoch:[ 2 ] Batch: 361 / 937 Main Model Loss: 0.0042893714 Interpreter Loss: 14040.476\n",
      "Epoch:[ 2 ] Batch: 362 / 937 Main Model Loss: 0.011886989 Interpreter Loss: 14047.84\n",
      "Epoch:[ 2 ] Batch: 363 / 937 Main Model Loss: 0.0027738712 Interpreter Loss: 13625.099\n",
      "Epoch:[ 2 ] Batch: 364 / 937 Main Model Loss: 0.0034163578 Interpreter Loss: 13897.119\n",
      "Epoch:[ 2 ] Batch: 365 / 937 Main Model Loss: 0.01045234 Interpreter Loss: 14450.291\n",
      "Epoch:[ 2 ] Batch: 366 / 937 Main Model Loss: 0.0054528024 Interpreter Loss: 13756.819\n",
      "Epoch:[ 2 ] Batch: 367 / 937 Main Model Loss: 0.017239975 Interpreter Loss: 13503.144\n",
      "Epoch:[ 2 ] Batch: 368 / 937 Main Model Loss: 0.029612765 Interpreter Loss: 13328.667\n",
      "Epoch:[ 2 ] Batch: 369 / 937 Main Model Loss: 0.036617007 Interpreter Loss: 13080.814\n",
      "Epoch:[ 2 ] Batch: 370 / 937 Main Model Loss: 0.017719073 Interpreter Loss: 13453.621\n",
      "Epoch:[ 2 ] Batch: 371 / 937 Main Model Loss: 0.00871324 Interpreter Loss: 13670.788\n",
      "Epoch:[ 2 ] Batch: 372 / 937 Main Model Loss: 0.07044067 Interpreter Loss: 14750.434\n",
      "Epoch:[ 2 ] Batch: 373 / 937 Main Model Loss: 0.06920177 Interpreter Loss: 13498.597\n",
      "Epoch:[ 2 ] Batch: 374 / 937 Main Model Loss: 0.004260282 Interpreter Loss: 14767.9795\n",
      "Epoch:[ 2 ] Batch: 375 / 937 Main Model Loss: 0.012072389 Interpreter Loss: 14457.788\n",
      "Epoch:[ 2 ] Batch: 376 / 937 Main Model Loss: 0.008709634 Interpreter Loss: 13924.387\n",
      "Epoch:[ 2 ] Batch: 377 / 937 Main Model Loss: 0.005925483 Interpreter Loss: 13582.11\n",
      "Epoch:[ 2 ] Batch: 378 / 937 Main Model Loss: 0.004292922 Interpreter Loss: 14277.189\n",
      "Epoch:[ 2 ] Batch: 379 / 937 Main Model Loss: 0.006248887 Interpreter Loss: 13852.032\n",
      "Epoch:[ 2 ] Batch: 380 / 937 Main Model Loss: 0.00068157085 Interpreter Loss: 12581.691\n",
      "Epoch:[ 2 ] Batch: 381 / 937 Main Model Loss: 0.0039068693 Interpreter Loss: 14089.514\n",
      "Epoch:[ 2 ] Batch: 382 / 937 Main Model Loss: 0.015400415 Interpreter Loss: 14241.066\n",
      "Epoch:[ 2 ] Batch: 383 / 937 Main Model Loss: 0.025697624 Interpreter Loss: 13808.636\n",
      "Epoch:[ 2 ] Batch: 384 / 937 Main Model Loss: 0.039377656 Interpreter Loss: 15008.851\n",
      "Epoch:[ 2 ] Batch: 385 / 937 Main Model Loss: 0.02846301 Interpreter Loss: 14591.4375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 2 ] Batch: 386 / 937 Main Model Loss: 0.0054170154 Interpreter Loss: 13961.258\n",
      "Epoch:[ 2 ] Batch: 387 / 937 Main Model Loss: 0.018703127 Interpreter Loss: 14501.33\n",
      "Epoch:[ 2 ] Batch: 388 / 937 Main Model Loss: 0.012807769 Interpreter Loss: 13533.301\n",
      "Epoch:[ 2 ] Batch: 389 / 937 Main Model Loss: 0.038412526 Interpreter Loss: 13129.559\n",
      "Epoch:[ 2 ] Batch: 390 / 937 Main Model Loss: 0.0017179581 Interpreter Loss: 13330.003\n",
      "Epoch:[ 2 ] Batch: 391 / 937 Main Model Loss: 0.006419729 Interpreter Loss: 13061.957\n",
      "Epoch:[ 2 ] Batch: 392 / 937 Main Model Loss: 0.020990256 Interpreter Loss: 13525.293\n",
      "Epoch:[ 2 ] Batch: 393 / 937 Main Model Loss: 0.028180555 Interpreter Loss: 13900.42\n",
      "Epoch:[ 2 ] Batch: 394 / 937 Main Model Loss: 0.010755559 Interpreter Loss: 13478.719\n",
      "Epoch:[ 2 ] Batch: 395 / 937 Main Model Loss: 0.0073005445 Interpreter Loss: 15497.252\n",
      "Epoch:[ 2 ] Batch: 396 / 937 Main Model Loss: 0.002042897 Interpreter Loss: 14588.551\n",
      "Epoch:[ 2 ] Batch: 397 / 937 Main Model Loss: 0.0036523675 Interpreter Loss: 14104.3545\n",
      "Epoch:[ 2 ] Batch: 398 / 937 Main Model Loss: 0.027977716 Interpreter Loss: 14889.162\n",
      "Epoch:[ 2 ] Batch: 399 / 937 Main Model Loss: 0.14702402 Interpreter Loss: 13139.529\n",
      "Epoch:[ 2 ] Batch: 400 / 937 Main Model Loss: 0.008860223 Interpreter Loss: 13839.57\n",
      "Epoch:[ 2 ] Batch: 401 / 937 Main Model Loss: 0.06870203 Interpreter Loss: 13926.542\n",
      "Epoch:[ 2 ] Batch: 402 / 937 Main Model Loss: 0.0060703307 Interpreter Loss: 13186.677\n",
      "Epoch:[ 2 ] Batch: 403 / 937 Main Model Loss: 0.015491905 Interpreter Loss: 13277.684\n",
      "Epoch:[ 2 ] Batch: 404 / 937 Main Model Loss: 0.005818475 Interpreter Loss: 12662.416\n",
      "Epoch:[ 2 ] Batch: 405 / 937 Main Model Loss: 0.008481128 Interpreter Loss: 12916.231\n",
      "Epoch:[ 2 ] Batch: 406 / 937 Main Model Loss: 0.004690732 Interpreter Loss: 14013.586\n",
      "Epoch:[ 2 ] Batch: 407 / 937 Main Model Loss: 0.008672271 Interpreter Loss: 13819.907\n",
      "Epoch:[ 2 ] Batch: 408 / 937 Main Model Loss: 0.04430652 Interpreter Loss: 13682.759\n",
      "Epoch:[ 2 ] Batch: 409 / 937 Main Model Loss: 0.0073563894 Interpreter Loss: 13623.638\n",
      "Epoch:[ 2 ] Batch: 410 / 937 Main Model Loss: 0.0073580043 Interpreter Loss: 13119.084\n",
      "Epoch:[ 2 ] Batch: 411 / 937 Main Model Loss: 0.014016207 Interpreter Loss: 13177.033\n",
      "Epoch:[ 2 ] Batch: 412 / 937 Main Model Loss: 0.10580194 Interpreter Loss: 14810.574\n",
      "Epoch:[ 2 ] Batch: 413 / 937 Main Model Loss: 0.029863358 Interpreter Loss: 13621.696\n",
      "Epoch:[ 2 ] Batch: 414 / 937 Main Model Loss: 0.044391766 Interpreter Loss: 13738.127\n",
      "Epoch:[ 2 ] Batch: 415 / 937 Main Model Loss: 0.07534418 Interpreter Loss: 12767.325\n",
      "Epoch:[ 2 ] Batch: 416 / 937 Main Model Loss: 0.08865811 Interpreter Loss: 14354.035\n",
      "Epoch:[ 2 ] Batch: 417 / 937 Main Model Loss: 0.089609504 Interpreter Loss: 14528.245\n",
      "Epoch:[ 2 ] Batch: 418 / 937 Main Model Loss: 0.029605165 Interpreter Loss: 14619.889\n",
      "Epoch:[ 2 ] Batch: 419 / 937 Main Model Loss: 0.066653416 Interpreter Loss: 14736.69\n",
      "Epoch:[ 2 ] Batch: 420 / 937 Main Model Loss: 0.12157477 Interpreter Loss: 13338.65\n",
      "Epoch:[ 2 ] Batch: 421 / 937 Main Model Loss: 0.0056835543 Interpreter Loss: 12935.211\n",
      "Epoch:[ 2 ] Batch: 422 / 937 Main Model Loss: 0.0064492933 Interpreter Loss: 13285.589\n",
      "Epoch:[ 2 ] Batch: 423 / 937 Main Model Loss: 0.012474356 Interpreter Loss: 14663.03\n",
      "Epoch:[ 2 ] Batch: 424 / 937 Main Model Loss: 0.031407237 Interpreter Loss: 16308.133\n",
      "Epoch:[ 2 ] Batch: 425 / 937 Main Model Loss: 0.029982056 Interpreter Loss: 15075.708\n",
      "Epoch:[ 2 ] Batch: 426 / 937 Main Model Loss: 0.014672537 Interpreter Loss: 14387.806\n",
      "Epoch:[ 2 ] Batch: 427 / 937 Main Model Loss: 0.022798669 Interpreter Loss: 13897.631\n",
      "Epoch:[ 2 ] Batch: 428 / 937 Main Model Loss: 0.0047376454 Interpreter Loss: 13840.506\n",
      "Epoch:[ 2 ] Batch: 429 / 937 Main Model Loss: 0.013039757 Interpreter Loss: 14276.33\n",
      "Epoch:[ 2 ] Batch: 430 / 937 Main Model Loss: 0.027011395 Interpreter Loss: 13614.838\n",
      "Epoch:[ 2 ] Batch: 431 / 937 Main Model Loss: 0.007149174 Interpreter Loss: 13427.408\n",
      "Epoch:[ 2 ] Batch: 432 / 937 Main Model Loss: 0.012485157 Interpreter Loss: 13638.84\n",
      "Epoch:[ 2 ] Batch: 433 / 937 Main Model Loss: 0.021373326 Interpreter Loss: 12971.381\n",
      "Epoch:[ 2 ] Batch: 434 / 937 Main Model Loss: 0.026633732 Interpreter Loss: 13236.367\n",
      "Epoch:[ 2 ] Batch: 435 / 937 Main Model Loss: 0.1102856 Interpreter Loss: 13698.442\n",
      "Epoch:[ 2 ] Batch: 436 / 937 Main Model Loss: 0.012888015 Interpreter Loss: 14540.165\n",
      "Epoch:[ 2 ] Batch: 437 / 937 Main Model Loss: 0.015149236 Interpreter Loss: 14026.498\n",
      "Epoch:[ 2 ] Batch: 438 / 937 Main Model Loss: 0.0060907905 Interpreter Loss: 14072.933\n",
      "Epoch:[ 2 ] Batch: 439 / 937 Main Model Loss: 0.007606106 Interpreter Loss: 15088.738\n",
      "Epoch:[ 2 ] Batch: 440 / 937 Main Model Loss: 0.025535706 Interpreter Loss: 14996.765\n",
      "Epoch:[ 2 ] Batch: 441 / 937 Main Model Loss: 0.012267437 Interpreter Loss: 14647.915\n",
      "Epoch:[ 2 ] Batch: 442 / 937 Main Model Loss: 0.007405091 Interpreter Loss: 14044.366\n",
      "Epoch:[ 2 ] Batch: 443 / 937 Main Model Loss: 0.09622261 Interpreter Loss: 15564.73\n",
      "Epoch:[ 2 ] Batch: 444 / 937 Main Model Loss: 0.010454524 Interpreter Loss: 14542.554\n",
      "Epoch:[ 2 ] Batch: 445 / 937 Main Model Loss: 0.0026935607 Interpreter Loss: 14296.481\n",
      "Epoch:[ 2 ] Batch: 446 / 937 Main Model Loss: 0.014930166 Interpreter Loss: 14794.149\n",
      "Epoch:[ 2 ] Batch: 447 / 937 Main Model Loss: 0.11079357 Interpreter Loss: 14116.934\n",
      "Epoch:[ 2 ] Batch: 448 / 937 Main Model Loss: 0.0953953 Interpreter Loss: 13470.637\n",
      "Epoch:[ 2 ] Batch: 449 / 937 Main Model Loss: 0.025372336 Interpreter Loss: 13713.723\n",
      "Epoch:[ 2 ] Batch: 450 / 937 Main Model Loss: 0.00867404 Interpreter Loss: 13625.352\n",
      "Epoch:[ 2 ] Batch: 451 / 937 Main Model Loss: 0.00150153 Interpreter Loss: 14073.195\n",
      "Epoch:[ 2 ] Batch: 452 / 937 Main Model Loss: 0.01778786 Interpreter Loss: 14786.408\n",
      "Epoch:[ 2 ] Batch: 453 / 937 Main Model Loss: 0.020775108 Interpreter Loss: 14068.231\n",
      "Epoch:[ 2 ] Batch: 454 / 937 Main Model Loss: 0.013109252 Interpreter Loss: 12700.944\n",
      "Epoch:[ 2 ] Batch: 455 / 937 Main Model Loss: 0.029526673 Interpreter Loss: 13529.247\n",
      "Epoch:[ 2 ] Batch: 456 / 937 Main Model Loss: 0.015254742 Interpreter Loss: 13903.353\n",
      "Epoch:[ 2 ] Batch: 457 / 937 Main Model Loss: 0.007913573 Interpreter Loss: 14911.507\n",
      "Epoch:[ 2 ] Batch: 458 / 937 Main Model Loss: 0.0131308725 Interpreter Loss: 14874.169\n",
      "Epoch:[ 2 ] Batch: 459 / 937 Main Model Loss: 0.002339182 Interpreter Loss: 14495.904\n",
      "Epoch:[ 2 ] Batch: 460 / 937 Main Model Loss: 0.011116289 Interpreter Loss: 14458.279\n",
      "Epoch:[ 2 ] Batch: 461 / 937 Main Model Loss: 0.0028862434 Interpreter Loss: 12888.443\n",
      "Epoch:[ 2 ] Batch: 462 / 937 Main Model Loss: 0.01979476 Interpreter Loss: 13273.809\n",
      "Epoch:[ 2 ] Batch: 463 / 937 Main Model Loss: 0.013956136 Interpreter Loss: 13259.02\n",
      "Epoch:[ 2 ] Batch: 464 / 937 Main Model Loss: 0.04169313 Interpreter Loss: 13957.274\n",
      "Epoch:[ 2 ] Batch: 465 / 937 Main Model Loss: 0.011751091 Interpreter Loss: 12643.196\n",
      "Epoch:[ 2 ] Batch: 466 / 937 Main Model Loss: 0.014144102 Interpreter Loss: 13199.896\n",
      "Epoch:[ 2 ] Batch: 467 / 937 Main Model Loss: 0.012777474 Interpreter Loss: 13033.331\n",
      "Epoch:[ 2 ] Batch: 468 / 937 Main Model Loss: 0.010517512 Interpreter Loss: 12957.404\n",
      "Epoch:[ 2 ] Batch: 469 / 937 Main Model Loss: 0.028063051 Interpreter Loss: 13820.571\n",
      "Epoch:[ 2 ] Batch: 470 / 937 Main Model Loss: 0.013277605 Interpreter Loss: 13812.506\n",
      "Epoch:[ 2 ] Batch: 471 / 937 Main Model Loss: 0.033921793 Interpreter Loss: 13787.1\n",
      "Epoch:[ 2 ] Batch: 472 / 937 Main Model Loss: 0.002189353 Interpreter Loss: 13126.493\n",
      "Epoch:[ 2 ] Batch: 473 / 937 Main Model Loss: 0.0049756723 Interpreter Loss: 13010.215\n",
      "Epoch:[ 2 ] Batch: 474 / 937 Main Model Loss: 0.005352483 Interpreter Loss: 13561.518\n",
      "Epoch:[ 2 ] Batch: 475 / 937 Main Model Loss: 0.00536481 Interpreter Loss: 13808.277\n",
      "Epoch:[ 2 ] Batch: 476 / 937 Main Model Loss: 0.05672771 Interpreter Loss: 14882.542\n",
      "Epoch:[ 2 ] Batch: 477 / 937 Main Model Loss: 0.009804676 Interpreter Loss: 13279.403\n",
      "Epoch:[ 2 ] Batch: 478 / 937 Main Model Loss: 0.012941207 Interpreter Loss: 12254.243\n",
      "Epoch:[ 2 ] Batch: 479 / 937 Main Model Loss: 0.032023124 Interpreter Loss: 12605.398\n",
      "Epoch:[ 2 ] Batch: 480 / 937 Main Model Loss: 0.006476854 Interpreter Loss: 12389.357\n",
      "Epoch:[ 2 ] Batch: 481 / 937 Main Model Loss: 0.01846435 Interpreter Loss: 13969.512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 2 ] Batch: 482 / 937 Main Model Loss: 0.025339093 Interpreter Loss: 13737.951\n",
      "Epoch:[ 2 ] Batch: 483 / 937 Main Model Loss: 0.004856946 Interpreter Loss: 13715.971\n",
      "Epoch:[ 2 ] Batch: 484 / 937 Main Model Loss: 0.033260614 Interpreter Loss: 13279.988\n",
      "Epoch:[ 2 ] Batch: 485 / 937 Main Model Loss: 0.019387335 Interpreter Loss: 13645.674\n",
      "Epoch:[ 2 ] Batch: 486 / 937 Main Model Loss: 0.0059089228 Interpreter Loss: 13043.026\n",
      "Epoch:[ 2 ] Batch: 487 / 937 Main Model Loss: 0.034346476 Interpreter Loss: 13577.104\n",
      "Epoch:[ 2 ] Batch: 488 / 937 Main Model Loss: 0.008808356 Interpreter Loss: 13411.34\n",
      "Epoch:[ 2 ] Batch: 489 / 937 Main Model Loss: 0.013383942 Interpreter Loss: 13588.205\n",
      "Epoch:[ 2 ] Batch: 490 / 937 Main Model Loss: 0.008859264 Interpreter Loss: 13588.687\n",
      "Epoch:[ 2 ] Batch: 491 / 937 Main Model Loss: 0.010683321 Interpreter Loss: 13286.468\n",
      "Epoch:[ 2 ] Batch: 492 / 937 Main Model Loss: 0.05686529 Interpreter Loss: 12420.848\n",
      "Epoch:[ 2 ] Batch: 493 / 937 Main Model Loss: 0.08107286 Interpreter Loss: 13264.301\n",
      "Epoch:[ 2 ] Batch: 494 / 937 Main Model Loss: 0.02149606 Interpreter Loss: 13155.396\n",
      "Epoch:[ 2 ] Batch: 495 / 937 Main Model Loss: 0.040202934 Interpreter Loss: 13521.748\n",
      "Epoch:[ 2 ] Batch: 496 / 937 Main Model Loss: 0.034353625 Interpreter Loss: 13485.429\n",
      "Epoch:[ 2 ] Batch: 497 / 937 Main Model Loss: 0.07605827 Interpreter Loss: 13649.258\n",
      "Epoch:[ 2 ] Batch: 498 / 937 Main Model Loss: 0.0075006103 Interpreter Loss: 13031.919\n",
      "Epoch:[ 2 ] Batch: 499 / 937 Main Model Loss: 0.047273375 Interpreter Loss: 14427.71\n",
      "Epoch:[ 2 ] Batch: 500 / 937 Main Model Loss: 0.048243772 Interpreter Loss: 14152.789\n",
      "Epoch:[ 2 ] Batch: 501 / 937 Main Model Loss: 0.0529918 Interpreter Loss: 14193.934\n",
      "Epoch:[ 2 ] Batch: 502 / 937 Main Model Loss: 0.009424958 Interpreter Loss: 13608.125\n",
      "Epoch:[ 2 ] Batch: 503 / 937 Main Model Loss: 0.027399087 Interpreter Loss: 13623.7295\n",
      "Epoch:[ 2 ] Batch: 504 / 937 Main Model Loss: 0.01970709 Interpreter Loss: 14189.807\n",
      "Epoch:[ 2 ] Batch: 505 / 937 Main Model Loss: 0.11928476 Interpreter Loss: 14888.7295\n",
      "Epoch:[ 2 ] Batch: 506 / 937 Main Model Loss: 0.025511429 Interpreter Loss: 15400.129\n",
      "Epoch:[ 2 ] Batch: 507 / 937 Main Model Loss: 0.021131877 Interpreter Loss: 14560.958\n",
      "Epoch:[ 2 ] Batch: 508 / 937 Main Model Loss: 0.027370675 Interpreter Loss: 13778.643\n",
      "Epoch:[ 2 ] Batch: 509 / 937 Main Model Loss: 0.0023509064 Interpreter Loss: 13033.473\n",
      "Epoch:[ 2 ] Batch: 510 / 937 Main Model Loss: 0.012650694 Interpreter Loss: 13542.168\n",
      "Epoch:[ 2 ] Batch: 511 / 937 Main Model Loss: 0.052969605 Interpreter Loss: 12683.505\n",
      "Epoch:[ 2 ] Batch: 512 / 937 Main Model Loss: 0.009069389 Interpreter Loss: 13497.346\n",
      "Epoch:[ 2 ] Batch: 513 / 937 Main Model Loss: 0.03396034 Interpreter Loss: 14017.916\n",
      "Epoch:[ 2 ] Batch: 514 / 937 Main Model Loss: 0.0032461074 Interpreter Loss: 13923.475\n",
      "Epoch:[ 2 ] Batch: 515 / 937 Main Model Loss: 0.0011305417 Interpreter Loss: 13569.271\n",
      "Epoch:[ 2 ] Batch: 516 / 937 Main Model Loss: 0.014137149 Interpreter Loss: 14515.324\n",
      "Epoch:[ 2 ] Batch: 517 / 937 Main Model Loss: 0.002473732 Interpreter Loss: 13851.014\n",
      "Epoch:[ 2 ] Batch: 518 / 937 Main Model Loss: 0.005543811 Interpreter Loss: 13798.832\n",
      "Epoch:[ 2 ] Batch: 519 / 937 Main Model Loss: 0.016231116 Interpreter Loss: 13947.713\n",
      "Epoch:[ 2 ] Batch: 520 / 937 Main Model Loss: 0.014016215 Interpreter Loss: 14084.793\n",
      "Epoch:[ 2 ] Batch: 521 / 937 Main Model Loss: 0.0064741336 Interpreter Loss: 13186.549\n",
      "Epoch:[ 2 ] Batch: 522 / 937 Main Model Loss: 0.016590465 Interpreter Loss: 13295.725\n",
      "Epoch:[ 2 ] Batch: 523 / 937 Main Model Loss: 0.037865058 Interpreter Loss: 12911.317\n",
      "Epoch:[ 2 ] Batch: 524 / 937 Main Model Loss: 0.013841437 Interpreter Loss: 12516.908\n",
      "Epoch:[ 2 ] Batch: 525 / 937 Main Model Loss: 0.018467924 Interpreter Loss: 12707.44\n",
      "Epoch:[ 2 ] Batch: 526 / 937 Main Model Loss: 0.009682629 Interpreter Loss: 13203.393\n",
      "Epoch:[ 2 ] Batch: 527 / 937 Main Model Loss: 0.045658577 Interpreter Loss: 13943.658\n",
      "Epoch:[ 2 ] Batch: 528 / 937 Main Model Loss: 0.010824424 Interpreter Loss: 14125.851\n",
      "Epoch:[ 2 ] Batch: 529 / 937 Main Model Loss: 0.0035423215 Interpreter Loss: 13498.735\n",
      "Epoch:[ 2 ] Batch: 530 / 937 Main Model Loss: 0.0042796317 Interpreter Loss: 13140.903\n",
      "Epoch:[ 2 ] Batch: 531 / 937 Main Model Loss: 0.010824046 Interpreter Loss: 12573.587\n",
      "Epoch:[ 2 ] Batch: 532 / 937 Main Model Loss: 0.01638971 Interpreter Loss: 13906.451\n",
      "Epoch:[ 2 ] Batch: 533 / 937 Main Model Loss: 0.003745952 Interpreter Loss: 13207.127\n",
      "Epoch:[ 2 ] Batch: 534 / 937 Main Model Loss: 0.0024057692 Interpreter Loss: 12867.275\n",
      "Epoch:[ 2 ] Batch: 535 / 937 Main Model Loss: 0.0013478181 Interpreter Loss: 12558.482\n",
      "Epoch:[ 2 ] Batch: 536 / 937 Main Model Loss: 0.016342217 Interpreter Loss: 14008.35\n",
      "Epoch:[ 2 ] Batch: 537 / 937 Main Model Loss: 0.1284081 Interpreter Loss: 14017.109\n",
      "Epoch:[ 2 ] Batch: 538 / 937 Main Model Loss: 0.009409397 Interpreter Loss: 13978.7705\n",
      "Epoch:[ 2 ] Batch: 539 / 937 Main Model Loss: 0.023113577 Interpreter Loss: 14883.87\n",
      "Epoch:[ 2 ] Batch: 540 / 937 Main Model Loss: 0.0059037004 Interpreter Loss: 14145.065\n",
      "Epoch:[ 2 ] Batch: 541 / 937 Main Model Loss: 0.03488577 Interpreter Loss: 15178.838\n",
      "Epoch:[ 2 ] Batch: 542 / 937 Main Model Loss: 0.042560454 Interpreter Loss: 14372.799\n",
      "Epoch:[ 2 ] Batch: 543 / 937 Main Model Loss: 0.06529106 Interpreter Loss: 14599.128\n",
      "Epoch:[ 2 ] Batch: 544 / 937 Main Model Loss: 0.06817664 Interpreter Loss: 14340.33\n",
      "Epoch:[ 2 ] Batch: 545 / 937 Main Model Loss: 0.015983101 Interpreter Loss: 14289.683\n",
      "Epoch:[ 2 ] Batch: 546 / 937 Main Model Loss: 0.0077651273 Interpreter Loss: 13394.762\n",
      "Epoch:[ 2 ] Batch: 547 / 937 Main Model Loss: 0.056314472 Interpreter Loss: 14903.622\n",
      "Epoch:[ 2 ] Batch: 548 / 937 Main Model Loss: 0.0051989816 Interpreter Loss: 13438.529\n",
      "Epoch:[ 2 ] Batch: 549 / 937 Main Model Loss: 0.060409147 Interpreter Loss: 12863.51\n",
      "Epoch:[ 2 ] Batch: 550 / 937 Main Model Loss: 0.06054508 Interpreter Loss: 13420.8\n",
      "Epoch:[ 2 ] Batch: 551 / 937 Main Model Loss: 0.009878768 Interpreter Loss: 13082.213\n",
      "Epoch:[ 2 ] Batch: 552 / 937 Main Model Loss: 0.028547065 Interpreter Loss: 13657.586\n",
      "Epoch:[ 2 ] Batch: 553 / 937 Main Model Loss: 0.008027936 Interpreter Loss: 14186.578\n",
      "Epoch:[ 2 ] Batch: 554 / 937 Main Model Loss: 0.119076796 Interpreter Loss: 14935.56\n",
      "Epoch:[ 2 ] Batch: 555 / 937 Main Model Loss: 0.00965278 Interpreter Loss: 13131.182\n",
      "Epoch:[ 2 ] Batch: 556 / 937 Main Model Loss: 0.06049367 Interpreter Loss: 13354.548\n",
      "Epoch:[ 2 ] Batch: 557 / 937 Main Model Loss: 0.02124377 Interpreter Loss: 14122.994\n",
      "Epoch:[ 2 ] Batch: 558 / 937 Main Model Loss: 0.031161021 Interpreter Loss: 13594.69\n",
      "Epoch:[ 2 ] Batch: 559 / 937 Main Model Loss: 0.0035787972 Interpreter Loss: 13080.863\n",
      "Epoch:[ 2 ] Batch: 560 / 937 Main Model Loss: 0.03827651 Interpreter Loss: 13431.391\n",
      "Epoch:[ 2 ] Batch: 561 / 937 Main Model Loss: 0.011034834 Interpreter Loss: 12767.586\n",
      "Epoch:[ 2 ] Batch: 562 / 937 Main Model Loss: 0.018452536 Interpreter Loss: 12830.229\n",
      "Epoch:[ 2 ] Batch: 563 / 937 Main Model Loss: 0.009983078 Interpreter Loss: 12592.979\n",
      "Epoch:[ 2 ] Batch: 564 / 937 Main Model Loss: 0.12077343 Interpreter Loss: 14537.925\n",
      "Epoch:[ 2 ] Batch: 565 / 937 Main Model Loss: 0.034159545 Interpreter Loss: 15349.029\n",
      "Epoch:[ 2 ] Batch: 566 / 937 Main Model Loss: 0.024498299 Interpreter Loss: 14907.76\n",
      "Epoch:[ 2 ] Batch: 567 / 937 Main Model Loss: 0.009424324 Interpreter Loss: 14451.623\n",
      "Epoch:[ 2 ] Batch: 568 / 937 Main Model Loss: 0.009697275 Interpreter Loss: 13398.933\n",
      "Epoch:[ 2 ] Batch: 569 / 937 Main Model Loss: 0.045726515 Interpreter Loss: 14600.99\n",
      "Epoch:[ 2 ] Batch: 570 / 937 Main Model Loss: 0.015288455 Interpreter Loss: 13268.06\n",
      "Epoch:[ 2 ] Batch: 571 / 937 Main Model Loss: 0.006359501 Interpreter Loss: 15199.104\n",
      "Epoch:[ 2 ] Batch: 572 / 937 Main Model Loss: 0.004916602 Interpreter Loss: 14407.49\n",
      "Epoch:[ 2 ] Batch: 573 / 937 Main Model Loss: 0.012886745 Interpreter Loss: 14946.54\n",
      "Epoch:[ 2 ] Batch: 574 / 937 Main Model Loss: 0.0541722 Interpreter Loss: 15440.871\n",
      "Epoch:[ 2 ] Batch: 575 / 937 Main Model Loss: 0.029541846 Interpreter Loss: 14244.258\n",
      "Epoch:[ 2 ] Batch: 576 / 937 Main Model Loss: 0.013163819 Interpreter Loss: 13873.168\n",
      "Epoch:[ 2 ] Batch: 577 / 937 Main Model Loss: 0.0138232 Interpreter Loss: 13512.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 2 ] Batch: 578 / 937 Main Model Loss: 0.17901604 Interpreter Loss: 13508.407\n",
      "Epoch:[ 2 ] Batch: 579 / 937 Main Model Loss: 0.042114574 Interpreter Loss: 15431.025\n",
      "Epoch:[ 2 ] Batch: 580 / 937 Main Model Loss: 0.019293677 Interpreter Loss: 14749.307\n",
      "Epoch:[ 2 ] Batch: 581 / 937 Main Model Loss: 0.0054589477 Interpreter Loss: 14419.391\n",
      "Epoch:[ 2 ] Batch: 582 / 937 Main Model Loss: 0.0068162493 Interpreter Loss: 15182.661\n",
      "Epoch:[ 2 ] Batch: 583 / 937 Main Model Loss: 0.019222422 Interpreter Loss: 15011.866\n",
      "Epoch:[ 2 ] Batch: 584 / 937 Main Model Loss: 0.036950067 Interpreter Loss: 14436.541\n",
      "Epoch:[ 2 ] Batch: 585 / 937 Main Model Loss: 0.047716383 Interpreter Loss: 15614.053\n",
      "Epoch:[ 2 ] Batch: 586 / 937 Main Model Loss: 0.004840022 Interpreter Loss: 13373.658\n",
      "Epoch:[ 2 ] Batch: 587 / 937 Main Model Loss: 0.006594677 Interpreter Loss: 13013.01\n",
      "Epoch:[ 2 ] Batch: 588 / 937 Main Model Loss: 0.023616403 Interpreter Loss: 13018.137\n",
      "Epoch:[ 2 ] Batch: 589 / 937 Main Model Loss: 0.032171827 Interpreter Loss: 14522.446\n",
      "Epoch:[ 2 ] Batch: 590 / 937 Main Model Loss: 0.035872467 Interpreter Loss: 14445.469\n",
      "Epoch:[ 2 ] Batch: 591 / 937 Main Model Loss: 0.09152505 Interpreter Loss: 13771.744\n",
      "Epoch:[ 2 ] Batch: 592 / 937 Main Model Loss: 0.0061775246 Interpreter Loss: 13214.075\n",
      "Epoch:[ 2 ] Batch: 593 / 937 Main Model Loss: 0.009074835 Interpreter Loss: 13239.839\n",
      "Epoch:[ 2 ] Batch: 594 / 937 Main Model Loss: 0.028495654 Interpreter Loss: 12671.472\n",
      "Epoch:[ 2 ] Batch: 595 / 937 Main Model Loss: 0.005854169 Interpreter Loss: 13567.168\n",
      "Epoch:[ 2 ] Batch: 596 / 937 Main Model Loss: 0.006042806 Interpreter Loss: 13754.404\n",
      "Epoch:[ 2 ] Batch: 597 / 937 Main Model Loss: 0.008255237 Interpreter Loss: 13480.73\n",
      "Epoch:[ 2 ] Batch: 598 / 937 Main Model Loss: 0.017510759 Interpreter Loss: 13627.648\n",
      "Epoch:[ 2 ] Batch: 599 / 937 Main Model Loss: 0.041702226 Interpreter Loss: 13796.303\n",
      "Epoch:[ 2 ] Batch: 600 / 937 Main Model Loss: 0.01840752 Interpreter Loss: 13331.467\n",
      "Epoch:[ 2 ] Batch: 601 / 937 Main Model Loss: 0.015277907 Interpreter Loss: 12850.344\n",
      "Epoch:[ 2 ] Batch: 602 / 937 Main Model Loss: 0.011287964 Interpreter Loss: 13536.176\n",
      "Epoch:[ 2 ] Batch: 603 / 937 Main Model Loss: 0.04748585 Interpreter Loss: 14973.694\n",
      "Epoch:[ 2 ] Batch: 604 / 937 Main Model Loss: 0.07072505 Interpreter Loss: 13415.591\n",
      "Epoch:[ 2 ] Batch: 605 / 937 Main Model Loss: 0.014540055 Interpreter Loss: 13577.729\n",
      "Epoch:[ 2 ] Batch: 606 / 937 Main Model Loss: 0.023405258 Interpreter Loss: 13387.713\n",
      "Epoch:[ 2 ] Batch: 607 / 937 Main Model Loss: 0.00636389 Interpreter Loss: 13564.521\n",
      "Epoch:[ 2 ] Batch: 608 / 937 Main Model Loss: 0.012909032 Interpreter Loss: 13248.252\n",
      "Epoch:[ 2 ] Batch: 609 / 937 Main Model Loss: 0.015514522 Interpreter Loss: 12813.973\n",
      "Epoch:[ 2 ] Batch: 610 / 937 Main Model Loss: 0.0036350428 Interpreter Loss: 13392.206\n",
      "Epoch:[ 2 ] Batch: 611 / 937 Main Model Loss: 0.005705832 Interpreter Loss: 14155.6\n",
      "Epoch:[ 2 ] Batch: 612 / 937 Main Model Loss: 0.0472512 Interpreter Loss: 14042.12\n",
      "Epoch:[ 2 ] Batch: 613 / 937 Main Model Loss: 0.022056665 Interpreter Loss: 14329.675\n",
      "Epoch:[ 2 ] Batch: 614 / 937 Main Model Loss: 0.031407647 Interpreter Loss: 14676.044\n",
      "Epoch:[ 2 ] Batch: 615 / 937 Main Model Loss: 0.048365243 Interpreter Loss: 14704.227\n",
      "Epoch:[ 2 ] Batch: 616 / 937 Main Model Loss: 0.016578153 Interpreter Loss: 14829.585\n",
      "Epoch:[ 2 ] Batch: 617 / 937 Main Model Loss: 0.0056338334 Interpreter Loss: 13650.116\n",
      "Epoch:[ 2 ] Batch: 618 / 937 Main Model Loss: 0.008886888 Interpreter Loss: 13985.5\n",
      "Epoch:[ 2 ] Batch: 619 / 937 Main Model Loss: 0.021270216 Interpreter Loss: 14288.744\n",
      "Epoch:[ 2 ] Batch: 620 / 937 Main Model Loss: 0.022773612 Interpreter Loss: 13365.967\n",
      "Epoch:[ 2 ] Batch: 621 / 937 Main Model Loss: 0.03169363 Interpreter Loss: 12579.375\n",
      "Epoch:[ 2 ] Batch: 622 / 937 Main Model Loss: 0.025009796 Interpreter Loss: 13116.285\n",
      "Epoch:[ 2 ] Batch: 623 / 937 Main Model Loss: 0.015093826 Interpreter Loss: 12669.897\n",
      "Epoch:[ 2 ] Batch: 624 / 937 Main Model Loss: 0.021019097 Interpreter Loss: 14270.957\n",
      "Epoch:[ 2 ] Batch: 625 / 937 Main Model Loss: 0.014708233 Interpreter Loss: 13533.73\n",
      "Epoch:[ 2 ] Batch: 626 / 937 Main Model Loss: 0.013710616 Interpreter Loss: 14033.785\n",
      "Epoch:[ 2 ] Batch: 627 / 937 Main Model Loss: 0.051005177 Interpreter Loss: 13260.012\n",
      "Epoch:[ 2 ] Batch: 628 / 937 Main Model Loss: 0.013513786 Interpreter Loss: 13437.561\n",
      "Epoch:[ 2 ] Batch: 629 / 937 Main Model Loss: 0.014355024 Interpreter Loss: 13746.152\n",
      "Epoch:[ 2 ] Batch: 630 / 937 Main Model Loss: 0.012335088 Interpreter Loss: 13071.76\n",
      "Epoch:[ 2 ] Batch: 631 / 937 Main Model Loss: 0.013486389 Interpreter Loss: 14138.552\n",
      "Epoch:[ 2 ] Batch: 632 / 937 Main Model Loss: 0.011812916 Interpreter Loss: 14668.266\n",
      "Epoch:[ 2 ] Batch: 633 / 937 Main Model Loss: 0.005604598 Interpreter Loss: 13954.975\n",
      "Epoch:[ 2 ] Batch: 634 / 937 Main Model Loss: 0.021552565 Interpreter Loss: 13798.344\n",
      "Epoch:[ 2 ] Batch: 635 / 937 Main Model Loss: 0.0060272356 Interpreter Loss: 13050.165\n",
      "Epoch:[ 2 ] Batch: 636 / 937 Main Model Loss: 0.016244793 Interpreter Loss: 13344.846\n",
      "Epoch:[ 2 ] Batch: 637 / 937 Main Model Loss: 0.012917643 Interpreter Loss: 12763.597\n",
      "Epoch:[ 2 ] Batch: 638 / 937 Main Model Loss: 0.013063465 Interpreter Loss: 13859.527\n",
      "Epoch:[ 2 ] Batch: 639 / 937 Main Model Loss: 0.010536983 Interpreter Loss: 12889.83\n",
      "Epoch:[ 2 ] Batch: 640 / 937 Main Model Loss: 0.031603597 Interpreter Loss: 13604.7705\n",
      "Epoch:[ 2 ] Batch: 641 / 937 Main Model Loss: 0.025562005 Interpreter Loss: 13344.124\n",
      "Epoch:[ 2 ] Batch: 642 / 937 Main Model Loss: 0.013970334 Interpreter Loss: 13096.766\n",
      "Epoch:[ 2 ] Batch: 643 / 937 Main Model Loss: 0.011803852 Interpreter Loss: 14224.914\n",
      "Epoch:[ 2 ] Batch: 644 / 937 Main Model Loss: 0.03896886 Interpreter Loss: 13757.994\n",
      "Epoch:[ 2 ] Batch: 645 / 937 Main Model Loss: 0.053993985 Interpreter Loss: 15017.171\n",
      "Epoch:[ 2 ] Batch: 646 / 937 Main Model Loss: 0.018208865 Interpreter Loss: 14628.469\n",
      "Epoch:[ 2 ] Batch: 647 / 937 Main Model Loss: 0.025790265 Interpreter Loss: 13927.387\n",
      "Epoch:[ 2 ] Batch: 648 / 937 Main Model Loss: 0.008524905 Interpreter Loss: 12672.1455\n",
      "Epoch:[ 2 ] Batch: 649 / 937 Main Model Loss: 0.03171811 Interpreter Loss: 14723.44\n",
      "Epoch:[ 2 ] Batch: 650 / 937 Main Model Loss: 0.011271346 Interpreter Loss: 13044.769\n",
      "Epoch:[ 2 ] Batch: 651 / 937 Main Model Loss: 0.01714969 Interpreter Loss: 11962.088\n",
      "Epoch:[ 2 ] Batch: 652 / 937 Main Model Loss: 0.0036048563 Interpreter Loss: 11858.147\n",
      "Epoch:[ 2 ] Batch: 653 / 937 Main Model Loss: 0.020066166 Interpreter Loss: 12651.098\n",
      "Epoch:[ 2 ] Batch: 654 / 937 Main Model Loss: 0.030182837 Interpreter Loss: 14027.64\n",
      "Epoch:[ 2 ] Batch: 655 / 937 Main Model Loss: 0.0073064277 Interpreter Loss: 13772.341\n",
      "Epoch:[ 2 ] Batch: 656 / 937 Main Model Loss: 0.015921919 Interpreter Loss: 14723.497\n",
      "Epoch:[ 2 ] Batch: 657 / 937 Main Model Loss: 0.0011777428 Interpreter Loss: 13690.424\n",
      "Epoch:[ 2 ] Batch: 658 / 937 Main Model Loss: 0.012093155 Interpreter Loss: 13864.986\n",
      "Epoch:[ 2 ] Batch: 659 / 937 Main Model Loss: 0.013723694 Interpreter Loss: 13882.059\n",
      "Epoch:[ 2 ] Batch: 660 / 937 Main Model Loss: 0.008066187 Interpreter Loss: 13717.365\n",
      "Epoch:[ 2 ] Batch: 661 / 937 Main Model Loss: 0.013619497 Interpreter Loss: 13882.106\n",
      "Epoch:[ 2 ] Batch: 662 / 937 Main Model Loss: 0.033867363 Interpreter Loss: 13879.591\n",
      "Epoch:[ 2 ] Batch: 663 / 937 Main Model Loss: 0.041115925 Interpreter Loss: 13737.61\n",
      "Epoch:[ 2 ] Batch: 664 / 937 Main Model Loss: 0.0071950625 Interpreter Loss: 13323.818\n",
      "Epoch:[ 2 ] Batch: 665 / 937 Main Model Loss: 0.06263272 Interpreter Loss: 14075.049\n",
      "Epoch:[ 2 ] Batch: 666 / 937 Main Model Loss: 0.012924296 Interpreter Loss: 14626.867\n",
      "Epoch:[ 2 ] Batch: 667 / 937 Main Model Loss: 0.011906229 Interpreter Loss: 13962.834\n",
      "Epoch:[ 2 ] Batch: 668 / 937 Main Model Loss: 0.013347434 Interpreter Loss: 14627.147\n",
      "Epoch:[ 2 ] Batch: 669 / 937 Main Model Loss: 0.035888966 Interpreter Loss: 14943.894\n",
      "Epoch:[ 2 ] Batch: 670 / 937 Main Model Loss: 0.038861144 Interpreter Loss: 13160.259\n",
      "Epoch:[ 2 ] Batch: 671 / 937 Main Model Loss: 0.01379025 Interpreter Loss: 12934.337\n",
      "Epoch:[ 2 ] Batch: 672 / 937 Main Model Loss: 0.013554021 Interpreter Loss: 13263.356\n",
      "Epoch:[ 2 ] Batch: 673 / 937 Main Model Loss: 0.098444894 Interpreter Loss: 12472.643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 2 ] Batch: 674 / 937 Main Model Loss: 0.018448966 Interpreter Loss: 13847.685\n",
      "Epoch:[ 2 ] Batch: 675 / 937 Main Model Loss: 0.0143618155 Interpreter Loss: 13641.527\n",
      "Epoch:[ 2 ] Batch: 676 / 937 Main Model Loss: 0.0027535772 Interpreter Loss: 12970.145\n",
      "Epoch:[ 2 ] Batch: 677 / 937 Main Model Loss: 0.007116332 Interpreter Loss: 13328.981\n",
      "Epoch:[ 2 ] Batch: 678 / 937 Main Model Loss: 0.09061899 Interpreter Loss: 13045.039\n",
      "Epoch:[ 2 ] Batch: 679 / 937 Main Model Loss: 0.010250324 Interpreter Loss: 13634.677\n",
      "Epoch:[ 2 ] Batch: 680 / 937 Main Model Loss: 0.015304892 Interpreter Loss: 13516.312\n",
      "Epoch:[ 2 ] Batch: 681 / 937 Main Model Loss: 0.0258388 Interpreter Loss: 13907.911\n",
      "Epoch:[ 2 ] Batch: 682 / 937 Main Model Loss: 0.0366969 Interpreter Loss: 13652.686\n",
      "Epoch:[ 2 ] Batch: 683 / 937 Main Model Loss: 0.0010128556 Interpreter Loss: 12906.29\n",
      "Epoch:[ 2 ] Batch: 684 / 937 Main Model Loss: 0.02329561 Interpreter Loss: 13137.891\n",
      "Epoch:[ 2 ] Batch: 685 / 937 Main Model Loss: 0.016436482 Interpreter Loss: 13669.789\n",
      "Epoch:[ 2 ] Batch: 686 / 937 Main Model Loss: 0.024755146 Interpreter Loss: 13019.273\n",
      "Epoch:[ 2 ] Batch: 687 / 937 Main Model Loss: 0.020583147 Interpreter Loss: 12756.492\n",
      "Epoch:[ 2 ] Batch: 688 / 937 Main Model Loss: 0.0141063025 Interpreter Loss: 13629.607\n",
      "Epoch:[ 2 ] Batch: 689 / 937 Main Model Loss: 0.010478278 Interpreter Loss: 13068.273\n",
      "Epoch:[ 2 ] Batch: 690 / 937 Main Model Loss: 0.020830665 Interpreter Loss: 13540.517\n",
      "Epoch:[ 2 ] Batch: 691 / 937 Main Model Loss: 0.017513424 Interpreter Loss: 13410.555\n",
      "Epoch:[ 2 ] Batch: 692 / 937 Main Model Loss: 0.011837104 Interpreter Loss: 13794.62\n",
      "Epoch:[ 2 ] Batch: 693 / 937 Main Model Loss: 0.03636361 Interpreter Loss: 13095.456\n",
      "Epoch:[ 2 ] Batch: 694 / 937 Main Model Loss: 0.14342885 Interpreter Loss: 13781.253\n",
      "Epoch:[ 2 ] Batch: 695 / 937 Main Model Loss: 0.007877671 Interpreter Loss: 13244.225\n",
      "Epoch:[ 2 ] Batch: 696 / 937 Main Model Loss: 0.006268371 Interpreter Loss: 12950.0625\n",
      "Epoch:[ 2 ] Batch: 697 / 937 Main Model Loss: 0.013448315 Interpreter Loss: 13385.807\n",
      "Epoch:[ 2 ] Batch: 698 / 937 Main Model Loss: 0.008857359 Interpreter Loss: 12701.576\n",
      "Epoch:[ 2 ] Batch: 699 / 937 Main Model Loss: 0.004342068 Interpreter Loss: 12959.382\n",
      "Epoch:[ 2 ] Batch: 700 / 937 Main Model Loss: 0.025345325 Interpreter Loss: 13664.835\n",
      "Epoch:[ 2 ] Batch: 701 / 937 Main Model Loss: 0.025410771 Interpreter Loss: 13588.457\n",
      "Epoch:[ 2 ] Batch: 702 / 937 Main Model Loss: 0.015024991 Interpreter Loss: 13802.598\n",
      "Epoch:[ 2 ] Batch: 703 / 937 Main Model Loss: 0.008833285 Interpreter Loss: 13553.705\n",
      "Epoch:[ 2 ] Batch: 704 / 937 Main Model Loss: 0.008994682 Interpreter Loss: 13642.887\n",
      "Epoch:[ 2 ] Batch: 705 / 937 Main Model Loss: 0.04808894 Interpreter Loss: 13356.635\n",
      "Epoch:[ 2 ] Batch: 706 / 937 Main Model Loss: 0.011147326 Interpreter Loss: 13239.847\n",
      "Epoch:[ 2 ] Batch: 707 / 937 Main Model Loss: 0.026303224 Interpreter Loss: 13665.404\n",
      "Epoch:[ 2 ] Batch: 708 / 937 Main Model Loss: 0.058702182 Interpreter Loss: 12890.464\n",
      "Epoch:[ 2 ] Batch: 709 / 937 Main Model Loss: 0.01123654 Interpreter Loss: 13449.501\n",
      "Epoch:[ 2 ] Batch: 710 / 937 Main Model Loss: 0.013919145 Interpreter Loss: 13037.235\n",
      "Epoch:[ 2 ] Batch: 711 / 937 Main Model Loss: 0.043777574 Interpreter Loss: 13283.979\n",
      "Epoch:[ 2 ] Batch: 712 / 937 Main Model Loss: 0.009330086 Interpreter Loss: 13438.176\n",
      "Epoch:[ 2 ] Batch: 713 / 937 Main Model Loss: 0.010317652 Interpreter Loss: 13208.62\n",
      "Epoch:[ 2 ] Batch: 714 / 937 Main Model Loss: 0.009170757 Interpreter Loss: 13037.693\n",
      "Epoch:[ 2 ] Batch: 715 / 937 Main Model Loss: 0.019769454 Interpreter Loss: 13697.574\n",
      "Epoch:[ 2 ] Batch: 716 / 937 Main Model Loss: 0.015463033 Interpreter Loss: 13832.467\n",
      "Epoch:[ 2 ] Batch: 717 / 937 Main Model Loss: 0.019037394 Interpreter Loss: 12621.632\n",
      "Epoch:[ 2 ] Batch: 718 / 937 Main Model Loss: 0.017944474 Interpreter Loss: 12612.331\n",
      "Epoch:[ 2 ] Batch: 719 / 937 Main Model Loss: 0.036888786 Interpreter Loss: 13117.479\n",
      "Epoch:[ 2 ] Batch: 720 / 937 Main Model Loss: 0.01588551 Interpreter Loss: 12965.652\n",
      "Epoch:[ 2 ] Batch: 721 / 937 Main Model Loss: 0.0048892004 Interpreter Loss: 12890.965\n",
      "Epoch:[ 2 ] Batch: 722 / 937 Main Model Loss: 0.059240766 Interpreter Loss: 14785.217\n",
      "Epoch:[ 2 ] Batch: 723 / 937 Main Model Loss: 0.05437205 Interpreter Loss: 13891.441\n",
      "Epoch:[ 2 ] Batch: 724 / 937 Main Model Loss: 0.018904384 Interpreter Loss: 13863.226\n",
      "Epoch:[ 2 ] Batch: 725 / 937 Main Model Loss: 0.027322548 Interpreter Loss: 13956.028\n",
      "Epoch:[ 2 ] Batch: 726 / 937 Main Model Loss: 0.005487495 Interpreter Loss: 12830.883\n",
      "Epoch:[ 2 ] Batch: 727 / 937 Main Model Loss: 0.006890733 Interpreter Loss: 12974.455\n",
      "Epoch:[ 2 ] Batch: 728 / 937 Main Model Loss: 0.0047759563 Interpreter Loss: 13218.028\n",
      "Epoch:[ 2 ] Batch: 729 / 937 Main Model Loss: 0.0110341795 Interpreter Loss: 13746.439\n",
      "Epoch:[ 2 ] Batch: 730 / 937 Main Model Loss: 0.057311136 Interpreter Loss: 14625.891\n",
      "Epoch:[ 2 ] Batch: 731 / 937 Main Model Loss: 0.015364602 Interpreter Loss: 13669.791\n",
      "Epoch:[ 2 ] Batch: 732 / 937 Main Model Loss: 0.04761708 Interpreter Loss: 13651.929\n",
      "Epoch:[ 2 ] Batch: 733 / 937 Main Model Loss: 0.0042355 Interpreter Loss: 13177.827\n",
      "Epoch:[ 2 ] Batch: 734 / 937 Main Model Loss: 0.032095045 Interpreter Loss: 14561.412\n",
      "Epoch:[ 2 ] Batch: 735 / 937 Main Model Loss: 0.02239897 Interpreter Loss: 13170.294\n",
      "Epoch:[ 2 ] Batch: 736 / 937 Main Model Loss: 0.030962542 Interpreter Loss: 13326.313\n",
      "Epoch:[ 2 ] Batch: 737 / 937 Main Model Loss: 0.0059063598 Interpreter Loss: 12948.7\n",
      "Epoch:[ 2 ] Batch: 738 / 937 Main Model Loss: 0.041062675 Interpreter Loss: 13592.121\n",
      "Epoch:[ 2 ] Batch: 739 / 937 Main Model Loss: 0.029639108 Interpreter Loss: 12517.457\n",
      "Epoch:[ 2 ] Batch: 740 / 937 Main Model Loss: 0.018742528 Interpreter Loss: 13825.146\n",
      "Epoch:[ 2 ] Batch: 741 / 937 Main Model Loss: 0.06674174 Interpreter Loss: 14756.426\n",
      "Epoch:[ 2 ] Batch: 742 / 937 Main Model Loss: 0.019109316 Interpreter Loss: 13406.615\n",
      "Epoch:[ 2 ] Batch: 743 / 937 Main Model Loss: 0.035881564 Interpreter Loss: 15164.323\n",
      "Epoch:[ 2 ] Batch: 744 / 937 Main Model Loss: 0.0078863045 Interpreter Loss: 14394.696\n",
      "Epoch:[ 2 ] Batch: 745 / 937 Main Model Loss: 0.01779766 Interpreter Loss: 14325.384\n",
      "Epoch:[ 2 ] Batch: 746 / 937 Main Model Loss: 0.0100488365 Interpreter Loss: 13702.289\n",
      "Epoch:[ 2 ] Batch: 747 / 937 Main Model Loss: 0.0043538962 Interpreter Loss: 13607.902\n",
      "Epoch:[ 2 ] Batch: 748 / 937 Main Model Loss: 0.02898129 Interpreter Loss: 14333.987\n",
      "Epoch:[ 2 ] Batch: 749 / 937 Main Model Loss: 0.020662596 Interpreter Loss: 13490.531\n",
      "Epoch:[ 2 ] Batch: 750 / 937 Main Model Loss: 0.011323793 Interpreter Loss: 14633.43\n",
      "Epoch:[ 2 ] Batch: 751 / 937 Main Model Loss: 0.029648054 Interpreter Loss: 14587.57\n",
      "Epoch:[ 2 ] Batch: 752 / 937 Main Model Loss: 0.0056726886 Interpreter Loss: 14191.785\n",
      "Epoch:[ 2 ] Batch: 753 / 937 Main Model Loss: 0.01807474 Interpreter Loss: 14084.02\n",
      "Epoch:[ 2 ] Batch: 754 / 937 Main Model Loss: 0.021718353 Interpreter Loss: 14267.087\n",
      "Epoch:[ 2 ] Batch: 755 / 937 Main Model Loss: 0.030989628 Interpreter Loss: 14836.077\n",
      "Epoch:[ 2 ] Batch: 756 / 937 Main Model Loss: 0.027709708 Interpreter Loss: 14234.87\n",
      "Epoch:[ 2 ] Batch: 757 / 937 Main Model Loss: 0.0073870462 Interpreter Loss: 13442.036\n",
      "Epoch:[ 2 ] Batch: 758 / 937 Main Model Loss: 0.021595402 Interpreter Loss: 14099.068\n",
      "Epoch:[ 2 ] Batch: 759 / 937 Main Model Loss: 0.018868351 Interpreter Loss: 13748.964\n",
      "Epoch:[ 2 ] Batch: 760 / 937 Main Model Loss: 0.0078118374 Interpreter Loss: 13508.957\n",
      "Epoch:[ 2 ] Batch: 761 / 937 Main Model Loss: 0.004159596 Interpreter Loss: 13661.057\n",
      "Epoch:[ 2 ] Batch: 762 / 937 Main Model Loss: 0.00796063 Interpreter Loss: 14028.376\n",
      "Epoch:[ 2 ] Batch: 763 / 937 Main Model Loss: 0.016352836 Interpreter Loss: 13548.816\n",
      "Epoch:[ 2 ] Batch: 764 / 937 Main Model Loss: 0.02199598 Interpreter Loss: 13182.725\n",
      "Epoch:[ 2 ] Batch: 765 / 937 Main Model Loss: 0.041022886 Interpreter Loss: 14006.68\n",
      "Epoch:[ 2 ] Batch: 766 / 937 Main Model Loss: 0.07838087 Interpreter Loss: 13466.831\n",
      "Epoch:[ 2 ] Batch: 767 / 937 Main Model Loss: 0.027181309 Interpreter Loss: 13428.211\n",
      "Epoch:[ 2 ] Batch: 768 / 937 Main Model Loss: 0.01305639 Interpreter Loss: 13691.517\n",
      "Epoch:[ 2 ] Batch: 769 / 937 Main Model Loss: 0.008362989 Interpreter Loss: 13763.823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 2 ] Batch: 770 / 937 Main Model Loss: 0.010866656 Interpreter Loss: 13076.552\n",
      "Epoch:[ 2 ] Batch: 771 / 937 Main Model Loss: 0.006277198 Interpreter Loss: 12865.439\n",
      "Epoch:[ 2 ] Batch: 772 / 937 Main Model Loss: 0.023286838 Interpreter Loss: 13463.374\n",
      "Epoch:[ 2 ] Batch: 773 / 937 Main Model Loss: 0.035667103 Interpreter Loss: 14170.061\n",
      "Epoch:[ 2 ] Batch: 774 / 937 Main Model Loss: 0.09577307 Interpreter Loss: 14297.912\n",
      "Epoch:[ 2 ] Batch: 775 / 937 Main Model Loss: 0.005414056 Interpreter Loss: 13561.68\n",
      "Epoch:[ 2 ] Batch: 776 / 937 Main Model Loss: 0.005185443 Interpreter Loss: 12441.148\n",
      "Epoch:[ 2 ] Batch: 777 / 937 Main Model Loss: 0.022034384 Interpreter Loss: 14179.078\n",
      "Epoch:[ 2 ] Batch: 778 / 937 Main Model Loss: 0.015612993 Interpreter Loss: 12868.359\n",
      "Epoch:[ 2 ] Batch: 779 / 937 Main Model Loss: 0.034198657 Interpreter Loss: 14426.9795\n",
      "Epoch:[ 2 ] Batch: 780 / 937 Main Model Loss: 0.013560486 Interpreter Loss: 12945.889\n",
      "Epoch:[ 2 ] Batch: 781 / 937 Main Model Loss: 0.008937271 Interpreter Loss: 12705.969\n",
      "Epoch:[ 2 ] Batch: 782 / 937 Main Model Loss: 0.003597586 Interpreter Loss: 13063.96\n",
      "Epoch:[ 2 ] Batch: 783 / 937 Main Model Loss: 0.0076637845 Interpreter Loss: 13464.137\n",
      "Epoch:[ 2 ] Batch: 784 / 937 Main Model Loss: 0.05424271 Interpreter Loss: 13531.8\n",
      "Epoch:[ 2 ] Batch: 785 / 937 Main Model Loss: 0.0021716314 Interpreter Loss: 12856.793\n",
      "Epoch:[ 2 ] Batch: 786 / 937 Main Model Loss: 0.023614299 Interpreter Loss: 14140.549\n",
      "Epoch:[ 2 ] Batch: 787 / 937 Main Model Loss: 0.048619796 Interpreter Loss: 14139.473\n",
      "Epoch:[ 2 ] Batch: 788 / 937 Main Model Loss: 0.010083779 Interpreter Loss: 13179.015\n",
      "Epoch:[ 2 ] Batch: 789 / 937 Main Model Loss: 0.026647424 Interpreter Loss: 14063.329\n",
      "Epoch:[ 2 ] Batch: 790 / 937 Main Model Loss: 0.007473913 Interpreter Loss: 12978.232\n",
      "Epoch:[ 2 ] Batch: 791 / 937 Main Model Loss: 0.004115203 Interpreter Loss: 12535.531\n",
      "Epoch:[ 2 ] Batch: 792 / 937 Main Model Loss: 0.020727314 Interpreter Loss: 13623.999\n",
      "Epoch:[ 2 ] Batch: 793 / 937 Main Model Loss: 0.00454483 Interpreter Loss: 13803.445\n",
      "Epoch:[ 2 ] Batch: 794 / 937 Main Model Loss: 0.009757129 Interpreter Loss: 13209.054\n",
      "Epoch:[ 2 ] Batch: 795 / 937 Main Model Loss: 0.03489328 Interpreter Loss: 13818.447\n",
      "Epoch:[ 2 ] Batch: 796 / 937 Main Model Loss: 0.014836389 Interpreter Loss: 13303.808\n",
      "Epoch:[ 2 ] Batch: 797 / 937 Main Model Loss: 0.014714348 Interpreter Loss: 12779.496\n",
      "Epoch:[ 2 ] Batch: 798 / 937 Main Model Loss: 0.0069109336 Interpreter Loss: 13143.306\n",
      "Epoch:[ 2 ] Batch: 799 / 937 Main Model Loss: 0.008301581 Interpreter Loss: 13983.899\n",
      "Epoch:[ 2 ] Batch: 800 / 937 Main Model Loss: 0.06530657 Interpreter Loss: 14760.664\n",
      "Epoch:[ 2 ] Batch: 801 / 937 Main Model Loss: 0.014543643 Interpreter Loss: 14435.75\n",
      "Epoch:[ 2 ] Batch: 802 / 937 Main Model Loss: 0.004162884 Interpreter Loss: 13593.28\n",
      "Epoch:[ 2 ] Batch: 803 / 937 Main Model Loss: 0.013632329 Interpreter Loss: 12981.274\n",
      "Epoch:[ 2 ] Batch: 804 / 937 Main Model Loss: 0.048178647 Interpreter Loss: 13943.724\n",
      "Epoch:[ 2 ] Batch: 805 / 937 Main Model Loss: 0.016572615 Interpreter Loss: 13035.511\n",
      "Epoch:[ 2 ] Batch: 806 / 937 Main Model Loss: 0.0100876 Interpreter Loss: 13665.47\n",
      "Epoch:[ 2 ] Batch: 807 / 937 Main Model Loss: 0.0081585515 Interpreter Loss: 12763.297\n",
      "Epoch:[ 2 ] Batch: 808 / 937 Main Model Loss: 0.007421899 Interpreter Loss: 13153.542\n",
      "Epoch:[ 2 ] Batch: 809 / 937 Main Model Loss: 0.008930876 Interpreter Loss: 12850.978\n",
      "Epoch:[ 2 ] Batch: 810 / 937 Main Model Loss: 0.0046974113 Interpreter Loss: 12452.711\n",
      "Epoch:[ 2 ] Batch: 811 / 937 Main Model Loss: 0.07260032 Interpreter Loss: 13371.855\n",
      "Epoch:[ 2 ] Batch: 812 / 937 Main Model Loss: 0.045962643 Interpreter Loss: 13228.609\n",
      "Epoch:[ 2 ] Batch: 813 / 937 Main Model Loss: 0.009733653 Interpreter Loss: 12471.713\n",
      "Epoch:[ 2 ] Batch: 814 / 937 Main Model Loss: 0.080141194 Interpreter Loss: 12908.707\n",
      "Epoch:[ 2 ] Batch: 815 / 937 Main Model Loss: 0.018903747 Interpreter Loss: 12544.221\n",
      "Epoch:[ 2 ] Batch: 816 / 937 Main Model Loss: 0.061564006 Interpreter Loss: 12664.966\n",
      "Epoch:[ 2 ] Batch: 817 / 937 Main Model Loss: 0.040719386 Interpreter Loss: 12982.934\n",
      "Epoch:[ 2 ] Batch: 818 / 937 Main Model Loss: 0.0056495024 Interpreter Loss: 12589.186\n",
      "Epoch:[ 2 ] Batch: 819 / 937 Main Model Loss: 0.01611504 Interpreter Loss: 14065.96\n",
      "Epoch:[ 2 ] Batch: 820 / 937 Main Model Loss: 0.0021866998 Interpreter Loss: 13058.15\n",
      "Epoch:[ 2 ] Batch: 821 / 937 Main Model Loss: 0.006739533 Interpreter Loss: 13023.164\n",
      "Epoch:[ 2 ] Batch: 822 / 937 Main Model Loss: 0.0312697 Interpreter Loss: 13888.976\n",
      "Epoch:[ 2 ] Batch: 823 / 937 Main Model Loss: 0.013420461 Interpreter Loss: 12933.807\n",
      "Epoch:[ 2 ] Batch: 824 / 937 Main Model Loss: 0.00504537 Interpreter Loss: 12514.718\n",
      "Epoch:[ 2 ] Batch: 825 / 937 Main Model Loss: 0.10461434 Interpreter Loss: 13791.003\n",
      "Epoch:[ 2 ] Batch: 826 / 937 Main Model Loss: 0.09095715 Interpreter Loss: 14805.516\n",
      "Epoch:[ 2 ] Batch: 827 / 937 Main Model Loss: 0.13190077 Interpreter Loss: 14967.903\n",
      "Epoch:[ 2 ] Batch: 828 / 937 Main Model Loss: 0.011753311 Interpreter Loss: 13900.875\n",
      "Epoch:[ 2 ] Batch: 829 / 937 Main Model Loss: 0.011675232 Interpreter Loss: 14018.255\n",
      "Epoch:[ 2 ] Batch: 830 / 937 Main Model Loss: 0.004345503 Interpreter Loss: 13355.907\n",
      "Epoch:[ 2 ] Batch: 831 / 937 Main Model Loss: 0.0069854823 Interpreter Loss: 13707.688\n",
      "Epoch:[ 2 ] Batch: 832 / 937 Main Model Loss: 0.0014872194 Interpreter Loss: 12605.643\n",
      "Epoch:[ 2 ] Batch: 833 / 937 Main Model Loss: 0.0033099714 Interpreter Loss: 12439.659\n",
      "Epoch:[ 2 ] Batch: 834 / 937 Main Model Loss: 0.030367484 Interpreter Loss: 12958.525\n",
      "Epoch:[ 2 ] Batch: 835 / 937 Main Model Loss: 0.023866637 Interpreter Loss: 13107.751\n",
      "Epoch:[ 2 ] Batch: 836 / 937 Main Model Loss: 0.0139363175 Interpreter Loss: 13210.524\n",
      "Epoch:[ 2 ] Batch: 837 / 937 Main Model Loss: 0.0024712468 Interpreter Loss: 12405.926\n",
      "Epoch:[ 2 ] Batch: 838 / 937 Main Model Loss: 0.049793538 Interpreter Loss: 14148.489\n",
      "Epoch:[ 2 ] Batch: 839 / 937 Main Model Loss: 0.0063906973 Interpreter Loss: 12841.867\n",
      "Epoch:[ 2 ] Batch: 840 / 937 Main Model Loss: 0.0013680949 Interpreter Loss: 12351.33\n",
      "Epoch:[ 2 ] Batch: 841 / 937 Main Model Loss: 0.014614044 Interpreter Loss: 13586.33\n",
      "Epoch:[ 2 ] Batch: 842 / 937 Main Model Loss: 0.0152325835 Interpreter Loss: 13964.815\n",
      "Epoch:[ 2 ] Batch: 843 / 937 Main Model Loss: 0.048555035 Interpreter Loss: 13902.443\n",
      "Epoch:[ 2 ] Batch: 844 / 937 Main Model Loss: 0.04642875 Interpreter Loss: 13747.434\n",
      "Epoch:[ 2 ] Batch: 845 / 937 Main Model Loss: 0.018394098 Interpreter Loss: 13423.711\n",
      "Epoch:[ 2 ] Batch: 846 / 937 Main Model Loss: 0.01976798 Interpreter Loss: 12974.143\n",
      "Epoch:[ 2 ] Batch: 847 / 937 Main Model Loss: 0.044937976 Interpreter Loss: 11975.854\n",
      "Epoch:[ 2 ] Batch: 848 / 937 Main Model Loss: 0.053390186 Interpreter Loss: 13527.561\n",
      "Epoch:[ 2 ] Batch: 849 / 937 Main Model Loss: 0.0034449867 Interpreter Loss: 13529.176\n",
      "Epoch:[ 2 ] Batch: 850 / 937 Main Model Loss: 0.014557188 Interpreter Loss: 14046.593\n",
      "Epoch:[ 2 ] Batch: 851 / 937 Main Model Loss: 0.007926804 Interpreter Loss: 14087.318\n",
      "Epoch:[ 2 ] Batch: 852 / 937 Main Model Loss: 0.03518754 Interpreter Loss: 13999.375\n",
      "Epoch:[ 2 ] Batch: 853 / 937 Main Model Loss: 0.018892236 Interpreter Loss: 13333.025\n",
      "Epoch:[ 2 ] Batch: 854 / 937 Main Model Loss: 0.005775247 Interpreter Loss: 13358.034\n",
      "Epoch:[ 2 ] Batch: 855 / 937 Main Model Loss: 0.020333603 Interpreter Loss: 13981.536\n",
      "Epoch:[ 2 ] Batch: 856 / 937 Main Model Loss: 0.012399154 Interpreter Loss: 13509.3125\n",
      "Epoch:[ 2 ] Batch: 857 / 937 Main Model Loss: 0.0351997 Interpreter Loss: 14183.756\n",
      "Epoch:[ 2 ] Batch: 858 / 937 Main Model Loss: 0.016593372 Interpreter Loss: 13895.911\n",
      "Epoch:[ 2 ] Batch: 859 / 937 Main Model Loss: 0.016164947 Interpreter Loss: 13733.747\n",
      "Epoch:[ 2 ] Batch: 860 / 937 Main Model Loss: 0.0066004847 Interpreter Loss: 12823.41\n",
      "Epoch:[ 2 ] Batch: 861 / 937 Main Model Loss: 0.0046702703 Interpreter Loss: 13067.075\n",
      "Epoch:[ 2 ] Batch: 862 / 937 Main Model Loss: 0.014117944 Interpreter Loss: 13306.5625\n",
      "Epoch:[ 2 ] Batch: 863 / 937 Main Model Loss: 0.015285497 Interpreter Loss: 13481.191\n",
      "Epoch:[ 2 ] Batch: 864 / 937 Main Model Loss: 0.051644474 Interpreter Loss: 13013.365\n",
      "Epoch:[ 2 ] Batch: 865 / 937 Main Model Loss: 0.01605399 Interpreter Loss: 13156.553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 2 ] Batch: 866 / 937 Main Model Loss: 0.006789717 Interpreter Loss: 12987.183\n",
      "Epoch:[ 2 ] Batch: 867 / 937 Main Model Loss: 0.010185938 Interpreter Loss: 14078.506\n",
      "Epoch:[ 2 ] Batch: 868 / 937 Main Model Loss: 0.029338952 Interpreter Loss: 13961.088\n",
      "Epoch:[ 2 ] Batch: 869 / 937 Main Model Loss: 0.020008512 Interpreter Loss: 14491.456\n",
      "Epoch:[ 2 ] Batch: 870 / 937 Main Model Loss: 0.06146182 Interpreter Loss: 14447.099\n",
      "Epoch:[ 2 ] Batch: 871 / 937 Main Model Loss: 0.01094939 Interpreter Loss: 14170.296\n",
      "Epoch:[ 2 ] Batch: 872 / 937 Main Model Loss: 0.034185216 Interpreter Loss: 13574.683\n",
      "Epoch:[ 2 ] Batch: 873 / 937 Main Model Loss: 0.012709948 Interpreter Loss: 13515.446\n",
      "Epoch:[ 2 ] Batch: 874 / 937 Main Model Loss: 0.0026642391 Interpreter Loss: 12923.298\n",
      "Epoch:[ 2 ] Batch: 875 / 937 Main Model Loss: 0.06096325 Interpreter Loss: 13213.437\n",
      "Epoch:[ 2 ] Batch: 876 / 937 Main Model Loss: 0.012095382 Interpreter Loss: 13149.531\n",
      "Epoch:[ 2 ] Batch: 877 / 937 Main Model Loss: 0.023937965 Interpreter Loss: 13606.947\n",
      "Epoch:[ 2 ] Batch: 878 / 937 Main Model Loss: 0.04052969 Interpreter Loss: 14237.64\n",
      "Epoch:[ 2 ] Batch: 879 / 937 Main Model Loss: 0.013399668 Interpreter Loss: 12951.736\n",
      "Epoch:[ 2 ] Batch: 880 / 937 Main Model Loss: 0.020755792 Interpreter Loss: 12518.708\n",
      "Epoch:[ 2 ] Batch: 881 / 937 Main Model Loss: 0.005018836 Interpreter Loss: 12404.204\n",
      "Epoch:[ 2 ] Batch: 882 / 937 Main Model Loss: 0.05060855 Interpreter Loss: 13725.751\n",
      "Epoch:[ 2 ] Batch: 883 / 937 Main Model Loss: 0.0032178345 Interpreter Loss: 12915.694\n",
      "Epoch:[ 2 ] Batch: 884 / 937 Main Model Loss: 0.016485455 Interpreter Loss: 12941.426\n",
      "Epoch:[ 2 ] Batch: 885 / 937 Main Model Loss: 0.004694624 Interpreter Loss: 12779.832\n",
      "Epoch:[ 2 ] Batch: 886 / 937 Main Model Loss: 0.00480576 Interpreter Loss: 13682.89\n",
      "Epoch:[ 2 ] Batch: 887 / 937 Main Model Loss: 0.050218474 Interpreter Loss: 13719.84\n",
      "Epoch:[ 2 ] Batch: 888 / 937 Main Model Loss: 0.007894631 Interpreter Loss: 13504.716\n",
      "Epoch:[ 2 ] Batch: 889 / 937 Main Model Loss: 0.005413682 Interpreter Loss: 12595.383\n",
      "Epoch:[ 2 ] Batch: 890 / 937 Main Model Loss: 0.0075792577 Interpreter Loss: 12398.552\n",
      "Epoch:[ 2 ] Batch: 891 / 937 Main Model Loss: 0.01594404 Interpreter Loss: 11937.806\n",
      "Epoch:[ 2 ] Batch: 892 / 937 Main Model Loss: 0.0005895922 Interpreter Loss: 11888.738\n",
      "Epoch:[ 2 ] Batch: 893 / 937 Main Model Loss: 0.0071964576 Interpreter Loss: 12835.626\n",
      "Epoch:[ 2 ] Batch: 894 / 937 Main Model Loss: 0.030948909 Interpreter Loss: 14142.977\n",
      "Epoch:[ 2 ] Batch: 895 / 937 Main Model Loss: 0.035328507 Interpreter Loss: 13805.557\n",
      "Epoch:[ 2 ] Batch: 896 / 937 Main Model Loss: 0.012479543 Interpreter Loss: 13114.003\n",
      "Epoch:[ 2 ] Batch: 897 / 937 Main Model Loss: 0.0049378425 Interpreter Loss: 13138.051\n",
      "Epoch:[ 2 ] Batch: 898 / 937 Main Model Loss: 0.014523641 Interpreter Loss: 13684.182\n",
      "Epoch:[ 2 ] Batch: 899 / 937 Main Model Loss: 0.010329791 Interpreter Loss: 13186.081\n",
      "Epoch:[ 2 ] Batch: 900 / 937 Main Model Loss: 0.019201217 Interpreter Loss: 13533.9\n",
      "Epoch:[ 2 ] Batch: 901 / 937 Main Model Loss: 0.005247128 Interpreter Loss: 12201.551\n",
      "Epoch:[ 2 ] Batch: 902 / 937 Main Model Loss: 0.048165552 Interpreter Loss: 12950.447\n",
      "Epoch:[ 2 ] Batch: 903 / 937 Main Model Loss: 0.013871185 Interpreter Loss: 12194.202\n",
      "Epoch:[ 2 ] Batch: 904 / 937 Main Model Loss: 0.023222737 Interpreter Loss: 12621.909\n",
      "Epoch:[ 2 ] Batch: 905 / 937 Main Model Loss: 0.0076174065 Interpreter Loss: 12976.217\n",
      "Epoch:[ 2 ] Batch: 906 / 937 Main Model Loss: 0.02370714 Interpreter Loss: 12996.2705\n",
      "Epoch:[ 2 ] Batch: 907 / 937 Main Model Loss: 0.03680506 Interpreter Loss: 13255.087\n",
      "Epoch:[ 2 ] Batch: 908 / 937 Main Model Loss: 0.0003272643 Interpreter Loss: 11614.654\n",
      "Epoch:[ 2 ] Batch: 909 / 937 Main Model Loss: 0.0009232362 Interpreter Loss: 12532.943\n",
      "Epoch:[ 2 ] Batch: 910 / 937 Main Model Loss: 0.0010364671 Interpreter Loss: 12922.267\n",
      "Epoch:[ 2 ] Batch: 911 / 937 Main Model Loss: 0.004624855 Interpreter Loss: 12998.395\n",
      "Epoch:[ 2 ] Batch: 912 / 937 Main Model Loss: 0.011293827 Interpreter Loss: 13734.78\n",
      "Epoch:[ 2 ] Batch: 913 / 937 Main Model Loss: 0.007532295 Interpreter Loss: 13546.755\n",
      "Epoch:[ 2 ] Batch: 914 / 937 Main Model Loss: 0.001530875 Interpreter Loss: 12005.527\n",
      "Epoch:[ 2 ] Batch: 915 / 937 Main Model Loss: 0.0015671451 Interpreter Loss: 11358.556\n",
      "Epoch:[ 2 ] Batch: 916 / 937 Main Model Loss: 0.007003202 Interpreter Loss: 11444.474\n",
      "Epoch:[ 2 ] Batch: 917 / 937 Main Model Loss: 0.00021872218 Interpreter Loss: 10962.357\n",
      "Epoch:[ 2 ] Batch: 918 / 937 Main Model Loss: 0.0076990128 Interpreter Loss: 12329.745\n",
      "Epoch:[ 2 ] Batch: 919 / 937 Main Model Loss: 0.007820748 Interpreter Loss: 13429.824\n",
      "Epoch:[ 2 ] Batch: 920 / 937 Main Model Loss: 0.0020995447 Interpreter Loss: 12677.754\n",
      "Epoch:[ 2 ] Batch: 921 / 937 Main Model Loss: 5.6629222e-05 Interpreter Loss: 12617.478\n",
      "Epoch:[ 2 ] Batch: 922 / 937 Main Model Loss: 0.00082562753 Interpreter Loss: 12249.733\n",
      "Epoch:[ 2 ] Batch: 923 / 937 Main Model Loss: 0.00021047865 Interpreter Loss: 12106.682\n",
      "Epoch:[ 2 ] Batch: 924 / 937 Main Model Loss: 0.00013573634 Interpreter Loss: 12486.451\n",
      "Epoch:[ 2 ] Batch: 925 / 937 Main Model Loss: 0.00085326005 Interpreter Loss: 12805.207\n",
      "Epoch:[ 2 ] Batch: 926 / 937 Main Model Loss: 0.007761234 Interpreter Loss: 13948.426\n",
      "Epoch:[ 2 ] Batch: 927 / 937 Main Model Loss: 0.0073319515 Interpreter Loss: 15753.559\n",
      "Epoch:[ 2 ] Batch: 928 / 937 Main Model Loss: 0.006428509 Interpreter Loss: 16840.703\n",
      "Epoch:[ 2 ] Batch: 929 / 937 Main Model Loss: 0.002092436 Interpreter Loss: 13777.409\n",
      "Epoch:[ 2 ] Batch: 930 / 937 Main Model Loss: 0.0007071993 Interpreter Loss: 11810.77\n",
      "Epoch:[ 2 ] Batch: 931 / 937 Main Model Loss: 0.0008880147 Interpreter Loss: 12470.075\n",
      "Epoch:[ 2 ] Batch: 932 / 937 Main Model Loss: 0.06343251 Interpreter Loss: 13400.783\n",
      "Epoch:[ 2 ] Batch: 933 / 937 Main Model Loss: 0.08550719 Interpreter Loss: 14489.0205\n",
      "Epoch:[ 2 ] Batch: 934 / 937 Main Model Loss: 0.002768964 Interpreter Loss: 13367.096\n",
      "Epoch:[ 2 ] Batch: 935 / 937 Main Model Loss: 0.0018127407 Interpreter Loss: 13470.078\n",
      "Epoch:[ 2 ] Batch: 936 / 937 Main Model Loss: 0.22719957 Interpreter Loss: 12156.689\n",
      " Main Model Acc:  0.984375 Interpreter Acc:  0.5\n",
      "INFO:tensorflow:Assets written to: checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 3 ] Batch: 0 / 937 Main Model Loss: 0.008103634 Interpreter Loss: 13173.951\n",
      "Epoch:[ 3 ] Batch: 1 / 937 Main Model Loss: 0.0143590495 Interpreter Loss: 13868.524\n",
      "Epoch:[ 3 ] Batch: 2 / 937 Main Model Loss: 0.08984823 Interpreter Loss: 13129.603\n",
      "Epoch:[ 3 ] Batch: 3 / 937 Main Model Loss: 0.02515901 Interpreter Loss: 13236.854\n",
      "Epoch:[ 3 ] Batch: 4 / 937 Main Model Loss: 0.008524597 Interpreter Loss: 12492.154\n",
      "Epoch:[ 3 ] Batch: 5 / 937 Main Model Loss: 0.0072877244 Interpreter Loss: 12671.847\n",
      "Epoch:[ 3 ] Batch: 6 / 937 Main Model Loss: 0.045522057 Interpreter Loss: 12941.766\n",
      "Epoch:[ 3 ] Batch: 7 / 937 Main Model Loss: 0.07460966 Interpreter Loss: 13066.152\n",
      "Epoch:[ 3 ] Batch: 8 / 937 Main Model Loss: 0.004365629 Interpreter Loss: 12689.819\n",
      "Epoch:[ 3 ] Batch: 9 / 937 Main Model Loss: 0.011697171 Interpreter Loss: 13347.322\n",
      "Epoch:[ 3 ] Batch: 10 / 937 Main Model Loss: 0.0031603163 Interpreter Loss: 12884.592\n",
      "Epoch:[ 3 ] Batch: 11 / 937 Main Model Loss: 0.030782538 Interpreter Loss: 14007.502\n",
      "Epoch:[ 3 ] Batch: 12 / 937 Main Model Loss: 0.007829798 Interpreter Loss: 13255.076\n",
      "Epoch:[ 3 ] Batch: 13 / 937 Main Model Loss: 0.023759682 Interpreter Loss: 14071.475\n",
      "Epoch:[ 3 ] Batch: 14 / 937 Main Model Loss: 0.025171556 Interpreter Loss: 13929.278\n",
      "Epoch:[ 3 ] Batch: 15 / 937 Main Model Loss: 0.009964554 Interpreter Loss: 14108.935\n",
      "Epoch:[ 3 ] Batch: 16 / 937 Main Model Loss: 0.014074608 Interpreter Loss: 13406.932\n",
      "Epoch:[ 3 ] Batch: 17 / 937 Main Model Loss: 0.037532825 Interpreter Loss: 13560.972\n",
      "Epoch:[ 3 ] Batch: 18 / 937 Main Model Loss: 0.02138309 Interpreter Loss: 13674.297\n",
      "Epoch:[ 3 ] Batch: 19 / 937 Main Model Loss: 0.009825704 Interpreter Loss: 14899.549\n",
      "Epoch:[ 3 ] Batch: 20 / 937 Main Model Loss: 0.0097235385 Interpreter Loss: 14365.901\n",
      "Epoch:[ 3 ] Batch: 21 / 937 Main Model Loss: 0.06494027 Interpreter Loss: 15823.075\n",
      "Epoch:[ 3 ] Batch: 22 / 937 Main Model Loss: 0.002904624 Interpreter Loss: 12543.998\n",
      "Epoch:[ 3 ] Batch: 23 / 937 Main Model Loss: 0.01578867 Interpreter Loss: 13096.786\n",
      "Epoch:[ 3 ] Batch: 24 / 937 Main Model Loss: 0.012627026 Interpreter Loss: 12784.41\n",
      "Epoch:[ 3 ] Batch: 25 / 937 Main Model Loss: 0.047669172 Interpreter Loss: 12744.469\n",
      "Epoch:[ 3 ] Batch: 26 / 937 Main Model Loss: 0.005274378 Interpreter Loss: 12420.605\n",
      "Epoch:[ 3 ] Batch: 27 / 937 Main Model Loss: 0.029813861 Interpreter Loss: 12996.405\n",
      "Epoch:[ 3 ] Batch: 28 / 937 Main Model Loss: 0.0069227535 Interpreter Loss: 12483.414\n",
      "Epoch:[ 3 ] Batch: 29 / 937 Main Model Loss: 0.024524294 Interpreter Loss: 13893.1045\n",
      "Epoch:[ 3 ] Batch: 30 / 937 Main Model Loss: 0.04460803 Interpreter Loss: 14420.45\n",
      "Epoch:[ 3 ] Batch: 31 / 937 Main Model Loss: 0.035280928 Interpreter Loss: 14566.573\n",
      "Epoch:[ 3 ] Batch: 32 / 937 Main Model Loss: 0.0024962774 Interpreter Loss: 13186.608\n",
      "Epoch:[ 3 ] Batch: 33 / 937 Main Model Loss: 0.0020839577 Interpreter Loss: 12876.169\n",
      "Epoch:[ 3 ] Batch: 34 / 937 Main Model Loss: 0.0068823397 Interpreter Loss: 12903.705\n",
      "Epoch:[ 3 ] Batch: 35 / 937 Main Model Loss: 0.005887754 Interpreter Loss: 13295.167\n",
      "Epoch:[ 3 ] Batch: 36 / 937 Main Model Loss: 0.011472138 Interpreter Loss: 12781.221\n",
      "Epoch:[ 3 ] Batch: 37 / 937 Main Model Loss: 0.017835319 Interpreter Loss: 13540.562\n",
      "Epoch:[ 3 ] Batch: 38 / 937 Main Model Loss: 0.006083389 Interpreter Loss: 12980.794\n",
      "Epoch:[ 3 ] Batch: 39 / 937 Main Model Loss: 0.016906824 Interpreter Loss: 13411.051\n",
      "Epoch:[ 3 ] Batch: 40 / 937 Main Model Loss: 0.021241337 Interpreter Loss: 13653.918\n",
      "Epoch:[ 3 ] Batch: 41 / 937 Main Model Loss: 0.0636797 Interpreter Loss: 13341.891\n",
      "Epoch:[ 3 ] Batch: 42 / 937 Main Model Loss: 0.05090587 Interpreter Loss: 12820.431\n",
      "Epoch:[ 3 ] Batch: 43 / 937 Main Model Loss: 0.018973675 Interpreter Loss: 13488.776\n",
      "Epoch:[ 3 ] Batch: 44 / 937 Main Model Loss: 0.00417097 Interpreter Loss: 13550.711\n",
      "Epoch:[ 3 ] Batch: 45 / 937 Main Model Loss: 0.021118758 Interpreter Loss: 13202.716\n",
      "Epoch:[ 3 ] Batch: 46 / 937 Main Model Loss: 0.004514531 Interpreter Loss: 12092.643\n",
      "Epoch:[ 3 ] Batch: 47 / 937 Main Model Loss: 0.00943025 Interpreter Loss: 13018.228\n",
      "Epoch:[ 3 ] Batch: 48 / 937 Main Model Loss: 0.0051962934 Interpreter Loss: 12198.352\n",
      "Epoch:[ 3 ] Batch: 49 / 937 Main Model Loss: 0.00082425727 Interpreter Loss: 12074.515\n",
      "Epoch:[ 3 ] Batch: 50 / 937 Main Model Loss: 0.029380793 Interpreter Loss: 12508.993\n",
      "Epoch:[ 3 ] Batch: 51 / 937 Main Model Loss: 0.011251591 Interpreter Loss: 12628.417\n",
      "Epoch:[ 3 ] Batch: 52 / 937 Main Model Loss: 0.00808526 Interpreter Loss: 12881.318\n",
      "Epoch:[ 3 ] Batch: 53 / 937 Main Model Loss: 0.0072301268 Interpreter Loss: 12347.426\n",
      "Epoch:[ 3 ] Batch: 54 / 937 Main Model Loss: 0.010252729 Interpreter Loss: 12918.673\n",
      "Epoch:[ 3 ] Batch: 55 / 937 Main Model Loss: 0.01340215 Interpreter Loss: 12994.094\n",
      "Epoch:[ 3 ] Batch: 56 / 937 Main Model Loss: 0.032228317 Interpreter Loss: 13684.266\n",
      "Epoch:[ 3 ] Batch: 57 / 937 Main Model Loss: 0.04761217 Interpreter Loss: 14218.981\n",
      "Epoch:[ 3 ] Batch: 58 / 937 Main Model Loss: 0.02624608 Interpreter Loss: 13482.683\n",
      "Epoch:[ 3 ] Batch: 59 / 937 Main Model Loss: 0.019414201 Interpreter Loss: 13232.613\n",
      "Epoch:[ 3 ] Batch: 60 / 937 Main Model Loss: 0.0036003934 Interpreter Loss: 12694.932\n",
      "Epoch:[ 3 ] Batch: 61 / 937 Main Model Loss: 0.019336352 Interpreter Loss: 12871.865\n",
      "Epoch:[ 3 ] Batch: 62 / 937 Main Model Loss: 0.028208107 Interpreter Loss: 12900.427\n",
      "Epoch:[ 3 ] Batch: 63 / 937 Main Model Loss: 0.007357841 Interpreter Loss: 13382.269\n",
      "Epoch:[ 3 ] Batch: 64 / 937 Main Model Loss: 0.024231456 Interpreter Loss: 13423.341\n",
      "Epoch:[ 3 ] Batch: 65 / 937 Main Model Loss: 0.006686273 Interpreter Loss: 12601.118\n",
      "Epoch:[ 3 ] Batch: 66 / 937 Main Model Loss: 0.006343661 Interpreter Loss: 13240.877\n",
      "Epoch:[ 3 ] Batch: 67 / 937 Main Model Loss: 0.021431772 Interpreter Loss: 12802.656\n",
      "Epoch:[ 3 ] Batch: 68 / 937 Main Model Loss: 0.007850377 Interpreter Loss: 12375.714\n",
      "Epoch:[ 3 ] Batch: 69 / 937 Main Model Loss: 0.10838231 Interpreter Loss: 12776.91\n",
      "Epoch:[ 3 ] Batch: 70 / 937 Main Model Loss: 0.0041769748 Interpreter Loss: 13527.439\n",
      "Epoch:[ 3 ] Batch: 71 / 937 Main Model Loss: 0.0050888634 Interpreter Loss: 12978.167\n",
      "Epoch:[ 3 ] Batch: 72 / 937 Main Model Loss: 0.014207629 Interpreter Loss: 14412.791\n",
      "Epoch:[ 3 ] Batch: 73 / 937 Main Model Loss: 0.0034358732 Interpreter Loss: 14025.559\n",
      "Epoch:[ 3 ] Batch: 74 / 937 Main Model Loss: 0.0060992176 Interpreter Loss: 13090.134\n",
      "Epoch:[ 3 ] Batch: 75 / 937 Main Model Loss: 0.0075461087 Interpreter Loss: 13458.18\n",
      "Epoch:[ 3 ] Batch: 76 / 937 Main Model Loss: 0.0013651882 Interpreter Loss: 12962.186\n",
      "Epoch:[ 3 ] Batch: 77 / 937 Main Model Loss: 0.012345431 Interpreter Loss: 13474.038\n",
      "Epoch:[ 3 ] Batch: 78 / 937 Main Model Loss: 0.009944093 Interpreter Loss: 13504.667\n",
      "Epoch:[ 3 ] Batch: 79 / 937 Main Model Loss: 0.044488907 Interpreter Loss: 14359.705\n",
      "Epoch:[ 3 ] Batch: 80 / 937 Main Model Loss: 0.01485035 Interpreter Loss: 13758.106\n",
      "Epoch:[ 3 ] Batch: 81 / 937 Main Model Loss: 0.0023909046 Interpreter Loss: 13116.674\n",
      "Epoch:[ 3 ] Batch: 82 / 937 Main Model Loss: 0.008527028 Interpreter Loss: 13860.437\n",
      "Epoch:[ 3 ] Batch: 83 / 937 Main Model Loss: 0.011434923 Interpreter Loss: 14288.651\n",
      "Epoch:[ 3 ] Batch: 84 / 937 Main Model Loss: 0.0080391755 Interpreter Loss: 13767.249\n",
      "Epoch:[ 3 ] Batch: 85 / 937 Main Model Loss: 0.0102682365 Interpreter Loss: 13787.157\n",
      "Epoch:[ 3 ] Batch: 86 / 937 Main Model Loss: 0.017168226 Interpreter Loss: 13736.39\n",
      "Epoch:[ 3 ] Batch: 87 / 937 Main Model Loss: 0.0032089134 Interpreter Loss: 13123.672\n",
      "Epoch:[ 3 ] Batch: 88 / 937 Main Model Loss: 0.017728966 Interpreter Loss: 13593.634\n",
      "Epoch:[ 3 ] Batch: 89 / 937 Main Model Loss: 0.008233919 Interpreter Loss: 14009.811\n",
      "Epoch:[ 3 ] Batch: 90 / 937 Main Model Loss: 0.0051341224 Interpreter Loss: 12853.754\n",
      "Epoch:[ 3 ] Batch: 91 / 937 Main Model Loss: 0.020241372 Interpreter Loss: 13160.233\n",
      "Epoch:[ 3 ] Batch: 92 / 937 Main Model Loss: 0.014496567 Interpreter Loss: 13211.84\n",
      "Epoch:[ 3 ] Batch: 93 / 937 Main Model Loss: 0.0030352538 Interpreter Loss: 14297.101\n",
      "Epoch:[ 3 ] Batch: 94 / 937 Main Model Loss: 0.014499569 Interpreter Loss: 14483.033\n",
      "Epoch:[ 3 ] Batch: 95 / 937 Main Model Loss: 0.01837175 Interpreter Loss: 14701.934\n",
      "Epoch:[ 3 ] Batch: 96 / 937 Main Model Loss: 0.012062246 Interpreter Loss: 13958.5625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 3 ] Batch: 97 / 937 Main Model Loss: 0.018396191 Interpreter Loss: 14008.087\n",
      "Epoch:[ 3 ] Batch: 98 / 937 Main Model Loss: 0.004490343 Interpreter Loss: 13491.059\n",
      "Epoch:[ 3 ] Batch: 99 / 937 Main Model Loss: 0.017972136 Interpreter Loss: 13582.989\n",
      "Epoch:[ 3 ] Batch: 100 / 937 Main Model Loss: 0.016734816 Interpreter Loss: 13944.025\n",
      "Epoch:[ 3 ] Batch: 101 / 937 Main Model Loss: 0.00751598 Interpreter Loss: 13336.704\n",
      "Epoch:[ 3 ] Batch: 102 / 937 Main Model Loss: 0.0037762315 Interpreter Loss: 12211.5625\n",
      "Epoch:[ 3 ] Batch: 103 / 937 Main Model Loss: 0.00575864 Interpreter Loss: 13100.193\n",
      "Epoch:[ 3 ] Batch: 104 / 937 Main Model Loss: 0.0062949173 Interpreter Loss: 11912.429\n",
      "Epoch:[ 3 ] Batch: 105 / 937 Main Model Loss: 0.003974898 Interpreter Loss: 11749.568\n",
      "Epoch:[ 3 ] Batch: 106 / 937 Main Model Loss: 0.029330587 Interpreter Loss: 12249.322\n",
      "Epoch:[ 3 ] Batch: 107 / 937 Main Model Loss: 0.027188512 Interpreter Loss: 13946.496\n",
      "Epoch:[ 3 ] Batch: 108 / 937 Main Model Loss: 0.0072616716 Interpreter Loss: 14109.1455\n",
      "Epoch:[ 3 ] Batch: 109 / 937 Main Model Loss: 0.031188913 Interpreter Loss: 13315.839\n",
      "Epoch:[ 3 ] Batch: 110 / 937 Main Model Loss: 0.023158818 Interpreter Loss: 12296.916\n",
      "Epoch:[ 3 ] Batch: 111 / 937 Main Model Loss: 0.0023750644 Interpreter Loss: 12289.4375\n",
      "Epoch:[ 3 ] Batch: 112 / 937 Main Model Loss: 0.008745877 Interpreter Loss: 12077.193\n",
      "Epoch:[ 3 ] Batch: 113 / 937 Main Model Loss: 0.08132093 Interpreter Loss: 13228.077\n",
      "Epoch:[ 3 ] Batch: 114 / 937 Main Model Loss: 0.019784119 Interpreter Loss: 11591.782\n",
      "Epoch:[ 3 ] Batch: 115 / 937 Main Model Loss: 0.010300535 Interpreter Loss: 11719.213\n",
      "Epoch:[ 3 ] Batch: 116 / 937 Main Model Loss: 0.0071012746 Interpreter Loss: 12170.721\n",
      "Epoch:[ 3 ] Batch: 117 / 937 Main Model Loss: 0.0055451784 Interpreter Loss: 12172.09\n",
      "Epoch:[ 3 ] Batch: 118 / 937 Main Model Loss: 0.017866218 Interpreter Loss: 12436.69\n",
      "Epoch:[ 3 ] Batch: 119 / 937 Main Model Loss: 0.0117996 Interpreter Loss: 12987.352\n",
      "Epoch:[ 3 ] Batch: 120 / 937 Main Model Loss: 0.012150053 Interpreter Loss: 12794.107\n",
      "Epoch:[ 3 ] Batch: 121 / 937 Main Model Loss: 0.040223204 Interpreter Loss: 13557.039\n",
      "Epoch:[ 3 ] Batch: 122 / 937 Main Model Loss: 0.01729189 Interpreter Loss: 13254.404\n",
      "Epoch:[ 3 ] Batch: 123 / 937 Main Model Loss: 0.009262048 Interpreter Loss: 13922.982\n",
      "Epoch:[ 3 ] Batch: 124 / 937 Main Model Loss: 0.02423166 Interpreter Loss: 13587.501\n",
      "Epoch:[ 3 ] Batch: 125 / 937 Main Model Loss: 0.013979916 Interpreter Loss: 13557.422\n",
      "Epoch:[ 3 ] Batch: 126 / 937 Main Model Loss: 0.011059472 Interpreter Loss: 14392.312\n",
      "Epoch:[ 3 ] Batch: 127 / 937 Main Model Loss: 0.0054687676 Interpreter Loss: 11984.8\n",
      "Epoch:[ 3 ] Batch: 128 / 937 Main Model Loss: 0.08374057 Interpreter Loss: 13192.359\n",
      "Epoch:[ 3 ] Batch: 129 / 937 Main Model Loss: 0.0123719685 Interpreter Loss: 13890.054\n",
      "Epoch:[ 3 ] Batch: 130 / 937 Main Model Loss: 0.010903352 Interpreter Loss: 13062.039\n",
      "Epoch:[ 3 ] Batch: 131 / 937 Main Model Loss: 0.006444609 Interpreter Loss: 13007.5625\n",
      "Epoch:[ 3 ] Batch: 132 / 937 Main Model Loss: 0.031739946 Interpreter Loss: 14887.505\n",
      "Epoch:[ 3 ] Batch: 133 / 937 Main Model Loss: 0.0050947806 Interpreter Loss: 13950.416\n",
      "Epoch:[ 3 ] Batch: 134 / 937 Main Model Loss: 0.0018100124 Interpreter Loss: 13900.995\n",
      "Epoch:[ 3 ] Batch: 135 / 937 Main Model Loss: 0.020601105 Interpreter Loss: 15259.854\n",
      "Epoch:[ 3 ] Batch: 136 / 937 Main Model Loss: 0.027341623 Interpreter Loss: 14694.633\n",
      "Epoch:[ 3 ] Batch: 137 / 937 Main Model Loss: 0.004648337 Interpreter Loss: 13387.254\n",
      "Epoch:[ 3 ] Batch: 138 / 937 Main Model Loss: 0.029539946 Interpreter Loss: 14564.651\n",
      "Epoch:[ 3 ] Batch: 139 / 937 Main Model Loss: 0.004656341 Interpreter Loss: 13083.732\n",
      "Epoch:[ 3 ] Batch: 140 / 937 Main Model Loss: 0.008548428 Interpreter Loss: 12908.315\n",
      "Epoch:[ 3 ] Batch: 141 / 937 Main Model Loss: 0.011743705 Interpreter Loss: 12740.399\n",
      "Epoch:[ 3 ] Batch: 142 / 937 Main Model Loss: 0.038495652 Interpreter Loss: 12208.556\n",
      "Epoch:[ 3 ] Batch: 143 / 937 Main Model Loss: 0.004997841 Interpreter Loss: 12663.359\n",
      "Epoch:[ 3 ] Batch: 144 / 937 Main Model Loss: 0.015070878 Interpreter Loss: 12379.285\n",
      "Epoch:[ 3 ] Batch: 145 / 937 Main Model Loss: 0.005443318 Interpreter Loss: 13064.254\n",
      "Epoch:[ 3 ] Batch: 146 / 937 Main Model Loss: 0.017104832 Interpreter Loss: 13846.449\n",
      "Epoch:[ 3 ] Batch: 147 / 937 Main Model Loss: 0.03196858 Interpreter Loss: 14043.078\n",
      "Epoch:[ 3 ] Batch: 148 / 937 Main Model Loss: 0.0040995535 Interpreter Loss: 13586.519\n",
      "Epoch:[ 3 ] Batch: 149 / 937 Main Model Loss: 0.007515868 Interpreter Loss: 12575.254\n",
      "Epoch:[ 3 ] Batch: 150 / 937 Main Model Loss: 0.010903249 Interpreter Loss: 13142.608\n",
      "Epoch:[ 3 ] Batch: 151 / 937 Main Model Loss: 0.0029719379 Interpreter Loss: 13214.925\n",
      "Epoch:[ 3 ] Batch: 152 / 937 Main Model Loss: 0.026727151 Interpreter Loss: 13453.49\n",
      "Epoch:[ 3 ] Batch: 153 / 937 Main Model Loss: 0.0011184191 Interpreter Loss: 12351.912\n",
      "Epoch:[ 3 ] Batch: 154 / 937 Main Model Loss: 0.00047422224 Interpreter Loss: 12549.484\n",
      "Epoch:[ 3 ] Batch: 155 / 937 Main Model Loss: 0.0024400954 Interpreter Loss: 12568.3545\n",
      "Epoch:[ 3 ] Batch: 156 / 937 Main Model Loss: 0.008415321 Interpreter Loss: 13638.236\n",
      "Epoch:[ 3 ] Batch: 157 / 937 Main Model Loss: 0.02219169 Interpreter Loss: 12681.354\n",
      "Epoch:[ 3 ] Batch: 158 / 937 Main Model Loss: 0.008761282 Interpreter Loss: 12224.203\n",
      "Epoch:[ 3 ] Batch: 159 / 937 Main Model Loss: 0.020923797 Interpreter Loss: 15957.817\n",
      "Epoch:[ 3 ] Batch: 160 / 937 Main Model Loss: 0.048436757 Interpreter Loss: 16714.27\n",
      "Epoch:[ 3 ] Batch: 161 / 937 Main Model Loss: 0.006740633 Interpreter Loss: 13778.693\n",
      "Epoch:[ 3 ] Batch: 162 / 937 Main Model Loss: 0.0045414777 Interpreter Loss: 13592.416\n",
      "Epoch:[ 3 ] Batch: 163 / 937 Main Model Loss: 0.0016039837 Interpreter Loss: 13558.006\n",
      "Epoch:[ 3 ] Batch: 164 / 937 Main Model Loss: 0.0020876732 Interpreter Loss: 13062.591\n",
      "Epoch:[ 3 ] Batch: 165 / 937 Main Model Loss: 0.004042717 Interpreter Loss: 12670.234\n",
      "Epoch:[ 3 ] Batch: 166 / 937 Main Model Loss: 0.0013291477 Interpreter Loss: 12178.719\n",
      "Epoch:[ 3 ] Batch: 167 / 937 Main Model Loss: 0.0072690826 Interpreter Loss: 12720.405\n",
      "Epoch:[ 3 ] Batch: 168 / 937 Main Model Loss: 0.037038896 Interpreter Loss: 14260.146\n",
      "Epoch:[ 3 ] Batch: 169 / 937 Main Model Loss: 0.0062541375 Interpreter Loss: 13488.249\n",
      "Epoch:[ 3 ] Batch: 170 / 937 Main Model Loss: 0.0041694227 Interpreter Loss: 13031.828\n",
      "Epoch:[ 3 ] Batch: 171 / 937 Main Model Loss: 0.09249137 Interpreter Loss: 13745.345\n",
      "Epoch:[ 3 ] Batch: 172 / 937 Main Model Loss: 0.0034889723 Interpreter Loss: 14171.695\n",
      "Epoch:[ 3 ] Batch: 173 / 937 Main Model Loss: 0.010228024 Interpreter Loss: 12856.632\n",
      "Epoch:[ 3 ] Batch: 174 / 937 Main Model Loss: 0.0035741716 Interpreter Loss: 13106.086\n",
      "Epoch:[ 3 ] Batch: 175 / 937 Main Model Loss: 0.017788693 Interpreter Loss: 13447.717\n",
      "Epoch:[ 3 ] Batch: 176 / 937 Main Model Loss: 0.0024570662 Interpreter Loss: 12360.482\n",
      "Epoch:[ 3 ] Batch: 177 / 937 Main Model Loss: 0.021836236 Interpreter Loss: 13000.506\n",
      "Epoch:[ 3 ] Batch: 178 / 937 Main Model Loss: 0.0065004993 Interpreter Loss: 12910.984\n",
      "Epoch:[ 3 ] Batch: 179 / 937 Main Model Loss: 0.0061096647 Interpreter Loss: 12644.949\n",
      "Epoch:[ 3 ] Batch: 180 / 937 Main Model Loss: 0.016040431 Interpreter Loss: 13198.27\n",
      "Epoch:[ 3 ] Batch: 181 / 937 Main Model Loss: 0.018403929 Interpreter Loss: 13448.643\n",
      "Epoch:[ 3 ] Batch: 182 / 937 Main Model Loss: 0.03165372 Interpreter Loss: 13509.202\n",
      "Epoch:[ 3 ] Batch: 183 / 937 Main Model Loss: 0.010271561 Interpreter Loss: 13493.886\n",
      "Epoch:[ 3 ] Batch: 184 / 937 Main Model Loss: 0.018919216 Interpreter Loss: 13178.953\n",
      "Epoch:[ 3 ] Batch: 185 / 937 Main Model Loss: 0.0056800907 Interpreter Loss: 13357.32\n",
      "Epoch:[ 3 ] Batch: 186 / 937 Main Model Loss: 0.010663575 Interpreter Loss: 12776.874\n",
      "Epoch:[ 3 ] Batch: 187 / 937 Main Model Loss: 0.00723998 Interpreter Loss: 13807.646\n",
      "Epoch:[ 3 ] Batch: 188 / 937 Main Model Loss: 0.004090303 Interpreter Loss: 13309.548\n",
      "Epoch:[ 3 ] Batch: 189 / 937 Main Model Loss: 0.011717736 Interpreter Loss: 13120.353\n",
      "Epoch:[ 3 ] Batch: 190 / 937 Main Model Loss: 0.0056860717 Interpreter Loss: 13586.5205\n",
      "Epoch:[ 3 ] Batch: 191 / 937 Main Model Loss: 0.0057151914 Interpreter Loss: 13653.232\n",
      "Epoch:[ 3 ] Batch: 192 / 937 Main Model Loss: 0.010308407 Interpreter Loss: 13592.083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 3 ] Batch: 193 / 937 Main Model Loss: 0.007831421 Interpreter Loss: 13549.414\n",
      "Epoch:[ 3 ] Batch: 194 / 937 Main Model Loss: 0.0045401133 Interpreter Loss: 13513.967\n",
      "Epoch:[ 3 ] Batch: 195 / 937 Main Model Loss: 0.0074631954 Interpreter Loss: 13182.877\n",
      "Epoch:[ 3 ] Batch: 196 / 937 Main Model Loss: 0.006016607 Interpreter Loss: 14390.971\n",
      "Epoch:[ 3 ] Batch: 197 / 937 Main Model Loss: 0.012210447 Interpreter Loss: 13985.806\n",
      "Epoch:[ 3 ] Batch: 198 / 937 Main Model Loss: 0.010458564 Interpreter Loss: 13648.295\n",
      "Epoch:[ 3 ] Batch: 199 / 937 Main Model Loss: 0.043631688 Interpreter Loss: 12456.917\n",
      "Epoch:[ 3 ] Batch: 200 / 937 Main Model Loss: 0.0140676005 Interpreter Loss: 12515.659\n",
      "Epoch:[ 3 ] Batch: 201 / 937 Main Model Loss: 0.014448089 Interpreter Loss: 13281.303\n",
      "Epoch:[ 3 ] Batch: 202 / 937 Main Model Loss: 0.006583199 Interpreter Loss: 14754.697\n",
      "Epoch:[ 3 ] Batch: 203 / 937 Main Model Loss: 0.025427887 Interpreter Loss: 15032.016\n",
      "Epoch:[ 3 ] Batch: 204 / 937 Main Model Loss: 0.038780756 Interpreter Loss: 15468.684\n",
      "Epoch:[ 3 ] Batch: 205 / 937 Main Model Loss: 0.006494882 Interpreter Loss: 13568.082\n",
      "Epoch:[ 3 ] Batch: 206 / 937 Main Model Loss: 0.010806138 Interpreter Loss: 13809.335\n",
      "Epoch:[ 3 ] Batch: 207 / 937 Main Model Loss: 0.00780754 Interpreter Loss: 13222.981\n",
      "Epoch:[ 3 ] Batch: 208 / 937 Main Model Loss: 0.0043806937 Interpreter Loss: 13214.727\n",
      "Epoch:[ 3 ] Batch: 209 / 937 Main Model Loss: 0.03069755 Interpreter Loss: 13319.0205\n",
      "Epoch:[ 3 ] Batch: 210 / 937 Main Model Loss: 0.0038356418 Interpreter Loss: 13394.652\n",
      "Epoch:[ 3 ] Batch: 211 / 937 Main Model Loss: 0.02477798 Interpreter Loss: 14108.771\n",
      "Epoch:[ 3 ] Batch: 212 / 937 Main Model Loss: 0.0015730582 Interpreter Loss: 13149.717\n",
      "Epoch:[ 3 ] Batch: 213 / 937 Main Model Loss: 0.014515083 Interpreter Loss: 12455.338\n",
      "Epoch:[ 3 ] Batch: 214 / 937 Main Model Loss: 0.0038665803 Interpreter Loss: 11841.092\n",
      "Epoch:[ 3 ] Batch: 215 / 937 Main Model Loss: 0.0025773286 Interpreter Loss: 12404.302\n",
      "Epoch:[ 3 ] Batch: 216 / 937 Main Model Loss: 0.028254814 Interpreter Loss: 13340.32\n",
      "Epoch:[ 3 ] Batch: 217 / 937 Main Model Loss: 0.009227686 Interpreter Loss: 12920.797\n",
      "Epoch:[ 3 ] Batch: 218 / 937 Main Model Loss: 0.03517527 Interpreter Loss: 12958.5\n",
      "Epoch:[ 3 ] Batch: 219 / 937 Main Model Loss: 0.019974759 Interpreter Loss: 13839.109\n",
      "Epoch:[ 3 ] Batch: 220 / 937 Main Model Loss: 0.0027044115 Interpreter Loss: 13852.426\n",
      "Epoch:[ 3 ] Batch: 221 / 937 Main Model Loss: 0.009861325 Interpreter Loss: 14139.657\n",
      "Epoch:[ 3 ] Batch: 222 / 937 Main Model Loss: 0.0023118036 Interpreter Loss: 13792.96\n",
      "Epoch:[ 3 ] Batch: 223 / 937 Main Model Loss: 0.0033390706 Interpreter Loss: 13864.002\n",
      "Epoch:[ 3 ] Batch: 224 / 937 Main Model Loss: 0.030096447 Interpreter Loss: 14201.78\n",
      "Epoch:[ 3 ] Batch: 225 / 937 Main Model Loss: 0.01473136 Interpreter Loss: 12588.103\n",
      "Epoch:[ 3 ] Batch: 226 / 937 Main Model Loss: 0.010572455 Interpreter Loss: 12769.043\n",
      "Epoch:[ 3 ] Batch: 227 / 937 Main Model Loss: 0.014018419 Interpreter Loss: 12771.628\n",
      "Epoch:[ 3 ] Batch: 228 / 937 Main Model Loss: 0.002787753 Interpreter Loss: 13065.433\n",
      "Epoch:[ 3 ] Batch: 229 / 937 Main Model Loss: 0.02595303 Interpreter Loss: 13606.906\n",
      "Epoch:[ 3 ] Batch: 230 / 937 Main Model Loss: 0.010511109 Interpreter Loss: 13411.213\n",
      "Epoch:[ 3 ] Batch: 231 / 937 Main Model Loss: 0.004702324 Interpreter Loss: 13489.512\n",
      "Epoch:[ 3 ] Batch: 232 / 937 Main Model Loss: 0.0022109344 Interpreter Loss: 12865.824\n",
      "Epoch:[ 3 ] Batch: 233 / 937 Main Model Loss: 0.0060940417 Interpreter Loss: 12502.753\n",
      "Epoch:[ 3 ] Batch: 234 / 937 Main Model Loss: 0.00047318017 Interpreter Loss: 11774.333\n",
      "Epoch:[ 3 ] Batch: 235 / 937 Main Model Loss: 0.0070156576 Interpreter Loss: 12887.486\n",
      "Epoch:[ 3 ] Batch: 236 / 937 Main Model Loss: 0.012366396 Interpreter Loss: 13026.325\n",
      "Epoch:[ 3 ] Batch: 237 / 937 Main Model Loss: 0.010434639 Interpreter Loss: 12173.873\n",
      "Epoch:[ 3 ] Batch: 238 / 937 Main Model Loss: 0.0046160975 Interpreter Loss: 12608.571\n",
      "Epoch:[ 3 ] Batch: 239 / 937 Main Model Loss: 0.010901198 Interpreter Loss: 12246.749\n",
      "Epoch:[ 3 ] Batch: 240 / 937 Main Model Loss: 0.004451213 Interpreter Loss: 12110.195\n",
      "Epoch:[ 3 ] Batch: 241 / 937 Main Model Loss: 0.021907529 Interpreter Loss: 12186.589\n",
      "Epoch:[ 3 ] Batch: 242 / 937 Main Model Loss: 0.00424274 Interpreter Loss: 12652.135\n",
      "Epoch:[ 3 ] Batch: 243 / 937 Main Model Loss: 0.010199743 Interpreter Loss: 12678.456\n",
      "Epoch:[ 3 ] Batch: 244 / 937 Main Model Loss: 0.006685226 Interpreter Loss: 12685.544\n",
      "Epoch:[ 3 ] Batch: 245 / 937 Main Model Loss: 0.0057298597 Interpreter Loss: 12586.977\n",
      "Epoch:[ 3 ] Batch: 246 / 937 Main Model Loss: 0.020630386 Interpreter Loss: 14188.471\n",
      "Epoch:[ 3 ] Batch: 247 / 937 Main Model Loss: 0.007593366 Interpreter Loss: 12806.001\n",
      "Epoch:[ 3 ] Batch: 248 / 937 Main Model Loss: 0.010435362 Interpreter Loss: 13142.379\n",
      "Epoch:[ 3 ] Batch: 249 / 937 Main Model Loss: 0.008216091 Interpreter Loss: 13428.631\n",
      "Epoch:[ 3 ] Batch: 250 / 937 Main Model Loss: 0.0068198116 Interpreter Loss: 13626.099\n",
      "Epoch:[ 3 ] Batch: 251 / 937 Main Model Loss: 0.0036662538 Interpreter Loss: 13384.4\n",
      "Epoch:[ 3 ] Batch: 252 / 937 Main Model Loss: 0.020516455 Interpreter Loss: 13262.994\n",
      "Epoch:[ 3 ] Batch: 253 / 937 Main Model Loss: 0.0029779 Interpreter Loss: 13255.115\n",
      "Epoch:[ 3 ] Batch: 254 / 937 Main Model Loss: 0.0019431106 Interpreter Loss: 12710.881\n",
      "Epoch:[ 3 ] Batch: 255 / 937 Main Model Loss: 0.0116093 Interpreter Loss: 12908.048\n",
      "Epoch:[ 3 ] Batch: 256 / 937 Main Model Loss: 0.007285956 Interpreter Loss: 12516.99\n",
      "Epoch:[ 3 ] Batch: 257 / 937 Main Model Loss: 0.0040471284 Interpreter Loss: 13172.801\n",
      "Epoch:[ 3 ] Batch: 258 / 937 Main Model Loss: 0.0026025437 Interpreter Loss: 12873.336\n",
      "Epoch:[ 3 ] Batch: 259 / 937 Main Model Loss: 0.0012380884 Interpreter Loss: 12095.319\n",
      "Epoch:[ 3 ] Batch: 260 / 937 Main Model Loss: 0.013329118 Interpreter Loss: 12807.57\n",
      "Epoch:[ 3 ] Batch: 261 / 937 Main Model Loss: 0.016502373 Interpreter Loss: 13086.306\n",
      "Epoch:[ 3 ] Batch: 262 / 937 Main Model Loss: 0.009565314 Interpreter Loss: 12616.115\n",
      "Epoch:[ 3 ] Batch: 263 / 937 Main Model Loss: 0.0036230902 Interpreter Loss: 12241.5\n",
      "Epoch:[ 3 ] Batch: 264 / 937 Main Model Loss: 0.0162935 Interpreter Loss: 12583.113\n",
      "Epoch:[ 3 ] Batch: 265 / 937 Main Model Loss: 0.009208474 Interpreter Loss: 13207.775\n",
      "Epoch:[ 3 ] Batch: 266 / 937 Main Model Loss: 0.02173537 Interpreter Loss: 12528.116\n",
      "Epoch:[ 3 ] Batch: 267 / 937 Main Model Loss: 0.006936876 Interpreter Loss: 13428.514\n",
      "Epoch:[ 3 ] Batch: 268 / 937 Main Model Loss: 0.012380467 Interpreter Loss: 13584.467\n",
      "Epoch:[ 3 ] Batch: 269 / 937 Main Model Loss: 0.0132544795 Interpreter Loss: 13832.139\n",
      "Epoch:[ 3 ] Batch: 270 / 937 Main Model Loss: 0.0016254853 Interpreter Loss: 13595.325\n",
      "Epoch:[ 3 ] Batch: 271 / 937 Main Model Loss: 0.0056772754 Interpreter Loss: 12452.531\n",
      "Epoch:[ 3 ] Batch: 272 / 937 Main Model Loss: 0.005891843 Interpreter Loss: 12454.015\n",
      "Epoch:[ 3 ] Batch: 273 / 937 Main Model Loss: 0.0019903132 Interpreter Loss: 12749.448\n",
      "Epoch:[ 3 ] Batch: 274 / 937 Main Model Loss: 0.006964794 Interpreter Loss: 13690.32\n",
      "Epoch:[ 3 ] Batch: 275 / 937 Main Model Loss: 0.004733934 Interpreter Loss: 11916.723\n",
      "Epoch:[ 3 ] Batch: 276 / 937 Main Model Loss: 0.005530164 Interpreter Loss: 12196.18\n",
      "Epoch:[ 3 ] Batch: 277 / 937 Main Model Loss: 0.008405497 Interpreter Loss: 12540.179\n",
      "Epoch:[ 3 ] Batch: 278 / 937 Main Model Loss: 0.026942883 Interpreter Loss: 12360.958\n",
      "Epoch:[ 3 ] Batch: 279 / 937 Main Model Loss: 0.010048152 Interpreter Loss: 12148.184\n",
      "Epoch:[ 3 ] Batch: 280 / 937 Main Model Loss: 0.008124196 Interpreter Loss: 12859.828\n",
      "Epoch:[ 3 ] Batch: 281 / 937 Main Model Loss: 0.022327648 Interpreter Loss: 12738.0\n",
      "Epoch:[ 3 ] Batch: 282 / 937 Main Model Loss: 0.005713924 Interpreter Loss: 12247.731\n",
      "Epoch:[ 3 ] Batch: 283 / 937 Main Model Loss: 0.023034273 Interpreter Loss: 13077.911\n",
      "Epoch:[ 3 ] Batch: 284 / 937 Main Model Loss: 0.011808439 Interpreter Loss: 13248.294\n",
      "Epoch:[ 3 ] Batch: 285 / 937 Main Model Loss: 0.009401541 Interpreter Loss: 12602.7\n",
      "Epoch:[ 3 ] Batch: 286 / 937 Main Model Loss: 0.014183433 Interpreter Loss: 12673.938\n",
      "Epoch:[ 3 ] Batch: 287 / 937 Main Model Loss: 0.012037555 Interpreter Loss: 12654.1875\n",
      "Epoch:[ 3 ] Batch: 288 / 937 Main Model Loss: 0.0027932837 Interpreter Loss: 12349.328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 3 ] Batch: 289 / 937 Main Model Loss: 0.02926269 Interpreter Loss: 12671.578\n",
      "Epoch:[ 3 ] Batch: 290 / 937 Main Model Loss: 0.007348526 Interpreter Loss: 12736.78\n",
      "Epoch:[ 3 ] Batch: 291 / 937 Main Model Loss: 0.0023278892 Interpreter Loss: 12676.928\n",
      "Epoch:[ 3 ] Batch: 292 / 937 Main Model Loss: 0.008596561 Interpreter Loss: 12631.776\n",
      "Epoch:[ 3 ] Batch: 293 / 937 Main Model Loss: 0.0063386713 Interpreter Loss: 12393.043\n",
      "Epoch:[ 3 ] Batch: 294 / 937 Main Model Loss: 0.010150037 Interpreter Loss: 12609.424\n",
      "Epoch:[ 3 ] Batch: 295 / 937 Main Model Loss: 0.0015838202 Interpreter Loss: 12505.311\n",
      "Epoch:[ 3 ] Batch: 296 / 937 Main Model Loss: 0.0012040483 Interpreter Loss: 12268.031\n",
      "Epoch:[ 3 ] Batch: 297 / 937 Main Model Loss: 0.005157779 Interpreter Loss: 11887.498\n",
      "Epoch:[ 3 ] Batch: 298 / 937 Main Model Loss: 0.032800976 Interpreter Loss: 12832.93\n",
      "Epoch:[ 3 ] Batch: 299 / 937 Main Model Loss: 0.005422877 Interpreter Loss: 12522.603\n",
      "Epoch:[ 3 ] Batch: 300 / 937 Main Model Loss: 0.005541313 Interpreter Loss: 14118.561\n",
      "Epoch:[ 3 ] Batch: 301 / 937 Main Model Loss: 0.0020701298 Interpreter Loss: 13277.237\n",
      "Epoch:[ 3 ] Batch: 302 / 937 Main Model Loss: 0.014988845 Interpreter Loss: 14735.173\n",
      "Epoch:[ 3 ] Batch: 303 / 937 Main Model Loss: 0.013052152 Interpreter Loss: 13528.675\n",
      "Epoch:[ 3 ] Batch: 304 / 937 Main Model Loss: 0.010376125 Interpreter Loss: 13689.519\n",
      "Epoch:[ 3 ] Batch: 305 / 937 Main Model Loss: 0.009395466 Interpreter Loss: 14299.704\n",
      "Epoch:[ 3 ] Batch: 306 / 937 Main Model Loss: 0.008688855 Interpreter Loss: 13550.612\n",
      "Epoch:[ 3 ] Batch: 307 / 937 Main Model Loss: 0.00074232544 Interpreter Loss: 13208.125\n",
      "Epoch:[ 3 ] Batch: 308 / 937 Main Model Loss: 0.002605564 Interpreter Loss: 13485.651\n",
      "Epoch:[ 3 ] Batch: 309 / 937 Main Model Loss: 0.002540865 Interpreter Loss: 13358.2705\n",
      "Epoch:[ 3 ] Batch: 310 / 937 Main Model Loss: 0.0066130366 Interpreter Loss: 13614.452\n",
      "Epoch:[ 3 ] Batch: 311 / 937 Main Model Loss: 0.009427651 Interpreter Loss: 13632.79\n",
      "Epoch:[ 3 ] Batch: 312 / 937 Main Model Loss: 0.0060037794 Interpreter Loss: 13640.445\n",
      "Epoch:[ 3 ] Batch: 313 / 937 Main Model Loss: 0.009285134 Interpreter Loss: 12929.571\n",
      "Epoch:[ 3 ] Batch: 314 / 937 Main Model Loss: 0.0030181338 Interpreter Loss: 13063.168\n",
      "Epoch:[ 3 ] Batch: 315 / 937 Main Model Loss: 0.029365838 Interpreter Loss: 13505.586\n",
      "Epoch:[ 3 ] Batch: 316 / 937 Main Model Loss: 0.00598529 Interpreter Loss: 12542.107\n",
      "Epoch:[ 3 ] Batch: 317 / 937 Main Model Loss: 0.025773965 Interpreter Loss: 12628.705\n",
      "Epoch:[ 3 ] Batch: 318 / 937 Main Model Loss: 0.0069311694 Interpreter Loss: 12956.18\n",
      "Epoch:[ 3 ] Batch: 319 / 937 Main Model Loss: 0.009554169 Interpreter Loss: 12338.583\n",
      "Epoch:[ 3 ] Batch: 320 / 937 Main Model Loss: 0.0032977944 Interpreter Loss: 13002.302\n",
      "Epoch:[ 3 ] Batch: 321 / 937 Main Model Loss: 0.00413271 Interpreter Loss: 12807.803\n",
      "Epoch:[ 3 ] Batch: 322 / 937 Main Model Loss: 0.02722376 Interpreter Loss: 14177.768\n",
      "Epoch:[ 3 ] Batch: 323 / 937 Main Model Loss: 0.01937515 Interpreter Loss: 14299.744\n",
      "Epoch:[ 3 ] Batch: 324 / 937 Main Model Loss: 0.0048814304 Interpreter Loss: 13563.235\n",
      "Epoch:[ 3 ] Batch: 325 / 937 Main Model Loss: 0.01298183 Interpreter Loss: 13384.808\n",
      "Epoch:[ 3 ] Batch: 326 / 937 Main Model Loss: 0.0019293019 Interpreter Loss: 13005.576\n",
      "Epoch:[ 3 ] Batch: 327 / 937 Main Model Loss: 0.0028475649 Interpreter Loss: 13382.285\n",
      "Epoch:[ 3 ] Batch: 328 / 937 Main Model Loss: 0.0079257535 Interpreter Loss: 12710.776\n",
      "Epoch:[ 3 ] Batch: 329 / 937 Main Model Loss: 0.0012088524 Interpreter Loss: 11779.378\n",
      "Epoch:[ 3 ] Batch: 330 / 937 Main Model Loss: 0.016411567 Interpreter Loss: 12958.656\n",
      "Epoch:[ 3 ] Batch: 331 / 937 Main Model Loss: 0.0068021677 Interpreter Loss: 12456.608\n",
      "Epoch:[ 3 ] Batch: 332 / 937 Main Model Loss: 0.0026391966 Interpreter Loss: 13046.363\n",
      "Epoch:[ 3 ] Batch: 333 / 937 Main Model Loss: 0.00392419 Interpreter Loss: 12607.702\n",
      "Epoch:[ 3 ] Batch: 334 / 937 Main Model Loss: 0.003220901 Interpreter Loss: 13100.273\n",
      "Epoch:[ 3 ] Batch: 335 / 937 Main Model Loss: 0.011077102 Interpreter Loss: 13174.08\n",
      "Epoch:[ 3 ] Batch: 336 / 937 Main Model Loss: 0.002345479 Interpreter Loss: 13313.173\n",
      "Epoch:[ 3 ] Batch: 337 / 937 Main Model Loss: 0.007104909 Interpreter Loss: 12550.741\n",
      "Epoch:[ 3 ] Batch: 338 / 937 Main Model Loss: 0.0036872542 Interpreter Loss: 12290.801\n",
      "Epoch:[ 3 ] Batch: 339 / 937 Main Model Loss: 0.005747094 Interpreter Loss: 11751.375\n",
      "Epoch:[ 3 ] Batch: 340 / 937 Main Model Loss: 0.0022879462 Interpreter Loss: 13932.864\n",
      "Epoch:[ 3 ] Batch: 341 / 937 Main Model Loss: 0.0014949505 Interpreter Loss: 13534.669\n",
      "Epoch:[ 3 ] Batch: 342 / 937 Main Model Loss: 0.017677523 Interpreter Loss: 14377.812\n",
      "Epoch:[ 3 ] Batch: 343 / 937 Main Model Loss: 0.029081784 Interpreter Loss: 14069.819\n",
      "Epoch:[ 3 ] Batch: 344 / 937 Main Model Loss: 0.005239802 Interpreter Loss: 12777.074\n",
      "Epoch:[ 3 ] Batch: 345 / 937 Main Model Loss: 0.0028889007 Interpreter Loss: 12628.671\n",
      "Epoch:[ 3 ] Batch: 346 / 937 Main Model Loss: 0.01272685 Interpreter Loss: 12922.904\n",
      "Epoch:[ 3 ] Batch: 347 / 937 Main Model Loss: 0.009727474 Interpreter Loss: 13014.694\n",
      "Epoch:[ 3 ] Batch: 348 / 937 Main Model Loss: 0.01390154 Interpreter Loss: 12515.675\n",
      "Epoch:[ 3 ] Batch: 349 / 937 Main Model Loss: 0.0040224316 Interpreter Loss: 12527.085\n",
      "Epoch:[ 3 ] Batch: 350 / 937 Main Model Loss: 0.00955671 Interpreter Loss: 12745.958\n",
      "Epoch:[ 3 ] Batch: 351 / 937 Main Model Loss: 0.011761067 Interpreter Loss: 12979.941\n",
      "Epoch:[ 3 ] Batch: 352 / 937 Main Model Loss: 0.03336362 Interpreter Loss: 14216.742\n",
      "Epoch:[ 3 ] Batch: 353 / 937 Main Model Loss: 0.018448278 Interpreter Loss: 13850.482\n",
      "Epoch:[ 3 ] Batch: 354 / 937 Main Model Loss: 0.008632189 Interpreter Loss: 14141.814\n",
      "Epoch:[ 3 ] Batch: 355 / 937 Main Model Loss: 0.0108644385 Interpreter Loss: 13855.984\n",
      "Epoch:[ 3 ] Batch: 356 / 937 Main Model Loss: 0.0024836408 Interpreter Loss: 13252.082\n",
      "Epoch:[ 3 ] Batch: 357 / 937 Main Model Loss: 0.0030130974 Interpreter Loss: 13224.731\n",
      "Epoch:[ 3 ] Batch: 358 / 937 Main Model Loss: 0.0006994279 Interpreter Loss: 13228.873\n",
      "Epoch:[ 3 ] Batch: 359 / 937 Main Model Loss: 0.004051024 Interpreter Loss: 13287.106\n",
      "Epoch:[ 3 ] Batch: 360 / 937 Main Model Loss: 0.010878522 Interpreter Loss: 14496.196\n",
      "Epoch:[ 3 ] Batch: 361 / 937 Main Model Loss: 0.0027722158 Interpreter Loss: 13059.844\n",
      "Epoch:[ 3 ] Batch: 362 / 937 Main Model Loss: 0.0037575362 Interpreter Loss: 12873.374\n",
      "Epoch:[ 3 ] Batch: 363 / 937 Main Model Loss: 0.00092742115 Interpreter Loss: 12682.212\n",
      "Epoch:[ 3 ] Batch: 364 / 937 Main Model Loss: 0.0017087176 Interpreter Loss: 12780.285\n",
      "Epoch:[ 3 ] Batch: 365 / 937 Main Model Loss: 0.0059154583 Interpreter Loss: 13057.393\n",
      "Epoch:[ 3 ] Batch: 366 / 937 Main Model Loss: 0.0033102748 Interpreter Loss: 12754.132\n",
      "Epoch:[ 3 ] Batch: 367 / 937 Main Model Loss: 0.017693076 Interpreter Loss: 12645.04\n",
      "Epoch:[ 3 ] Batch: 368 / 937 Main Model Loss: 0.012106478 Interpreter Loss: 12422.086\n",
      "Epoch:[ 3 ] Batch: 369 / 937 Main Model Loss: 0.017753929 Interpreter Loss: 12034.659\n",
      "Epoch:[ 3 ] Batch: 370 / 937 Main Model Loss: 0.007274979 Interpreter Loss: 12477.609\n",
      "Epoch:[ 3 ] Batch: 371 / 937 Main Model Loss: 0.0046038083 Interpreter Loss: 12692.615\n",
      "Epoch:[ 3 ] Batch: 372 / 937 Main Model Loss: 0.021237249 Interpreter Loss: 13649.501\n",
      "Epoch:[ 3 ] Batch: 373 / 937 Main Model Loss: 0.049503267 Interpreter Loss: 12640.666\n",
      "Epoch:[ 3 ] Batch: 374 / 937 Main Model Loss: 0.0075292545 Interpreter Loss: 13347.98\n",
      "Epoch:[ 3 ] Batch: 375 / 937 Main Model Loss: 0.011221992 Interpreter Loss: 13192.208\n",
      "Epoch:[ 3 ] Batch: 376 / 937 Main Model Loss: 0.0034153154 Interpreter Loss: 13005.343\n",
      "Epoch:[ 3 ] Batch: 377 / 937 Main Model Loss: 0.0033635362 Interpreter Loss: 12595.871\n",
      "Epoch:[ 3 ] Batch: 378 / 937 Main Model Loss: 0.0036903184 Interpreter Loss: 12864.178\n",
      "Epoch:[ 3 ] Batch: 379 / 937 Main Model Loss: 0.004044974 Interpreter Loss: 12775.0625\n",
      "Epoch:[ 3 ] Batch: 380 / 937 Main Model Loss: 0.00058573845 Interpreter Loss: 11730.456\n",
      "Epoch:[ 3 ] Batch: 381 / 937 Main Model Loss: 0.0072419485 Interpreter Loss: 13269.52\n",
      "Epoch:[ 3 ] Batch: 382 / 937 Main Model Loss: 0.005325002 Interpreter Loss: 13236.294\n",
      "Epoch:[ 3 ] Batch: 383 / 937 Main Model Loss: 0.007223917 Interpreter Loss: 13036.598\n",
      "Epoch:[ 3 ] Batch: 384 / 937 Main Model Loss: 0.027862333 Interpreter Loss: 13476.613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 3 ] Batch: 385 / 937 Main Model Loss: 0.010446586 Interpreter Loss: 13638.3\n",
      "Epoch:[ 3 ] Batch: 386 / 937 Main Model Loss: 0.0037174656 Interpreter Loss: 12902.909\n",
      "Epoch:[ 3 ] Batch: 387 / 937 Main Model Loss: 0.003335569 Interpreter Loss: 13265.131\n",
      "Epoch:[ 3 ] Batch: 388 / 937 Main Model Loss: 0.0025725835 Interpreter Loss: 12420.884\n",
      "Epoch:[ 3 ] Batch: 389 / 937 Main Model Loss: 0.008114036 Interpreter Loss: 12049.873\n",
      "Epoch:[ 3 ] Batch: 390 / 937 Main Model Loss: 0.0015355635 Interpreter Loss: 12370.914\n",
      "Epoch:[ 3 ] Batch: 391 / 937 Main Model Loss: 0.0036052994 Interpreter Loss: 12096.754\n",
      "Epoch:[ 3 ] Batch: 392 / 937 Main Model Loss: 0.01090263 Interpreter Loss: 12696.893\n",
      "Epoch:[ 3 ] Batch: 393 / 937 Main Model Loss: 0.012975405 Interpreter Loss: 12787.695\n",
      "Epoch:[ 3 ] Batch: 394 / 937 Main Model Loss: 0.004851021 Interpreter Loss: 12263.185\n",
      "Epoch:[ 3 ] Batch: 395 / 937 Main Model Loss: 0.008441324 Interpreter Loss: 14395.228\n",
      "Epoch:[ 3 ] Batch: 396 / 937 Main Model Loss: 0.00085822167 Interpreter Loss: 13738.482\n",
      "Epoch:[ 3 ] Batch: 397 / 937 Main Model Loss: 0.0022146006 Interpreter Loss: 13159.17\n",
      "Epoch:[ 3 ] Batch: 398 / 937 Main Model Loss: 0.008113192 Interpreter Loss: 13604.932\n",
      "Epoch:[ 3 ] Batch: 399 / 937 Main Model Loss: 0.041050896 Interpreter Loss: 12678.185\n",
      "Epoch:[ 3 ] Batch: 400 / 937 Main Model Loss: 0.0037502828 Interpreter Loss: 12660.781\n",
      "Epoch:[ 3 ] Batch: 401 / 937 Main Model Loss: 0.025922388 Interpreter Loss: 13004.165\n",
      "Epoch:[ 3 ] Batch: 402 / 937 Main Model Loss: 0.0067195855 Interpreter Loss: 12353.569\n",
      "Epoch:[ 3 ] Batch: 403 / 937 Main Model Loss: 0.0141762085 Interpreter Loss: 12021.995\n",
      "Epoch:[ 3 ] Batch: 404 / 937 Main Model Loss: 0.0039861766 Interpreter Loss: 11543.844\n",
      "Epoch:[ 3 ] Batch: 405 / 937 Main Model Loss: 0.0055349907 Interpreter Loss: 11844.328\n",
      "Epoch:[ 3 ] Batch: 406 / 937 Main Model Loss: 0.001737392 Interpreter Loss: 12996.889\n",
      "Epoch:[ 3 ] Batch: 407 / 937 Main Model Loss: 0.007734615 Interpreter Loss: 12824.854\n",
      "Epoch:[ 3 ] Batch: 408 / 937 Main Model Loss: 0.024072148 Interpreter Loss: 12630.798\n",
      "Epoch:[ 3 ] Batch: 409 / 937 Main Model Loss: 0.0031038725 Interpreter Loss: 12933.348\n",
      "Epoch:[ 3 ] Batch: 410 / 937 Main Model Loss: 0.0026844225 Interpreter Loss: 12097.64\n",
      "Epoch:[ 3 ] Batch: 411 / 937 Main Model Loss: 0.0032531535 Interpreter Loss: 12320.69\n",
      "Epoch:[ 3 ] Batch: 412 / 937 Main Model Loss: 0.05849801 Interpreter Loss: 13989.236\n",
      "Epoch:[ 3 ] Batch: 413 / 937 Main Model Loss: 0.03622063 Interpreter Loss: 12541.925\n",
      "Epoch:[ 3 ] Batch: 414 / 937 Main Model Loss: 0.018713992 Interpreter Loss: 12874.838\n",
      "Epoch:[ 3 ] Batch: 415 / 937 Main Model Loss: 0.042197175 Interpreter Loss: 12178.063\n",
      "Epoch:[ 3 ] Batch: 416 / 937 Main Model Loss: 0.080576494 Interpreter Loss: 13696.87\n",
      "Epoch:[ 3 ] Batch: 417 / 937 Main Model Loss: 0.026133792 Interpreter Loss: 13767.148\n",
      "Epoch:[ 3 ] Batch: 418 / 937 Main Model Loss: 0.010418268 Interpreter Loss: 13291.361\n",
      "Epoch:[ 3 ] Batch: 419 / 937 Main Model Loss: 0.01342501 Interpreter Loss: 14307.204\n",
      "Epoch:[ 3 ] Batch: 420 / 937 Main Model Loss: 0.014721201 Interpreter Loss: 13587.3125\n",
      "Epoch:[ 3 ] Batch: 421 / 937 Main Model Loss: 0.0019618066 Interpreter Loss: 11866.131\n",
      "Epoch:[ 3 ] Batch: 422 / 937 Main Model Loss: 0.0036575333 Interpreter Loss: 12224.095\n",
      "Epoch:[ 3 ] Batch: 423 / 937 Main Model Loss: 0.02179571 Interpreter Loss: 13909.166\n",
      "Epoch:[ 3 ] Batch: 424 / 937 Main Model Loss: 0.005391759 Interpreter Loss: 14106.5\n",
      "Epoch:[ 3 ] Batch: 425 / 937 Main Model Loss: 0.014722057 Interpreter Loss: 13882.166\n",
      "Epoch:[ 3 ] Batch: 426 / 937 Main Model Loss: 0.01197085 Interpreter Loss: 13486.827\n",
      "Epoch:[ 3 ] Batch: 427 / 937 Main Model Loss: 0.004719269 Interpreter Loss: 12557.312\n",
      "Epoch:[ 3 ] Batch: 428 / 937 Main Model Loss: 0.0035653703 Interpreter Loss: 13287.927\n",
      "Epoch:[ 3 ] Batch: 429 / 937 Main Model Loss: 0.017705796 Interpreter Loss: 12713.761\n",
      "Epoch:[ 3 ] Batch: 430 / 937 Main Model Loss: 0.0111470185 Interpreter Loss: 13037.537\n",
      "Epoch:[ 3 ] Batch: 431 / 937 Main Model Loss: 0.009812182 Interpreter Loss: 12619.432\n",
      "Epoch:[ 3 ] Batch: 432 / 937 Main Model Loss: 0.017981654 Interpreter Loss: 13015.578\n",
      "Epoch:[ 3 ] Batch: 433 / 937 Main Model Loss: 0.00893491 Interpreter Loss: 12259.0625\n",
      "Epoch:[ 3 ] Batch: 434 / 937 Main Model Loss: 0.012507182 Interpreter Loss: 12239.746\n",
      "Epoch:[ 3 ] Batch: 435 / 937 Main Model Loss: 0.039548647 Interpreter Loss: 12715.378\n",
      "Epoch:[ 3 ] Batch: 436 / 937 Main Model Loss: 0.0047661443 Interpreter Loss: 13612.109\n",
      "Epoch:[ 3 ] Batch: 437 / 937 Main Model Loss: 0.0025685383 Interpreter Loss: 13371.534\n",
      "Epoch:[ 3 ] Batch: 438 / 937 Main Model Loss: 0.0009874284 Interpreter Loss: 12960.655\n",
      "Epoch:[ 3 ] Batch: 439 / 937 Main Model Loss: 0.00456857 Interpreter Loss: 13463.908\n",
      "Epoch:[ 3 ] Batch: 440 / 937 Main Model Loss: 0.006739878 Interpreter Loss: 13922.324\n",
      "Epoch:[ 3 ] Batch: 441 / 937 Main Model Loss: 0.0024251048 Interpreter Loss: 13372.035\n",
      "Epoch:[ 3 ] Batch: 442 / 937 Main Model Loss: 0.0021804147 Interpreter Loss: 13086.279\n",
      "Epoch:[ 3 ] Batch: 443 / 937 Main Model Loss: 0.027849678 Interpreter Loss: 15009.551\n",
      "Epoch:[ 3 ] Batch: 444 / 937 Main Model Loss: 0.0015675396 Interpreter Loss: 13573.383\n",
      "Epoch:[ 3 ] Batch: 445 / 937 Main Model Loss: 0.0010962677 Interpreter Loss: 13190.99\n",
      "Epoch:[ 3 ] Batch: 446 / 937 Main Model Loss: 0.012048672 Interpreter Loss: 13403.653\n",
      "Epoch:[ 3 ] Batch: 447 / 937 Main Model Loss: 0.031291135 Interpreter Loss: 14354.877\n",
      "Epoch:[ 3 ] Batch: 448 / 937 Main Model Loss: 0.0051300284 Interpreter Loss: 13455.076\n",
      "Epoch:[ 3 ] Batch: 449 / 937 Main Model Loss: 0.0067814607 Interpreter Loss: 13270.294\n",
      "Epoch:[ 3 ] Batch: 450 / 937 Main Model Loss: 0.005332499 Interpreter Loss: 12821.462\n",
      "Epoch:[ 3 ] Batch: 451 / 937 Main Model Loss: 0.00041558425 Interpreter Loss: 13156.386\n",
      "Epoch:[ 3 ] Batch: 452 / 937 Main Model Loss: 0.027733797 Interpreter Loss: 14306.111\n",
      "Epoch:[ 3 ] Batch: 453 / 937 Main Model Loss: 0.017507836 Interpreter Loss: 13643.952\n",
      "Epoch:[ 3 ] Batch: 454 / 937 Main Model Loss: 0.0029112678 Interpreter Loss: 11988.133\n",
      "Epoch:[ 3 ] Batch: 455 / 937 Main Model Loss: 0.013491613 Interpreter Loss: 12589.938\n",
      "Epoch:[ 3 ] Batch: 456 / 937 Main Model Loss: 0.012535613 Interpreter Loss: 12876.01\n",
      "Epoch:[ 3 ] Batch: 457 / 937 Main Model Loss: 0.004127359 Interpreter Loss: 13993.371\n",
      "Epoch:[ 3 ] Batch: 458 / 937 Main Model Loss: 0.01096991 Interpreter Loss: 13862.199\n",
      "Epoch:[ 3 ] Batch: 459 / 937 Main Model Loss: 0.0017835157 Interpreter Loss: 13594.258\n",
      "Epoch:[ 3 ] Batch: 460 / 937 Main Model Loss: 0.005521137 Interpreter Loss: 13331.591\n",
      "Epoch:[ 3 ] Batch: 461 / 937 Main Model Loss: 0.0025290542 Interpreter Loss: 12031.086\n",
      "Epoch:[ 3 ] Batch: 462 / 937 Main Model Loss: 0.0033664955 Interpreter Loss: 11998.151\n",
      "Epoch:[ 3 ] Batch: 463 / 937 Main Model Loss: 0.01228025 Interpreter Loss: 12271.789\n",
      "Epoch:[ 3 ] Batch: 464 / 937 Main Model Loss: 0.01063852 Interpreter Loss: 12629.901\n",
      "Epoch:[ 3 ] Batch: 465 / 937 Main Model Loss: 0.0024526187 Interpreter Loss: 11932.317\n",
      "Epoch:[ 3 ] Batch: 466 / 937 Main Model Loss: 0.011023007 Interpreter Loss: 12175.889\n",
      "Epoch:[ 3 ] Batch: 467 / 937 Main Model Loss: 0.039025523 Interpreter Loss: 12476.134\n",
      "Epoch:[ 3 ] Batch: 468 / 937 Main Model Loss: 0.012552954 Interpreter Loss: 11617.3125\n",
      "Epoch:[ 3 ] Batch: 469 / 937 Main Model Loss: 0.0049742116 Interpreter Loss: 13198.3955\n",
      "Epoch:[ 3 ] Batch: 470 / 937 Main Model Loss: 0.002871703 Interpreter Loss: 12684.765\n",
      "Epoch:[ 3 ] Batch: 471 / 937 Main Model Loss: 0.016584337 Interpreter Loss: 13187.272\n",
      "Epoch:[ 3 ] Batch: 472 / 937 Main Model Loss: 0.001411044 Interpreter Loss: 12037.049\n",
      "Epoch:[ 3 ] Batch: 473 / 937 Main Model Loss: 0.0032775872 Interpreter Loss: 12108.097\n",
      "Epoch:[ 3 ] Batch: 474 / 937 Main Model Loss: 0.0014228182 Interpreter Loss: 12643.615\n",
      "Epoch:[ 3 ] Batch: 475 / 937 Main Model Loss: 0.009352645 Interpreter Loss: 13070.738\n",
      "Epoch:[ 3 ] Batch: 476 / 937 Main Model Loss: 0.024132533 Interpreter Loss: 14054.836\n",
      "Epoch:[ 3 ] Batch: 477 / 937 Main Model Loss: 0.0041538007 Interpreter Loss: 12447.992\n",
      "Epoch:[ 3 ] Batch: 478 / 937 Main Model Loss: 0.014564248 Interpreter Loss: 11681.838\n",
      "Epoch:[ 3 ] Batch: 479 / 937 Main Model Loss: 0.012684748 Interpreter Loss: 11644.075\n",
      "Epoch:[ 3 ] Batch: 480 / 937 Main Model Loss: 0.039320678 Interpreter Loss: 12012.147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 3 ] Batch: 481 / 937 Main Model Loss: 0.008634975 Interpreter Loss: 13083.654\n",
      "Epoch:[ 3 ] Batch: 482 / 937 Main Model Loss: 0.008219039 Interpreter Loss: 12706.286\n",
      "Epoch:[ 3 ] Batch: 483 / 937 Main Model Loss: 0.0023798235 Interpreter Loss: 12300.093\n",
      "Epoch:[ 3 ] Batch: 484 / 937 Main Model Loss: 0.0068934597 Interpreter Loss: 12402.06\n",
      "Epoch:[ 3 ] Batch: 485 / 937 Main Model Loss: 0.0072335345 Interpreter Loss: 12577.804\n",
      "Epoch:[ 3 ] Batch: 486 / 937 Main Model Loss: 0.013490064 Interpreter Loss: 12283.373\n",
      "Epoch:[ 3 ] Batch: 487 / 937 Main Model Loss: 0.0033933478 Interpreter Loss: 12292.164\n",
      "Epoch:[ 3 ] Batch: 488 / 937 Main Model Loss: 0.019462839 Interpreter Loss: 12402.787\n",
      "Epoch:[ 3 ] Batch: 489 / 937 Main Model Loss: 0.0038319458 Interpreter Loss: 12636.67\n",
      "Epoch:[ 3 ] Batch: 490 / 937 Main Model Loss: 0.015687365 Interpreter Loss: 12870.4\n",
      "Epoch:[ 3 ] Batch: 491 / 937 Main Model Loss: 0.0027003102 Interpreter Loss: 12467.054\n",
      "Epoch:[ 3 ] Batch: 492 / 937 Main Model Loss: 0.0030674958 Interpreter Loss: 11711.729\n",
      "Epoch:[ 3 ] Batch: 493 / 937 Main Model Loss: 0.016621707 Interpreter Loss: 12119.953\n",
      "Epoch:[ 3 ] Batch: 494 / 937 Main Model Loss: 0.0074011614 Interpreter Loss: 12034.514\n",
      "Epoch:[ 3 ] Batch: 495 / 937 Main Model Loss: 0.009628948 Interpreter Loss: 12818.416\n",
      "Epoch:[ 3 ] Batch: 496 / 937 Main Model Loss: 0.011729913 Interpreter Loss: 13548.001\n",
      "Epoch:[ 3 ] Batch: 497 / 937 Main Model Loss: 0.00808176 Interpreter Loss: 13134.863\n",
      "Epoch:[ 3 ] Batch: 498 / 937 Main Model Loss: 0.0054337336 Interpreter Loss: 12039.016\n",
      "Epoch:[ 3 ] Batch: 499 / 937 Main Model Loss: 0.007868182 Interpreter Loss: 13067.592\n",
      "Epoch:[ 3 ] Batch: 500 / 937 Main Model Loss: 0.011047758 Interpreter Loss: 13572.722\n",
      "Epoch:[ 3 ] Batch: 501 / 937 Main Model Loss: 0.0119283125 Interpreter Loss: 13688.88\n",
      "Epoch:[ 3 ] Batch: 502 / 937 Main Model Loss: 0.008065835 Interpreter Loss: 13079.174\n",
      "Epoch:[ 3 ] Batch: 503 / 937 Main Model Loss: 0.007868412 Interpreter Loss: 12582.24\n",
      "Epoch:[ 3 ] Batch: 504 / 937 Main Model Loss: 0.0056973626 Interpreter Loss: 13905.338\n",
      "Epoch:[ 3 ] Batch: 505 / 937 Main Model Loss: 0.028195 Interpreter Loss: 14175.225\n",
      "Epoch:[ 3 ] Batch: 506 / 937 Main Model Loss: 0.012688755 Interpreter Loss: 14533.013\n",
      "Epoch:[ 3 ] Batch: 507 / 937 Main Model Loss: 0.01677843 Interpreter Loss: 13760.891\n",
      "Epoch:[ 3 ] Batch: 508 / 937 Main Model Loss: 0.009241284 Interpreter Loss: 12997.54\n",
      "Epoch:[ 3 ] Batch: 509 / 937 Main Model Loss: 0.001048944 Interpreter Loss: 12161.574\n",
      "Epoch:[ 3 ] Batch: 510 / 937 Main Model Loss: 0.008218977 Interpreter Loss: 12832.099\n",
      "Epoch:[ 3 ] Batch: 511 / 937 Main Model Loss: 0.006542041 Interpreter Loss: 11886.195\n",
      "Epoch:[ 3 ] Batch: 512 / 937 Main Model Loss: 0.0077815545 Interpreter Loss: 12577.302\n",
      "Epoch:[ 3 ] Batch: 513 / 937 Main Model Loss: 0.038798712 Interpreter Loss: 12727.052\n",
      "Epoch:[ 3 ] Batch: 514 / 937 Main Model Loss: 0.0033605737 Interpreter Loss: 12806.916\n",
      "Epoch:[ 3 ] Batch: 515 / 937 Main Model Loss: 0.0009515032 Interpreter Loss: 12796.295\n",
      "Epoch:[ 3 ] Batch: 516 / 937 Main Model Loss: 0.0035826263 Interpreter Loss: 13589.716\n",
      "Epoch:[ 3 ] Batch: 517 / 937 Main Model Loss: 0.011690393 Interpreter Loss: 12648.384\n",
      "Epoch:[ 3 ] Batch: 518 / 937 Main Model Loss: 0.00199863 Interpreter Loss: 12733.445\n",
      "Epoch:[ 3 ] Batch: 519 / 937 Main Model Loss: 0.002846649 Interpreter Loss: 12691.476\n",
      "Epoch:[ 3 ] Batch: 520 / 937 Main Model Loss: 0.002561923 Interpreter Loss: 13566.129\n",
      "Epoch:[ 3 ] Batch: 521 / 937 Main Model Loss: 0.00340189 Interpreter Loss: 12288.057\n",
      "Epoch:[ 3 ] Batch: 522 / 937 Main Model Loss: 0.008143123 Interpreter Loss: 12213.859\n",
      "Epoch:[ 3 ] Batch: 523 / 937 Main Model Loss: 0.016794056 Interpreter Loss: 12184.426\n",
      "Epoch:[ 3 ] Batch: 524 / 937 Main Model Loss: 0.003569063 Interpreter Loss: 11717.36\n",
      "Epoch:[ 3 ] Batch: 525 / 937 Main Model Loss: 0.015114618 Interpreter Loss: 11808.694\n",
      "Epoch:[ 3 ] Batch: 526 / 937 Main Model Loss: 0.005469442 Interpreter Loss: 12583.092\n",
      "Epoch:[ 3 ] Batch: 527 / 937 Main Model Loss: 0.016504448 Interpreter Loss: 13346.315\n",
      "Epoch:[ 3 ] Batch: 528 / 937 Main Model Loss: 0.0020878331 Interpreter Loss: 13211.566\n",
      "Epoch:[ 3 ] Batch: 529 / 937 Main Model Loss: 0.004777577 Interpreter Loss: 12689.864\n",
      "Epoch:[ 3 ] Batch: 530 / 937 Main Model Loss: 0.008486484 Interpreter Loss: 12443.626\n",
      "Epoch:[ 3 ] Batch: 531 / 937 Main Model Loss: 0.008731524 Interpreter Loss: 11483.454\n",
      "Epoch:[ 3 ] Batch: 532 / 937 Main Model Loss: 0.00366061 Interpreter Loss: 12843.863\n",
      "Epoch:[ 3 ] Batch: 533 / 937 Main Model Loss: 0.0016574671 Interpreter Loss: 12647.958\n",
      "Epoch:[ 3 ] Batch: 534 / 937 Main Model Loss: 0.0008409707 Interpreter Loss: 11996.37\n",
      "Epoch:[ 3 ] Batch: 535 / 937 Main Model Loss: 0.0010599048 Interpreter Loss: 11808.421\n",
      "Epoch:[ 3 ] Batch: 536 / 937 Main Model Loss: 0.005606332 Interpreter Loss: 13047.234\n",
      "Epoch:[ 3 ] Batch: 537 / 937 Main Model Loss: 0.048140563 Interpreter Loss: 13403.212\n",
      "Epoch:[ 3 ] Batch: 538 / 937 Main Model Loss: 0.0017275608 Interpreter Loss: 12880.499\n",
      "Epoch:[ 3 ] Batch: 539 / 937 Main Model Loss: 0.015585377 Interpreter Loss: 13471.014\n",
      "Epoch:[ 3 ] Batch: 540 / 937 Main Model Loss: 0.0062797675 Interpreter Loss: 13045.916\n",
      "Epoch:[ 3 ] Batch: 541 / 937 Main Model Loss: 0.017086111 Interpreter Loss: 14260.755\n",
      "Epoch:[ 3 ] Batch: 542 / 937 Main Model Loss: 0.025972405 Interpreter Loss: 13380.033\n",
      "Epoch:[ 3 ] Batch: 543 / 937 Main Model Loss: 0.025851741 Interpreter Loss: 13455.889\n",
      "Epoch:[ 3 ] Batch: 544 / 937 Main Model Loss: 0.0043391343 Interpreter Loss: 13478.337\n",
      "Epoch:[ 3 ] Batch: 545 / 937 Main Model Loss: 0.013196956 Interpreter Loss: 13191.866\n",
      "Epoch:[ 3 ] Batch: 546 / 937 Main Model Loss: 0.005693514 Interpreter Loss: 12630.748\n",
      "Epoch:[ 3 ] Batch: 547 / 937 Main Model Loss: 0.034427553 Interpreter Loss: 13826.594\n",
      "Epoch:[ 3 ] Batch: 548 / 937 Main Model Loss: 0.0009632561 Interpreter Loss: 12281.208\n",
      "Epoch:[ 3 ] Batch: 549 / 937 Main Model Loss: 0.028360156 Interpreter Loss: 12779.731\n",
      "Epoch:[ 3 ] Batch: 550 / 937 Main Model Loss: 0.040704988 Interpreter Loss: 12882.204\n",
      "Epoch:[ 3 ] Batch: 551 / 937 Main Model Loss: 0.028581182 Interpreter Loss: 12226.748\n",
      "Epoch:[ 3 ] Batch: 552 / 937 Main Model Loss: 0.014560732 Interpreter Loss: 12801.081\n",
      "Epoch:[ 3 ] Batch: 553 / 937 Main Model Loss: 0.0074878437 Interpreter Loss: 12950.398\n",
      "Epoch:[ 3 ] Batch: 554 / 937 Main Model Loss: 0.067016095 Interpreter Loss: 14280.189\n",
      "Epoch:[ 3 ] Batch: 555 / 937 Main Model Loss: 0.005487929 Interpreter Loss: 12411.221\n",
      "Epoch:[ 3 ] Batch: 556 / 937 Main Model Loss: 0.010843519 Interpreter Loss: 13020.077\n",
      "Epoch:[ 3 ] Batch: 557 / 937 Main Model Loss: 0.010411722 Interpreter Loss: 13247.2\n",
      "Epoch:[ 3 ] Batch: 558 / 937 Main Model Loss: 0.014262742 Interpreter Loss: 12552.809\n",
      "Epoch:[ 3 ] Batch: 559 / 937 Main Model Loss: 0.000738993 Interpreter Loss: 12190.862\n",
      "Epoch:[ 3 ] Batch: 560 / 937 Main Model Loss: 0.0062515377 Interpreter Loss: 12748.247\n",
      "Epoch:[ 3 ] Batch: 561 / 937 Main Model Loss: 0.005589504 Interpreter Loss: 12055.453\n",
      "Epoch:[ 3 ] Batch: 562 / 937 Main Model Loss: 0.007894842 Interpreter Loss: 11850.105\n",
      "Epoch:[ 3 ] Batch: 563 / 937 Main Model Loss: 0.0047106463 Interpreter Loss: 12090.218\n",
      "Epoch:[ 3 ] Batch: 564 / 937 Main Model Loss: 0.017830832 Interpreter Loss: 14146.426\n",
      "Epoch:[ 3 ] Batch: 565 / 937 Main Model Loss: 0.0033543962 Interpreter Loss: 14514.499\n",
      "Epoch:[ 3 ] Batch: 566 / 937 Main Model Loss: 0.0022317176 Interpreter Loss: 14102.224\n",
      "Epoch:[ 3 ] Batch: 567 / 937 Main Model Loss: 0.0063034846 Interpreter Loss: 13614.898\n",
      "Epoch:[ 3 ] Batch: 568 / 937 Main Model Loss: 0.0060050036 Interpreter Loss: 12328.939\n",
      "Epoch:[ 3 ] Batch: 569 / 937 Main Model Loss: 0.014743308 Interpreter Loss: 12935.109\n",
      "Epoch:[ 3 ] Batch: 570 / 937 Main Model Loss: 0.0039607254 Interpreter Loss: 12279.941\n",
      "Epoch:[ 3 ] Batch: 571 / 937 Main Model Loss: 0.002710575 Interpreter Loss: 14050.543\n",
      "Epoch:[ 3 ] Batch: 572 / 937 Main Model Loss: 0.005320248 Interpreter Loss: 13632.596\n",
      "Epoch:[ 3 ] Batch: 573 / 937 Main Model Loss: 0.003747543 Interpreter Loss: 14490.549\n",
      "Epoch:[ 3 ] Batch: 574 / 937 Main Model Loss: 0.0125581585 Interpreter Loss: 14689.044\n",
      "Epoch:[ 3 ] Batch: 575 / 937 Main Model Loss: 0.0055187694 Interpreter Loss: 13082.992\n",
      "Epoch:[ 3 ] Batch: 576 / 937 Main Model Loss: 0.01585724 Interpreter Loss: 13104.801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 3 ] Batch: 577 / 937 Main Model Loss: 0.012034368 Interpreter Loss: 12783.499\n",
      "Epoch:[ 3 ] Batch: 578 / 937 Main Model Loss: 0.047193136 Interpreter Loss: 12472.609\n",
      "Epoch:[ 3 ] Batch: 579 / 937 Main Model Loss: 0.019931147 Interpreter Loss: 14497.785\n",
      "Epoch:[ 3 ] Batch: 580 / 937 Main Model Loss: 0.006187204 Interpreter Loss: 13732.222\n",
      "Epoch:[ 3 ] Batch: 581 / 937 Main Model Loss: 0.0015583184 Interpreter Loss: 13538.014\n",
      "Epoch:[ 3 ] Batch: 582 / 937 Main Model Loss: 0.007248452 Interpreter Loss: 13762.459\n",
      "Epoch:[ 3 ] Batch: 583 / 937 Main Model Loss: 0.014249237 Interpreter Loss: 14133.545\n",
      "Epoch:[ 3 ] Batch: 584 / 937 Main Model Loss: 0.011749412 Interpreter Loss: 13443.1045\n",
      "Epoch:[ 3 ] Batch: 585 / 937 Main Model Loss: 0.031614527 Interpreter Loss: 13875.2705\n",
      "Epoch:[ 3 ] Batch: 586 / 937 Main Model Loss: 0.0047563845 Interpreter Loss: 12128.108\n",
      "Epoch:[ 3 ] Batch: 587 / 937 Main Model Loss: 0.00353284 Interpreter Loss: 11929.922\n",
      "Epoch:[ 3 ] Batch: 588 / 937 Main Model Loss: 0.009443157 Interpreter Loss: 11933.228\n",
      "Epoch:[ 3 ] Batch: 589 / 937 Main Model Loss: 0.00917462 Interpreter Loss: 14029.648\n",
      "Epoch:[ 3 ] Batch: 590 / 937 Main Model Loss: 0.014460868 Interpreter Loss: 14328.102\n",
      "Epoch:[ 3 ] Batch: 591 / 937 Main Model Loss: 0.024887014 Interpreter Loss: 13881.315\n",
      "Epoch:[ 3 ] Batch: 592 / 937 Main Model Loss: 0.0030780965 Interpreter Loss: 12466.641\n",
      "Epoch:[ 3 ] Batch: 593 / 937 Main Model Loss: 0.02996525 Interpreter Loss: 12647.559\n",
      "Epoch:[ 3 ] Batch: 594 / 937 Main Model Loss: 0.008037124 Interpreter Loss: 11916.086\n",
      "Epoch:[ 3 ] Batch: 595 / 937 Main Model Loss: 0.0031132703 Interpreter Loss: 12729.083\n",
      "Epoch:[ 3 ] Batch: 596 / 937 Main Model Loss: 0.009271655 Interpreter Loss: 13011.221\n",
      "Epoch:[ 3 ] Batch: 597 / 937 Main Model Loss: 0.008349984 Interpreter Loss: 12643.913\n",
      "Epoch:[ 3 ] Batch: 598 / 937 Main Model Loss: 0.0043592798 Interpreter Loss: 12927.946\n",
      "Epoch:[ 3 ] Batch: 599 / 937 Main Model Loss: 0.023068244 Interpreter Loss: 12981.985\n",
      "Epoch:[ 3 ] Batch: 600 / 937 Main Model Loss: 0.0067037903 Interpreter Loss: 13353.006\n",
      "Epoch:[ 3 ] Batch: 601 / 937 Main Model Loss: 0.013120826 Interpreter Loss: 12236.42\n",
      "Epoch:[ 3 ] Batch: 602 / 937 Main Model Loss: 0.004148426 Interpreter Loss: 12774.556\n",
      "Epoch:[ 3 ] Batch: 603 / 937 Main Model Loss: 0.008257907 Interpreter Loss: 14171.946\n",
      "Epoch:[ 3 ] Batch: 604 / 937 Main Model Loss: 0.079672284 Interpreter Loss: 12541.039\n",
      "Epoch:[ 3 ] Batch: 605 / 937 Main Model Loss: 0.017593153 Interpreter Loss: 12841.287\n",
      "Epoch:[ 3 ] Batch: 606 / 937 Main Model Loss: 0.007545113 Interpreter Loss: 12621.516\n",
      "Epoch:[ 3 ] Batch: 607 / 937 Main Model Loss: 0.0026190612 Interpreter Loss: 12771.44\n",
      "Epoch:[ 3 ] Batch: 608 / 937 Main Model Loss: 0.015931088 Interpreter Loss: 12340.792\n",
      "Epoch:[ 3 ] Batch: 609 / 937 Main Model Loss: 0.012260051 Interpreter Loss: 12611.579\n",
      "Epoch:[ 3 ] Batch: 610 / 937 Main Model Loss: 0.0006502286 Interpreter Loss: 12528.259\n",
      "Epoch:[ 3 ] Batch: 611 / 937 Main Model Loss: 0.0021539703 Interpreter Loss: 13202.888\n",
      "Epoch:[ 3 ] Batch: 612 / 937 Main Model Loss: 0.0032198126 Interpreter Loss: 14238.326\n",
      "Epoch:[ 3 ] Batch: 613 / 937 Main Model Loss: 0.012488362 Interpreter Loss: 13429.16\n",
      "Epoch:[ 3 ] Batch: 614 / 937 Main Model Loss: 0.048995085 Interpreter Loss: 14718.464\n",
      "Epoch:[ 3 ] Batch: 615 / 937 Main Model Loss: 0.024610102 Interpreter Loss: 13928.635\n",
      "Epoch:[ 3 ] Batch: 616 / 937 Main Model Loss: 0.01713232 Interpreter Loss: 14355.877\n",
      "Epoch:[ 3 ] Batch: 617 / 937 Main Model Loss: 0.0020605116 Interpreter Loss: 12550.746\n",
      "Epoch:[ 3 ] Batch: 618 / 937 Main Model Loss: 0.00563923 Interpreter Loss: 13017.892\n",
      "Epoch:[ 3 ] Batch: 619 / 937 Main Model Loss: 0.0081789 Interpreter Loss: 13687.621\n",
      "Epoch:[ 3 ] Batch: 620 / 937 Main Model Loss: 0.0045403745 Interpreter Loss: 12674.226\n",
      "Epoch:[ 3 ] Batch: 621 / 937 Main Model Loss: 0.016819477 Interpreter Loss: 11533.814\n",
      "Epoch:[ 3 ] Batch: 622 / 937 Main Model Loss: 0.009247234 Interpreter Loss: 12187.636\n",
      "Epoch:[ 3 ] Batch: 623 / 937 Main Model Loss: 0.0013910313 Interpreter Loss: 11563.6045\n",
      "Epoch:[ 3 ] Batch: 624 / 937 Main Model Loss: 0.00454302 Interpreter Loss: 13002.635\n",
      "Epoch:[ 3 ] Batch: 625 / 937 Main Model Loss: 0.0048310203 Interpreter Loss: 12423.458\n",
      "Epoch:[ 3 ] Batch: 626 / 937 Main Model Loss: 0.0056255287 Interpreter Loss: 13112.302\n",
      "Epoch:[ 3 ] Batch: 627 / 937 Main Model Loss: 0.015401029 Interpreter Loss: 13212.792\n",
      "Epoch:[ 3 ] Batch: 628 / 937 Main Model Loss: 0.011017429 Interpreter Loss: 12918.301\n",
      "Epoch:[ 3 ] Batch: 629 / 937 Main Model Loss: 0.023909982 Interpreter Loss: 13076.521\n",
      "Epoch:[ 3 ] Batch: 630 / 937 Main Model Loss: 0.008052715 Interpreter Loss: 12605.25\n",
      "Epoch:[ 3 ] Batch: 631 / 937 Main Model Loss: 0.019134054 Interpreter Loss: 13062.945\n",
      "Epoch:[ 3 ] Batch: 632 / 937 Main Model Loss: 0.005760394 Interpreter Loss: 13902.492\n",
      "Epoch:[ 3 ] Batch: 633 / 937 Main Model Loss: 0.0017379108 Interpreter Loss: 13207.295\n",
      "Epoch:[ 3 ] Batch: 634 / 937 Main Model Loss: 0.0042773234 Interpreter Loss: 13644.633\n",
      "Epoch:[ 3 ] Batch: 635 / 937 Main Model Loss: 0.0021932758 Interpreter Loss: 12065.537\n",
      "Epoch:[ 3 ] Batch: 636 / 937 Main Model Loss: 0.0081531685 Interpreter Loss: 12767.786\n",
      "Epoch:[ 3 ] Batch: 637 / 937 Main Model Loss: 0.00754047 Interpreter Loss: 11701.178\n",
      "Epoch:[ 3 ] Batch: 638 / 937 Main Model Loss: 0.014040125 Interpreter Loss: 12878.898\n",
      "Epoch:[ 3 ] Batch: 639 / 937 Main Model Loss: 0.005861785 Interpreter Loss: 12040.9375\n",
      "Epoch:[ 3 ] Batch: 640 / 937 Main Model Loss: 0.010134593 Interpreter Loss: 13096.912\n",
      "Epoch:[ 3 ] Batch: 641 / 937 Main Model Loss: 0.017575022 Interpreter Loss: 12578.517\n",
      "Epoch:[ 3 ] Batch: 642 / 937 Main Model Loss: 0.005967196 Interpreter Loss: 12367.198\n",
      "Epoch:[ 3 ] Batch: 643 / 937 Main Model Loss: 0.025662621 Interpreter Loss: 13373.924\n",
      "Epoch:[ 3 ] Batch: 644 / 937 Main Model Loss: 0.010670605 Interpreter Loss: 12579.832\n",
      "Epoch:[ 3 ] Batch: 645 / 937 Main Model Loss: 0.011985558 Interpreter Loss: 13513.72\n",
      "Epoch:[ 3 ] Batch: 646 / 937 Main Model Loss: 0.012722759 Interpreter Loss: 13748.8545\n",
      "Epoch:[ 3 ] Batch: 647 / 937 Main Model Loss: 0.020190539 Interpreter Loss: 13081.123\n",
      "Epoch:[ 3 ] Batch: 648 / 937 Main Model Loss: 0.004770264 Interpreter Loss: 12094.0\n",
      "Epoch:[ 3 ] Batch: 649 / 937 Main Model Loss: 0.012185729 Interpreter Loss: 13273.815\n",
      "Epoch:[ 3 ] Batch: 650 / 937 Main Model Loss: 0.025909329 Interpreter Loss: 12561.065\n",
      "Epoch:[ 3 ] Batch: 651 / 937 Main Model Loss: 0.0032303305 Interpreter Loss: 11174.146\n",
      "Epoch:[ 3 ] Batch: 652 / 937 Main Model Loss: 0.004497453 Interpreter Loss: 11125.793\n",
      "Epoch:[ 3 ] Batch: 653 / 937 Main Model Loss: 0.010682821 Interpreter Loss: 12179.445\n",
      "Epoch:[ 3 ] Batch: 654 / 937 Main Model Loss: 0.0068519213 Interpreter Loss: 13232.433\n",
      "Epoch:[ 3 ] Batch: 655 / 937 Main Model Loss: 0.0039193733 Interpreter Loss: 13063.424\n",
      "Epoch:[ 3 ] Batch: 656 / 937 Main Model Loss: 0.0048127426 Interpreter Loss: 13699.691\n",
      "Epoch:[ 3 ] Batch: 657 / 937 Main Model Loss: 0.0004941301 Interpreter Loss: 13073.12\n",
      "Epoch:[ 3 ] Batch: 658 / 937 Main Model Loss: 0.0071090027 Interpreter Loss: 13319.815\n",
      "Epoch:[ 3 ] Batch: 659 / 937 Main Model Loss: 0.0013271815 Interpreter Loss: 13954.817\n",
      "Epoch:[ 3 ] Batch: 660 / 937 Main Model Loss: 0.004464021 Interpreter Loss: 13163.699\n",
      "Epoch:[ 3 ] Batch: 661 / 937 Main Model Loss: 0.008040285 Interpreter Loss: 12952.545\n",
      "Epoch:[ 3 ] Batch: 662 / 937 Main Model Loss: 0.0058337287 Interpreter Loss: 12737.543\n",
      "Epoch:[ 3 ] Batch: 663 / 937 Main Model Loss: 0.013587848 Interpreter Loss: 12792.143\n",
      "Epoch:[ 3 ] Batch: 664 / 937 Main Model Loss: 0.0013684963 Interpreter Loss: 13013.412\n",
      "Epoch:[ 3 ] Batch: 665 / 937 Main Model Loss: 0.036082055 Interpreter Loss: 13328.943\n",
      "Epoch:[ 3 ] Batch: 666 / 937 Main Model Loss: 0.024791628 Interpreter Loss: 13867.011\n",
      "Epoch:[ 3 ] Batch: 667 / 937 Main Model Loss: 0.0073017823 Interpreter Loss: 13466.262\n",
      "Epoch:[ 3 ] Batch: 668 / 937 Main Model Loss: 0.007615272 Interpreter Loss: 13801.4795\n",
      "Epoch:[ 3 ] Batch: 669 / 937 Main Model Loss: 0.007080439 Interpreter Loss: 14088.907\n",
      "Epoch:[ 3 ] Batch: 670 / 937 Main Model Loss: 0.003477187 Interpreter Loss: 12638.057\n",
      "Epoch:[ 3 ] Batch: 671 / 937 Main Model Loss: 0.011155071 Interpreter Loss: 12132.895\n",
      "Epoch:[ 3 ] Batch: 672 / 937 Main Model Loss: 0.011920994 Interpreter Loss: 12622.621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 3 ] Batch: 673 / 937 Main Model Loss: 0.05729969 Interpreter Loss: 11881.129\n",
      "Epoch:[ 3 ] Batch: 674 / 937 Main Model Loss: 0.016015923 Interpreter Loss: 13685.666\n",
      "Epoch:[ 3 ] Batch: 675 / 937 Main Model Loss: 0.0034744071 Interpreter Loss: 12930.033\n",
      "Epoch:[ 3 ] Batch: 676 / 937 Main Model Loss: 0.004671784 Interpreter Loss: 12351.206\n",
      "Epoch:[ 3 ] Batch: 677 / 937 Main Model Loss: 0.0037258172 Interpreter Loss: 12769.947\n",
      "Epoch:[ 3 ] Batch: 678 / 937 Main Model Loss: 0.07840579 Interpreter Loss: 12382.425\n",
      "Epoch:[ 3 ] Batch: 679 / 937 Main Model Loss: 0.0056914063 Interpreter Loss: 12743.642\n",
      "Epoch:[ 3 ] Batch: 680 / 937 Main Model Loss: 0.009523991 Interpreter Loss: 12509.1045\n",
      "Epoch:[ 3 ] Batch: 681 / 937 Main Model Loss: 0.015282301 Interpreter Loss: 12979.648\n",
      "Epoch:[ 3 ] Batch: 682 / 937 Main Model Loss: 0.01976052 Interpreter Loss: 13073.521\n",
      "Epoch:[ 3 ] Batch: 683 / 937 Main Model Loss: 0.0005795569 Interpreter Loss: 12306.081\n",
      "Epoch:[ 3 ] Batch: 684 / 937 Main Model Loss: 0.0032756657 Interpreter Loss: 12180.427\n",
      "Epoch:[ 3 ] Batch: 685 / 937 Main Model Loss: 0.0066652196 Interpreter Loss: 12276.614\n",
      "Epoch:[ 3 ] Batch: 686 / 937 Main Model Loss: 0.036125507 Interpreter Loss: 12954.544\n",
      "Epoch:[ 3 ] Batch: 687 / 937 Main Model Loss: 0.005482112 Interpreter Loss: 12040.146\n",
      "Epoch:[ 3 ] Batch: 688 / 937 Main Model Loss: 0.004589822 Interpreter Loss: 13500.496\n",
      "Epoch:[ 3 ] Batch: 689 / 937 Main Model Loss: 0.016458482 Interpreter Loss: 12359.57\n",
      "Epoch:[ 3 ] Batch: 690 / 937 Main Model Loss: 0.007797226 Interpreter Loss: 12330.658\n",
      "Epoch:[ 3 ] Batch: 691 / 937 Main Model Loss: 0.009266932 Interpreter Loss: 12862.71\n",
      "Epoch:[ 3 ] Batch: 692 / 937 Main Model Loss: 0.006287361 Interpreter Loss: 12609.771\n",
      "Epoch:[ 3 ] Batch: 693 / 937 Main Model Loss: 0.009480638 Interpreter Loss: 12459.959\n",
      "Epoch:[ 3 ] Batch: 694 / 937 Main Model Loss: 0.03474398 Interpreter Loss: 14041.581\n",
      "Epoch:[ 3 ] Batch: 695 / 937 Main Model Loss: 0.024404299 Interpreter Loss: 12589.597\n",
      "Epoch:[ 3 ] Batch: 696 / 937 Main Model Loss: 0.0017763993 Interpreter Loss: 12155.206\n",
      "Epoch:[ 3 ] Batch: 697 / 937 Main Model Loss: 0.012842136 Interpreter Loss: 12667.541\n",
      "Epoch:[ 3 ] Batch: 698 / 937 Main Model Loss: 0.0029751428 Interpreter Loss: 11944.457\n",
      "Epoch:[ 3 ] Batch: 699 / 937 Main Model Loss: 0.006273789 Interpreter Loss: 12352.774\n",
      "Epoch:[ 3 ] Batch: 700 / 937 Main Model Loss: 0.0070413332 Interpreter Loss: 13005.169\n",
      "Epoch:[ 3 ] Batch: 701 / 937 Main Model Loss: 0.0049307747 Interpreter Loss: 12617.11\n",
      "Epoch:[ 3 ] Batch: 702 / 937 Main Model Loss: 0.0053300573 Interpreter Loss: 12970.988\n",
      "Epoch:[ 3 ] Batch: 703 / 937 Main Model Loss: 0.0066003273 Interpreter Loss: 13523.372\n",
      "Epoch:[ 3 ] Batch: 704 / 937 Main Model Loss: 0.007861384 Interpreter Loss: 13051.765\n",
      "Epoch:[ 3 ] Batch: 705 / 937 Main Model Loss: 0.013023837 Interpreter Loss: 12849.256\n",
      "Epoch:[ 3 ] Batch: 706 / 937 Main Model Loss: 0.01017194 Interpreter Loss: 12410.57\n",
      "Epoch:[ 3 ] Batch: 707 / 937 Main Model Loss: 0.007386239 Interpreter Loss: 12704.96\n",
      "Epoch:[ 3 ] Batch: 708 / 937 Main Model Loss: 0.00692155 Interpreter Loss: 12721.626\n",
      "Epoch:[ 3 ] Batch: 709 / 937 Main Model Loss: 0.016170004 Interpreter Loss: 12361.314\n",
      "Epoch:[ 3 ] Batch: 710 / 937 Main Model Loss: 0.01259744 Interpreter Loss: 12443.114\n",
      "Epoch:[ 3 ] Batch: 711 / 937 Main Model Loss: 0.008482654 Interpreter Loss: 12542.517\n",
      "Epoch:[ 3 ] Batch: 712 / 937 Main Model Loss: 0.02665554 Interpreter Loss: 12842.612\n",
      "Epoch:[ 3 ] Batch: 713 / 937 Main Model Loss: 0.0027669412 Interpreter Loss: 12238.498\n",
      "Epoch:[ 3 ] Batch: 714 / 937 Main Model Loss: 0.004063912 Interpreter Loss: 12658.118\n",
      "Epoch:[ 3 ] Batch: 715 / 937 Main Model Loss: 0.018863838 Interpreter Loss: 12799.125\n",
      "Epoch:[ 3 ] Batch: 716 / 937 Main Model Loss: 0.0040106843 Interpreter Loss: 12926.454\n",
      "Epoch:[ 3 ] Batch: 717 / 937 Main Model Loss: 0.011564448 Interpreter Loss: 11906.6455\n",
      "Epoch:[ 3 ] Batch: 718 / 937 Main Model Loss: 0.010055738 Interpreter Loss: 11878.85\n",
      "Epoch:[ 3 ] Batch: 719 / 937 Main Model Loss: 0.024984274 Interpreter Loss: 12694.616\n",
      "Epoch:[ 3 ] Batch: 720 / 937 Main Model Loss: 0.006738954 Interpreter Loss: 11904.287\n",
      "Epoch:[ 3 ] Batch: 721 / 937 Main Model Loss: 0.0041940827 Interpreter Loss: 12166.766\n",
      "Epoch:[ 3 ] Batch: 722 / 937 Main Model Loss: 0.016792828 Interpreter Loss: 13527.336\n",
      "Epoch:[ 3 ] Batch: 723 / 937 Main Model Loss: 0.025460962 Interpreter Loss: 13073.613\n",
      "Epoch:[ 3 ] Batch: 724 / 937 Main Model Loss: 0.0147771705 Interpreter Loss: 13955.486\n",
      "Epoch:[ 3 ] Batch: 725 / 937 Main Model Loss: 0.0043700263 Interpreter Loss: 12651.75\n",
      "Epoch:[ 3 ] Batch: 726 / 937 Main Model Loss: 0.024985014 Interpreter Loss: 12150.712\n",
      "Epoch:[ 3 ] Batch: 727 / 937 Main Model Loss: 0.0032550632 Interpreter Loss: 12231.973\n",
      "Epoch:[ 3 ] Batch: 728 / 937 Main Model Loss: 0.0022697914 Interpreter Loss: 12379.273\n",
      "Epoch:[ 3 ] Batch: 729 / 937 Main Model Loss: 0.0024975068 Interpreter Loss: 13120.121\n",
      "Epoch:[ 3 ] Batch: 730 / 937 Main Model Loss: 0.022917263 Interpreter Loss: 14430.926\n",
      "Epoch:[ 3 ] Batch: 731 / 937 Main Model Loss: 0.0062890155 Interpreter Loss: 13079.784\n",
      "Epoch:[ 3 ] Batch: 732 / 937 Main Model Loss: 0.0038005088 Interpreter Loss: 13973.264\n",
      "Epoch:[ 3 ] Batch: 733 / 937 Main Model Loss: 0.0035573193 Interpreter Loss: 12476.452\n",
      "Epoch:[ 3 ] Batch: 734 / 937 Main Model Loss: 0.0061795874 Interpreter Loss: 13993.783\n",
      "Epoch:[ 3 ] Batch: 735 / 937 Main Model Loss: 0.005942637 Interpreter Loss: 13010.2\n",
      "Epoch:[ 3 ] Batch: 736 / 937 Main Model Loss: 0.008591241 Interpreter Loss: 12637.21\n",
      "Epoch:[ 3 ] Batch: 737 / 937 Main Model Loss: 0.011651947 Interpreter Loss: 12398.185\n",
      "Epoch:[ 3 ] Batch: 738 / 937 Main Model Loss: 0.014139628 Interpreter Loss: 12496.226\n",
      "Epoch:[ 3 ] Batch: 739 / 937 Main Model Loss: 0.04726037 Interpreter Loss: 11797.93\n",
      "Epoch:[ 3 ] Batch: 740 / 937 Main Model Loss: 0.007107977 Interpreter Loss: 13094.807\n",
      "Epoch:[ 3 ] Batch: 741 / 937 Main Model Loss: 0.007129212 Interpreter Loss: 13853.533\n",
      "Epoch:[ 3 ] Batch: 742 / 937 Main Model Loss: 0.0044223126 Interpreter Loss: 12844.968\n",
      "Epoch:[ 3 ] Batch: 743 / 937 Main Model Loss: 0.022994522 Interpreter Loss: 14816.381\n",
      "Epoch:[ 3 ] Batch: 744 / 937 Main Model Loss: 0.0018185802 Interpreter Loss: 13761.879\n",
      "Epoch:[ 3 ] Batch: 745 / 937 Main Model Loss: 0.0041240165 Interpreter Loss: 13814.003\n",
      "Epoch:[ 3 ] Batch: 746 / 937 Main Model Loss: 0.005461786 Interpreter Loss: 13040.595\n",
      "Epoch:[ 3 ] Batch: 747 / 937 Main Model Loss: 0.020343933 Interpreter Loss: 13247.432\n",
      "Epoch:[ 3 ] Batch: 748 / 937 Main Model Loss: 0.012474704 Interpreter Loss: 13383.408\n",
      "Epoch:[ 3 ] Batch: 749 / 937 Main Model Loss: 0.010287482 Interpreter Loss: 12839.994\n",
      "Epoch:[ 3 ] Batch: 750 / 937 Main Model Loss: 0.008883113 Interpreter Loss: 13763.051\n",
      "Epoch:[ 3 ] Batch: 751 / 937 Main Model Loss: 0.020862719 Interpreter Loss: 14463.192\n",
      "Epoch:[ 3 ] Batch: 752 / 937 Main Model Loss: 0.0021570018 Interpreter Loss: 13430.614\n",
      "Epoch:[ 3 ] Batch: 753 / 937 Main Model Loss: 0.0034811688 Interpreter Loss: 13263.09\n",
      "Epoch:[ 3 ] Batch: 754 / 937 Main Model Loss: 0.037860114 Interpreter Loss: 14351.658\n",
      "Epoch:[ 3 ] Batch: 755 / 937 Main Model Loss: 0.009908987 Interpreter Loss: 13709.866\n",
      "Epoch:[ 3 ] Batch: 756 / 937 Main Model Loss: 0.0016815665 Interpreter Loss: 13085.641\n",
      "Epoch:[ 3 ] Batch: 757 / 937 Main Model Loss: 0.0047500227 Interpreter Loss: 12806.623\n",
      "Epoch:[ 3 ] Batch: 758 / 937 Main Model Loss: 0.004291173 Interpreter Loss: 13248.372\n",
      "Epoch:[ 3 ] Batch: 759 / 937 Main Model Loss: 0.005512071 Interpreter Loss: 12821.145\n",
      "Epoch:[ 3 ] Batch: 760 / 937 Main Model Loss: 0.012877919 Interpreter Loss: 12942.571\n",
      "Epoch:[ 3 ] Batch: 761 / 937 Main Model Loss: 0.0022132965 Interpreter Loss: 12923.106\n",
      "Epoch:[ 3 ] Batch: 762 / 937 Main Model Loss: 0.004494859 Interpreter Loss: 13356.297\n",
      "Epoch:[ 3 ] Batch: 763 / 937 Main Model Loss: 0.005253017 Interpreter Loss: 12835.967\n",
      "Epoch:[ 3 ] Batch: 764 / 937 Main Model Loss: 0.013076274 Interpreter Loss: 11798.762\n",
      "Epoch:[ 3 ] Batch: 765 / 937 Main Model Loss: 0.007112773 Interpreter Loss: 13113.41\n",
      "Epoch:[ 3 ] Batch: 766 / 937 Main Model Loss: 0.0043401625 Interpreter Loss: 13376.491\n",
      "Epoch:[ 3 ] Batch: 767 / 937 Main Model Loss: 0.008191669 Interpreter Loss: 13244.164\n",
      "Epoch:[ 3 ] Batch: 768 / 937 Main Model Loss: 0.007009146 Interpreter Loss: 13227.557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 3 ] Batch: 769 / 937 Main Model Loss: 0.010742567 Interpreter Loss: 12812.224\n",
      "Epoch:[ 3 ] Batch: 770 / 937 Main Model Loss: 0.0034032054 Interpreter Loss: 12308.239\n",
      "Epoch:[ 3 ] Batch: 771 / 937 Main Model Loss: 0.003240046 Interpreter Loss: 12186.852\n",
      "Epoch:[ 3 ] Batch: 772 / 937 Main Model Loss: 0.053807218 Interpreter Loss: 12843.145\n",
      "Epoch:[ 3 ] Batch: 773 / 937 Main Model Loss: 0.013221711 Interpreter Loss: 13435.424\n",
      "Epoch:[ 3 ] Batch: 774 / 937 Main Model Loss: 0.019256797 Interpreter Loss: 13675.587\n",
      "Epoch:[ 3 ] Batch: 775 / 937 Main Model Loss: 0.0025957362 Interpreter Loss: 12444.847\n",
      "Epoch:[ 3 ] Batch: 776 / 937 Main Model Loss: 0.0016632064 Interpreter Loss: 11604.38\n",
      "Epoch:[ 3 ] Batch: 777 / 937 Main Model Loss: 0.03251184 Interpreter Loss: 13209.92\n",
      "Epoch:[ 3 ] Batch: 778 / 937 Main Model Loss: 0.0029477607 Interpreter Loss: 12011.96\n",
      "Epoch:[ 3 ] Batch: 779 / 937 Main Model Loss: 0.026115844 Interpreter Loss: 12784.956\n",
      "Epoch:[ 3 ] Batch: 780 / 937 Main Model Loss: 0.004577259 Interpreter Loss: 11593.059\n",
      "Epoch:[ 3 ] Batch: 781 / 937 Main Model Loss: 0.0023124402 Interpreter Loss: 11870.118\n",
      "Epoch:[ 3 ] Batch: 782 / 937 Main Model Loss: 0.018637711 Interpreter Loss: 12681.664\n",
      "Epoch:[ 3 ] Batch: 783 / 937 Main Model Loss: 0.021879237 Interpreter Loss: 12796.538\n",
      "Epoch:[ 3 ] Batch: 784 / 937 Main Model Loss: 0.0063562496 Interpreter Loss: 13379.506\n",
      "Epoch:[ 3 ] Batch: 785 / 937 Main Model Loss: 0.0011627204 Interpreter Loss: 12057.209\n",
      "Epoch:[ 3 ] Batch: 786 / 937 Main Model Loss: 0.034894183 Interpreter Loss: 13397.427\n",
      "Epoch:[ 3 ] Batch: 787 / 937 Main Model Loss: 0.020068742 Interpreter Loss: 13431.827\n",
      "Epoch:[ 3 ] Batch: 788 / 937 Main Model Loss: 0.0076706186 Interpreter Loss: 12635.419\n",
      "Epoch:[ 3 ] Batch: 789 / 937 Main Model Loss: 0.019372761 Interpreter Loss: 13318.593\n",
      "Epoch:[ 3 ] Batch: 790 / 937 Main Model Loss: 0.0060894755 Interpreter Loss: 12190.225\n",
      "Epoch:[ 3 ] Batch: 791 / 937 Main Model Loss: 0.0015403333 Interpreter Loss: 11979.336\n",
      "Epoch:[ 3 ] Batch: 792 / 937 Main Model Loss: 0.011149348 Interpreter Loss: 12960.655\n",
      "Epoch:[ 3 ] Batch: 793 / 937 Main Model Loss: 0.0019404968 Interpreter Loss: 12892.315\n",
      "Epoch:[ 3 ] Batch: 794 / 937 Main Model Loss: 0.010560264 Interpreter Loss: 12668.104\n",
      "Epoch:[ 3 ] Batch: 795 / 937 Main Model Loss: 0.03501914 Interpreter Loss: 13442.613\n",
      "Epoch:[ 3 ] Batch: 796 / 937 Main Model Loss: 0.010630788 Interpreter Loss: 12395.277\n",
      "Epoch:[ 3 ] Batch: 797 / 937 Main Model Loss: 0.0108186025 Interpreter Loss: 12156.215\n",
      "Epoch:[ 3 ] Batch: 798 / 937 Main Model Loss: 0.0014938659 Interpreter Loss: 12430.445\n",
      "Epoch:[ 3 ] Batch: 799 / 937 Main Model Loss: 0.012525338 Interpreter Loss: 13441.365\n",
      "Epoch:[ 3 ] Batch: 800 / 937 Main Model Loss: 0.1436883 Interpreter Loss: 13582.337\n",
      "Epoch:[ 3 ] Batch: 801 / 937 Main Model Loss: 0.0057405853 Interpreter Loss: 14096.553\n",
      "Epoch:[ 3 ] Batch: 802 / 937 Main Model Loss: 0.009467194 Interpreter Loss: 12877.945\n",
      "Epoch:[ 3 ] Batch: 803 / 937 Main Model Loss: 0.0034847253 Interpreter Loss: 12513.259\n",
      "Epoch:[ 3 ] Batch: 804 / 937 Main Model Loss: 0.0024298842 Interpreter Loss: 13351.685\n",
      "Epoch:[ 3 ] Batch: 805 / 937 Main Model Loss: 0.0064553125 Interpreter Loss: 12489.756\n",
      "Epoch:[ 3 ] Batch: 806 / 937 Main Model Loss: 0.0068751397 Interpreter Loss: 12684.229\n",
      "Epoch:[ 3 ] Batch: 807 / 937 Main Model Loss: 0.0036675557 Interpreter Loss: 12275.836\n",
      "Epoch:[ 3 ] Batch: 808 / 937 Main Model Loss: 0.0069881277 Interpreter Loss: 12119.728\n",
      "Epoch:[ 3 ] Batch: 809 / 937 Main Model Loss: 0.0040357863 Interpreter Loss: 12078.6045\n",
      "Epoch:[ 3 ] Batch: 810 / 937 Main Model Loss: 0.020707164 Interpreter Loss: 12190.469\n",
      "Epoch:[ 3 ] Batch: 811 / 937 Main Model Loss: 0.054485157 Interpreter Loss: 12408.595\n",
      "Epoch:[ 3 ] Batch: 812 / 937 Main Model Loss: 0.020289104 Interpreter Loss: 13520.578\n",
      "Epoch:[ 3 ] Batch: 813 / 937 Main Model Loss: 0.015284638 Interpreter Loss: 12008.148\n",
      "Epoch:[ 3 ] Batch: 814 / 937 Main Model Loss: 0.008836228 Interpreter Loss: 12981.271\n",
      "Epoch:[ 3 ] Batch: 815 / 937 Main Model Loss: 0.018696014 Interpreter Loss: 12298.416\n",
      "Epoch:[ 3 ] Batch: 816 / 937 Main Model Loss: 0.024078032 Interpreter Loss: 12550.789\n",
      "Epoch:[ 3 ] Batch: 817 / 937 Main Model Loss: 0.0036616416 Interpreter Loss: 12635.556\n",
      "Epoch:[ 3 ] Batch: 818 / 937 Main Model Loss: 0.0042241025 Interpreter Loss: 11958.56\n",
      "Epoch:[ 3 ] Batch: 819 / 937 Main Model Loss: 0.03042104 Interpreter Loss: 14392.841\n",
      "Epoch:[ 3 ] Batch: 820 / 937 Main Model Loss: 0.0059019225 Interpreter Loss: 12545.868\n",
      "Epoch:[ 3 ] Batch: 821 / 937 Main Model Loss: 0.0065791844 Interpreter Loss: 12492.043\n",
      "Epoch:[ 3 ] Batch: 822 / 937 Main Model Loss: 0.0031196554 Interpreter Loss: 12021.843\n",
      "Epoch:[ 3 ] Batch: 823 / 937 Main Model Loss: 0.007994087 Interpreter Loss: 12236.457\n",
      "Epoch:[ 3 ] Batch: 824 / 937 Main Model Loss: 0.0024133788 Interpreter Loss: 12133.085\n",
      "Epoch:[ 3 ] Batch: 825 / 937 Main Model Loss: 0.0068935924 Interpreter Loss: 14151.69\n",
      "Epoch:[ 3 ] Batch: 826 / 937 Main Model Loss: 0.028660737 Interpreter Loss: 13976.3\n",
      "Epoch:[ 3 ] Batch: 827 / 937 Main Model Loss: 0.025700895 Interpreter Loss: 15790.827\n",
      "Epoch:[ 3 ] Batch: 828 / 937 Main Model Loss: 0.0057982686 Interpreter Loss: 13133.5205\n",
      "Epoch:[ 3 ] Batch: 829 / 937 Main Model Loss: 0.010668318 Interpreter Loss: 13121.823\n",
      "Epoch:[ 3 ] Batch: 830 / 937 Main Model Loss: 0.0137386555 Interpreter Loss: 12754.196\n",
      "Epoch:[ 3 ] Batch: 831 / 937 Main Model Loss: 0.0045897025 Interpreter Loss: 13090.708\n",
      "Epoch:[ 3 ] Batch: 832 / 937 Main Model Loss: 0.0010838143 Interpreter Loss: 11978.22\n",
      "Epoch:[ 3 ] Batch: 833 / 937 Main Model Loss: 0.001335529 Interpreter Loss: 12094.533\n",
      "Epoch:[ 3 ] Batch: 834 / 937 Main Model Loss: 0.011027757 Interpreter Loss: 12924.308\n",
      "Epoch:[ 3 ] Batch: 835 / 937 Main Model Loss: 0.003725201 Interpreter Loss: 12518.273\n",
      "Epoch:[ 3 ] Batch: 836 / 937 Main Model Loss: 0.0010744436 Interpreter Loss: 12088.755\n",
      "Epoch:[ 3 ] Batch: 837 / 937 Main Model Loss: 0.0017609447 Interpreter Loss: 11778.731\n",
      "Epoch:[ 3 ] Batch: 838 / 937 Main Model Loss: 0.026853157 Interpreter Loss: 13045.891\n",
      "Epoch:[ 3 ] Batch: 839 / 937 Main Model Loss: 0.0049803676 Interpreter Loss: 12142.916\n",
      "Epoch:[ 3 ] Batch: 840 / 937 Main Model Loss: 0.010298271 Interpreter Loss: 11685.093\n",
      "Epoch:[ 3 ] Batch: 841 / 937 Main Model Loss: 0.011951088 Interpreter Loss: 12745.608\n",
      "Epoch:[ 3 ] Batch: 842 / 937 Main Model Loss: 0.0101164505 Interpreter Loss: 13179.878\n",
      "Epoch:[ 3 ] Batch: 843 / 937 Main Model Loss: 0.020277426 Interpreter Loss: 13146.113\n",
      "Epoch:[ 3 ] Batch: 844 / 937 Main Model Loss: 0.04240511 Interpreter Loss: 13583.156\n",
      "Epoch:[ 3 ] Batch: 845 / 937 Main Model Loss: 0.010711582 Interpreter Loss: 12403.036\n",
      "Epoch:[ 3 ] Batch: 846 / 937 Main Model Loss: 0.029609255 Interpreter Loss: 13022.904\n",
      "Epoch:[ 3 ] Batch: 847 / 937 Main Model Loss: 0.01123694 Interpreter Loss: 11480.963\n",
      "Epoch:[ 3 ] Batch: 848 / 937 Main Model Loss: 0.0036587436 Interpreter Loss: 12224.495\n",
      "Epoch:[ 3 ] Batch: 849 / 937 Main Model Loss: 0.0038966227 Interpreter Loss: 12834.238\n",
      "Epoch:[ 3 ] Batch: 850 / 937 Main Model Loss: 0.08175696 Interpreter Loss: 13180.981\n",
      "Epoch:[ 3 ] Batch: 851 / 937 Main Model Loss: 0.016533602 Interpreter Loss: 13336.827\n",
      "Epoch:[ 3 ] Batch: 852 / 937 Main Model Loss: 0.038063288 Interpreter Loss: 13089.401\n",
      "Epoch:[ 3 ] Batch: 853 / 937 Main Model Loss: 0.05249503 Interpreter Loss: 12858.524\n",
      "Epoch:[ 3 ] Batch: 854 / 937 Main Model Loss: 0.0022917949 Interpreter Loss: 12543.973\n",
      "Epoch:[ 3 ] Batch: 855 / 937 Main Model Loss: 0.02140245 Interpreter Loss: 13095.392\n",
      "Epoch:[ 3 ] Batch: 856 / 937 Main Model Loss: 0.002692635 Interpreter Loss: 12941.198\n",
      "Epoch:[ 3 ] Batch: 857 / 937 Main Model Loss: 0.031340476 Interpreter Loss: 12462.204\n",
      "Epoch:[ 3 ] Batch: 858 / 937 Main Model Loss: 0.004497226 Interpreter Loss: 12916.688\n",
      "Epoch:[ 3 ] Batch: 859 / 937 Main Model Loss: 0.0070365667 Interpreter Loss: 12750.691\n",
      "Epoch:[ 3 ] Batch: 860 / 937 Main Model Loss: 0.0025150678 Interpreter Loss: 12211.056\n",
      "Epoch:[ 3 ] Batch: 861 / 937 Main Model Loss: 0.003330897 Interpreter Loss: 12561.444\n",
      "Epoch:[ 3 ] Batch: 862 / 937 Main Model Loss: 0.014300833 Interpreter Loss: 13138.932\n",
      "Epoch:[ 3 ] Batch: 863 / 937 Main Model Loss: 0.0107439235 Interpreter Loss: 13227.538\n",
      "Epoch:[ 3 ] Batch: 864 / 937 Main Model Loss: 0.021301232 Interpreter Loss: 12474.304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 3 ] Batch: 865 / 937 Main Model Loss: 0.009050807 Interpreter Loss: 11986.887\n",
      "Epoch:[ 3 ] Batch: 866 / 937 Main Model Loss: 0.039891448 Interpreter Loss: 13579.779\n",
      "Epoch:[ 3 ] Batch: 867 / 937 Main Model Loss: 0.010615792 Interpreter Loss: 13600.496\n",
      "Epoch:[ 3 ] Batch: 868 / 937 Main Model Loss: 0.023496803 Interpreter Loss: 13190.002\n",
      "Epoch:[ 3 ] Batch: 869 / 937 Main Model Loss: 0.015665814 Interpreter Loss: 14615.645\n",
      "Epoch:[ 3 ] Batch: 870 / 937 Main Model Loss: 0.020371418 Interpreter Loss: 14739.23\n",
      "Epoch:[ 3 ] Batch: 871 / 937 Main Model Loss: 0.0026976194 Interpreter Loss: 13747.876\n",
      "Epoch:[ 3 ] Batch: 872 / 937 Main Model Loss: 0.006059191 Interpreter Loss: 12818.761\n",
      "Epoch:[ 3 ] Batch: 873 / 937 Main Model Loss: 0.0026166798 Interpreter Loss: 12775.146\n",
      "Epoch:[ 3 ] Batch: 874 / 937 Main Model Loss: 0.0025078198 Interpreter Loss: 12284.224\n",
      "Epoch:[ 3 ] Batch: 875 / 937 Main Model Loss: 0.0042999987 Interpreter Loss: 13157.713\n",
      "Epoch:[ 3 ] Batch: 876 / 937 Main Model Loss: 0.004149637 Interpreter Loss: 12503.568\n",
      "Epoch:[ 3 ] Batch: 877 / 937 Main Model Loss: 0.011440268 Interpreter Loss: 13088.453\n",
      "Epoch:[ 3 ] Batch: 878 / 937 Main Model Loss: 0.03836354 Interpreter Loss: 13390.422\n",
      "Epoch:[ 3 ] Batch: 879 / 937 Main Model Loss: 0.0051297275 Interpreter Loss: 12315.032\n",
      "Epoch:[ 3 ] Batch: 880 / 937 Main Model Loss: 0.008584349 Interpreter Loss: 11986.481\n",
      "Epoch:[ 3 ] Batch: 881 / 937 Main Model Loss: 0.0017501217 Interpreter Loss: 11642.743\n",
      "Epoch:[ 3 ] Batch: 882 / 937 Main Model Loss: 0.025764985 Interpreter Loss: 13005.447\n",
      "Epoch:[ 3 ] Batch: 883 / 937 Main Model Loss: 0.0067290775 Interpreter Loss: 12386.99\n",
      "Epoch:[ 3 ] Batch: 884 / 937 Main Model Loss: 0.005259093 Interpreter Loss: 12175.393\n",
      "Epoch:[ 3 ] Batch: 885 / 937 Main Model Loss: 0.0024241968 Interpreter Loss: 12069.165\n",
      "Epoch:[ 3 ] Batch: 886 / 937 Main Model Loss: 0.0030289218 Interpreter Loss: 13184.055\n",
      "Epoch:[ 3 ] Batch: 887 / 937 Main Model Loss: 0.023826784 Interpreter Loss: 13316.073\n",
      "Epoch:[ 3 ] Batch: 888 / 937 Main Model Loss: 0.0055340393 Interpreter Loss: 12716.721\n",
      "Epoch:[ 3 ] Batch: 889 / 937 Main Model Loss: 0.003002805 Interpreter Loss: 11929.784\n",
      "Epoch:[ 3 ] Batch: 890 / 937 Main Model Loss: 0.0015979074 Interpreter Loss: 11623.936\n",
      "Epoch:[ 3 ] Batch: 891 / 937 Main Model Loss: 0.01291015 Interpreter Loss: 12376.718\n",
      "Epoch:[ 3 ] Batch: 892 / 937 Main Model Loss: 0.0011598754 Interpreter Loss: 11419.483\n",
      "Epoch:[ 3 ] Batch: 893 / 937 Main Model Loss: 0.012018096 Interpreter Loss: 12170.687\n",
      "Epoch:[ 3 ] Batch: 894 / 937 Main Model Loss: 0.016762506 Interpreter Loss: 13156.7295\n",
      "Epoch:[ 3 ] Batch: 895 / 937 Main Model Loss: 0.0030271364 Interpreter Loss: 12360.3955\n",
      "Epoch:[ 3 ] Batch: 896 / 937 Main Model Loss: 0.007819735 Interpreter Loss: 12448.582\n",
      "Epoch:[ 3 ] Batch: 897 / 937 Main Model Loss: 0.0057627666 Interpreter Loss: 12136.74\n",
      "Epoch:[ 3 ] Batch: 898 / 937 Main Model Loss: 0.0164345 Interpreter Loss: 12973.01\n",
      "Epoch:[ 3 ] Batch: 899 / 937 Main Model Loss: 0.0053499057 Interpreter Loss: 12641.539\n",
      "Epoch:[ 3 ] Batch: 900 / 937 Main Model Loss: 0.009134529 Interpreter Loss: 12935.057\n",
      "Epoch:[ 3 ] Batch: 901 / 937 Main Model Loss: 0.06407275 Interpreter Loss: 11971.3125\n",
      "Epoch:[ 3 ] Batch: 902 / 937 Main Model Loss: 0.060936872 Interpreter Loss: 12877.296\n",
      "Epoch:[ 3 ] Batch: 903 / 937 Main Model Loss: 0.012999739 Interpreter Loss: 11268.316\n",
      "Epoch:[ 3 ] Batch: 904 / 937 Main Model Loss: 0.002696578 Interpreter Loss: 12259.898\n",
      "Epoch:[ 3 ] Batch: 905 / 937 Main Model Loss: 0.0035386854 Interpreter Loss: 11976.042\n",
      "Epoch:[ 3 ] Batch: 906 / 937 Main Model Loss: 0.009479123 Interpreter Loss: 12360.449\n",
      "Epoch:[ 3 ] Batch: 907 / 937 Main Model Loss: 0.038245864 Interpreter Loss: 11843.696\n",
      "Epoch:[ 3 ] Batch: 908 / 937 Main Model Loss: 0.0002651366 Interpreter Loss: 10896.566\n",
      "Epoch:[ 3 ] Batch: 909 / 937 Main Model Loss: 7.3445626e-05 Interpreter Loss: 11984.687\n",
      "Epoch:[ 3 ] Batch: 910 / 937 Main Model Loss: 0.00094647094 Interpreter Loss: 12248.096\n",
      "Epoch:[ 3 ] Batch: 911 / 937 Main Model Loss: 0.011216783 Interpreter Loss: 12796.908\n",
      "Epoch:[ 3 ] Batch: 912 / 937 Main Model Loss: 0.0043448987 Interpreter Loss: 12942.007\n",
      "Epoch:[ 3 ] Batch: 913 / 937 Main Model Loss: 0.001407565 Interpreter Loss: 12747.712\n",
      "Epoch:[ 3 ] Batch: 914 / 937 Main Model Loss: 0.00058014574 Interpreter Loss: 11337.582\n",
      "Epoch:[ 3 ] Batch: 915 / 937 Main Model Loss: 0.001085083 Interpreter Loss: 10788.919\n",
      "Epoch:[ 3 ] Batch: 916 / 937 Main Model Loss: 0.0042327037 Interpreter Loss: 10815.85\n",
      "Epoch:[ 3 ] Batch: 917 / 937 Main Model Loss: 0.0002731618 Interpreter Loss: 10350.134\n",
      "Epoch:[ 3 ] Batch: 918 / 937 Main Model Loss: 0.011448537 Interpreter Loss: 11916.85\n",
      "Epoch:[ 3 ] Batch: 919 / 937 Main Model Loss: 0.0023045714 Interpreter Loss: 13524.976\n",
      "Epoch:[ 3 ] Batch: 920 / 937 Main Model Loss: 0.00070633006 Interpreter Loss: 12041.196\n",
      "Epoch:[ 3 ] Batch: 921 / 937 Main Model Loss: 0.00011497275 Interpreter Loss: 12037.544\n",
      "Epoch:[ 3 ] Batch: 922 / 937 Main Model Loss: 0.0059770723 Interpreter Loss: 11791.537\n",
      "Epoch:[ 3 ] Batch: 923 / 937 Main Model Loss: 0.00018061798 Interpreter Loss: 11515.122\n",
      "Epoch:[ 3 ] Batch: 924 / 937 Main Model Loss: 0.0004908853 Interpreter Loss: 11838.202\n",
      "Epoch:[ 3 ] Batch: 925 / 937 Main Model Loss: 0.0006691193 Interpreter Loss: 12113.928\n",
      "Epoch:[ 3 ] Batch: 926 / 937 Main Model Loss: 0.0037217373 Interpreter Loss: 13124.249\n",
      "Epoch:[ 3 ] Batch: 927 / 937 Main Model Loss: 0.013547942 Interpreter Loss: 15411.373\n",
      "Epoch:[ 3 ] Batch: 928 / 937 Main Model Loss: 0.011668119 Interpreter Loss: 16502.469\n",
      "Epoch:[ 3 ] Batch: 929 / 937 Main Model Loss: 0.0006067526 Interpreter Loss: 13669.45\n",
      "Epoch:[ 3 ] Batch: 930 / 937 Main Model Loss: 0.013975216 Interpreter Loss: 11851.461\n",
      "Epoch:[ 3 ] Batch: 931 / 937 Main Model Loss: 0.0003900952 Interpreter Loss: 11811.287\n",
      "Epoch:[ 3 ] Batch: 932 / 937 Main Model Loss: 0.0049484456 Interpreter Loss: 13007.584\n",
      "Epoch:[ 3 ] Batch: 933 / 937 Main Model Loss: 0.012581624 Interpreter Loss: 15203.505\n",
      "Epoch:[ 3 ] Batch: 934 / 937 Main Model Loss: 0.0031375608 Interpreter Loss: 12758.499\n",
      "Epoch:[ 3 ] Batch: 935 / 937 Main Model Loss: 0.0008473953 Interpreter Loss: 12724.209\n",
      "Epoch:[ 3 ] Batch: 936 / 937 Main Model Loss: 0.09521764 Interpreter Loss: 11268.687\n",
      " Main Model Acc:  0.984375 Interpreter Acc:  0.71875\n",
      "INFO:tensorflow:Assets written to: checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 4 ] Batch: 0 / 937 Main Model Loss: 0.019272398 Interpreter Loss: 12202.569\n",
      "Epoch:[ 4 ] Batch: 1 / 937 Main Model Loss: 0.0051955455 Interpreter Loss: 12585.473\n",
      "Epoch:[ 4 ] Batch: 2 / 937 Main Model Loss: 0.017589608 Interpreter Loss: 13229.726\n",
      "Epoch:[ 4 ] Batch: 3 / 937 Main Model Loss: 0.0027417035 Interpreter Loss: 13195.184\n",
      "Epoch:[ 4 ] Batch: 4 / 937 Main Model Loss: 0.030979576 Interpreter Loss: 12303.983\n",
      "Epoch:[ 4 ] Batch: 5 / 937 Main Model Loss: 0.010254232 Interpreter Loss: 12153.252\n",
      "Epoch:[ 4 ] Batch: 6 / 937 Main Model Loss: 0.0064910296 Interpreter Loss: 12396.736\n",
      "Epoch:[ 4 ] Batch: 7 / 937 Main Model Loss: 0.014037506 Interpreter Loss: 12547.229\n",
      "Epoch:[ 4 ] Batch: 8 / 937 Main Model Loss: 0.027558234 Interpreter Loss: 12317.566\n",
      "Epoch:[ 4 ] Batch: 9 / 937 Main Model Loss: 0.0042872997 Interpreter Loss: 12116.159\n",
      "Epoch:[ 4 ] Batch: 10 / 937 Main Model Loss: 0.0044799303 Interpreter Loss: 12676.434\n",
      "Epoch:[ 4 ] Batch: 11 / 937 Main Model Loss: 0.025574148 Interpreter Loss: 13584.977\n",
      "Epoch:[ 4 ] Batch: 12 / 937 Main Model Loss: 0.025957527 Interpreter Loss: 12740.959\n",
      "Epoch:[ 4 ] Batch: 13 / 937 Main Model Loss: 0.0075683286 Interpreter Loss: 13452.521\n",
      "Epoch:[ 4 ] Batch: 14 / 937 Main Model Loss: 0.008123372 Interpreter Loss: 13386.295\n",
      "Epoch:[ 4 ] Batch: 15 / 937 Main Model Loss: 0.026590237 Interpreter Loss: 13255.567\n",
      "Epoch:[ 4 ] Batch: 16 / 937 Main Model Loss: 0.0063713607 Interpreter Loss: 12138.866\n",
      "Epoch:[ 4 ] Batch: 17 / 937 Main Model Loss: 0.022716912 Interpreter Loss: 12992.781\n",
      "Epoch:[ 4 ] Batch: 18 / 937 Main Model Loss: 0.0035613833 Interpreter Loss: 12754.548\n",
      "Epoch:[ 4 ] Batch: 19 / 937 Main Model Loss: 0.010415323 Interpreter Loss: 14062.699\n",
      "Epoch:[ 4 ] Batch: 20 / 937 Main Model Loss: 0.004331771 Interpreter Loss: 14173.054\n",
      "Epoch:[ 4 ] Batch: 21 / 937 Main Model Loss: 0.010495427 Interpreter Loss: 15183.08\n",
      "Epoch:[ 4 ] Batch: 22 / 937 Main Model Loss: 0.0026207424 Interpreter Loss: 12255.741\n",
      "Epoch:[ 4 ] Batch: 23 / 937 Main Model Loss: 0.012983019 Interpreter Loss: 12366.199\n",
      "Epoch:[ 4 ] Batch: 24 / 937 Main Model Loss: 0.002841919 Interpreter Loss: 12328.335\n",
      "Epoch:[ 4 ] Batch: 25 / 937 Main Model Loss: 0.02154008 Interpreter Loss: 12389.213\n",
      "Epoch:[ 4 ] Batch: 26 / 937 Main Model Loss: 0.0010686198 Interpreter Loss: 11635.502\n",
      "Epoch:[ 4 ] Batch: 27 / 937 Main Model Loss: 0.002520317 Interpreter Loss: 12905.051\n",
      "Epoch:[ 4 ] Batch: 28 / 937 Main Model Loss: 0.0015636361 Interpreter Loss: 11813.338\n",
      "Epoch:[ 4 ] Batch: 29 / 937 Main Model Loss: 0.006984465 Interpreter Loss: 12646.743\n",
      "Epoch:[ 4 ] Batch: 30 / 937 Main Model Loss: 0.053783678 Interpreter Loss: 13045.893\n",
      "Epoch:[ 4 ] Batch: 31 / 937 Main Model Loss: 0.022087222 Interpreter Loss: 14319.69\n",
      "Epoch:[ 4 ] Batch: 32 / 937 Main Model Loss: 0.001644399 Interpreter Loss: 12570.445\n",
      "Epoch:[ 4 ] Batch: 33 / 937 Main Model Loss: 0.002063104 Interpreter Loss: 12478.142\n",
      "Epoch:[ 4 ] Batch: 34 / 937 Main Model Loss: 0.0035439366 Interpreter Loss: 12294.235\n",
      "Epoch:[ 4 ] Batch: 35 / 937 Main Model Loss: 0.0009715546 Interpreter Loss: 12812.781\n",
      "Epoch:[ 4 ] Batch: 36 / 937 Main Model Loss: 0.01900304 Interpreter Loss: 12943.156\n",
      "Epoch:[ 4 ] Batch: 37 / 937 Main Model Loss: 0.0037931441 Interpreter Loss: 13347.986\n",
      "Epoch:[ 4 ] Batch: 38 / 937 Main Model Loss: 0.003940843 Interpreter Loss: 12114.451\n",
      "Epoch:[ 4 ] Batch: 39 / 937 Main Model Loss: 0.001558348 Interpreter Loss: 12373.184\n",
      "Epoch:[ 4 ] Batch: 40 / 937 Main Model Loss: 0.016747512 Interpreter Loss: 12877.619\n",
      "Epoch:[ 4 ] Batch: 41 / 937 Main Model Loss: 0.015528514 Interpreter Loss: 13469.476\n",
      "Epoch:[ 4 ] Batch: 42 / 937 Main Model Loss: 0.04293978 Interpreter Loss: 11981.461\n",
      "Epoch:[ 4 ] Batch: 43 / 937 Main Model Loss: 0.007520812 Interpreter Loss: 12506.2705\n",
      "Epoch:[ 4 ] Batch: 44 / 937 Main Model Loss: 0.0009166828 Interpreter Loss: 12576.877\n",
      "Epoch:[ 4 ] Batch: 45 / 937 Main Model Loss: 0.017470224 Interpreter Loss: 12721.063\n",
      "Epoch:[ 4 ] Batch: 46 / 937 Main Model Loss: 0.0029887082 Interpreter Loss: 11466.816\n",
      "Epoch:[ 4 ] Batch: 47 / 937 Main Model Loss: 0.0043804366 Interpreter Loss: 13089.52\n",
      "Epoch:[ 4 ] Batch: 48 / 937 Main Model Loss: 0.010661879 Interpreter Loss: 12244.033\n",
      "Epoch:[ 4 ] Batch: 49 / 937 Main Model Loss: 0.0009091464 Interpreter Loss: 11498.185\n",
      "Epoch:[ 4 ] Batch: 50 / 937 Main Model Loss: 0.0124234315 Interpreter Loss: 12236.873\n",
      "Epoch:[ 4 ] Batch: 51 / 937 Main Model Loss: 0.0038035002 Interpreter Loss: 12125.927\n",
      "Epoch:[ 4 ] Batch: 52 / 937 Main Model Loss: 0.0013003722 Interpreter Loss: 12221.026\n",
      "Epoch:[ 4 ] Batch: 53 / 937 Main Model Loss: 0.00538343 Interpreter Loss: 12002.718\n",
      "Epoch:[ 4 ] Batch: 54 / 937 Main Model Loss: 0.0054159323 Interpreter Loss: 12812.903\n",
      "Epoch:[ 4 ] Batch: 55 / 937 Main Model Loss: 0.0034667968 Interpreter Loss: 12359.12\n",
      "Epoch:[ 4 ] Batch: 56 / 937 Main Model Loss: 0.0028162752 Interpreter Loss: 12431.492\n",
      "Epoch:[ 4 ] Batch: 57 / 937 Main Model Loss: 0.0059035113 Interpreter Loss: 14585.234\n",
      "Epoch:[ 4 ] Batch: 58 / 937 Main Model Loss: 0.00909796 Interpreter Loss: 12467.519\n",
      "Epoch:[ 4 ] Batch: 59 / 937 Main Model Loss: 0.003602528 Interpreter Loss: 12604.354\n",
      "Epoch:[ 4 ] Batch: 60 / 937 Main Model Loss: 0.0007000929 Interpreter Loss: 12114.449\n",
      "Epoch:[ 4 ] Batch: 61 / 937 Main Model Loss: 0.002385273 Interpreter Loss: 11951.957\n",
      "Epoch:[ 4 ] Batch: 62 / 937 Main Model Loss: 0.004997634 Interpreter Loss: 12912.047\n",
      "Epoch:[ 4 ] Batch: 63 / 937 Main Model Loss: 0.0026816924 Interpreter Loss: 12636.4\n",
      "Epoch:[ 4 ] Batch: 64 / 937 Main Model Loss: 0.0116029335 Interpreter Loss: 12701.868\n",
      "Epoch:[ 4 ] Batch: 65 / 937 Main Model Loss: 0.0025846055 Interpreter Loss: 11760.243\n",
      "Epoch:[ 4 ] Batch: 66 / 937 Main Model Loss: 0.0011935536 Interpreter Loss: 12179.869\n",
      "Epoch:[ 4 ] Batch: 67 / 937 Main Model Loss: 0.009177302 Interpreter Loss: 12183.008\n",
      "Epoch:[ 4 ] Batch: 68 / 937 Main Model Loss: 0.014567197 Interpreter Loss: 12078.683\n",
      "Epoch:[ 4 ] Batch: 69 / 937 Main Model Loss: 0.091707535 Interpreter Loss: 12710.6\n",
      "Epoch:[ 4 ] Batch: 70 / 937 Main Model Loss: 0.0075622625 Interpreter Loss: 13019.023\n",
      "Epoch:[ 4 ] Batch: 71 / 937 Main Model Loss: 0.0014617998 Interpreter Loss: 11968.882\n",
      "Epoch:[ 4 ] Batch: 72 / 937 Main Model Loss: 0.0060761617 Interpreter Loss: 13334.012\n",
      "Epoch:[ 4 ] Batch: 73 / 937 Main Model Loss: 0.008502369 Interpreter Loss: 13632.068\n",
      "Epoch:[ 4 ] Batch: 74 / 937 Main Model Loss: 0.0012398998 Interpreter Loss: 12358.849\n",
      "Epoch:[ 4 ] Batch: 75 / 937 Main Model Loss: 0.006125079 Interpreter Loss: 13102.251\n",
      "Epoch:[ 4 ] Batch: 76 / 937 Main Model Loss: 0.0006901616 Interpreter Loss: 12258.514\n",
      "Epoch:[ 4 ] Batch: 77 / 937 Main Model Loss: 0.022485882 Interpreter Loss: 12261.555\n",
      "Epoch:[ 4 ] Batch: 78 / 937 Main Model Loss: 0.010652839 Interpreter Loss: 12519.899\n",
      "Epoch:[ 4 ] Batch: 79 / 937 Main Model Loss: 0.012576268 Interpreter Loss: 13514.694\n",
      "Epoch:[ 4 ] Batch: 80 / 937 Main Model Loss: 0.0057671466 Interpreter Loss: 13008.893\n",
      "Epoch:[ 4 ] Batch: 81 / 937 Main Model Loss: 0.0017629336 Interpreter Loss: 12374.256\n",
      "Epoch:[ 4 ] Batch: 82 / 937 Main Model Loss: 0.04626075 Interpreter Loss: 12736.671\n",
      "Epoch:[ 4 ] Batch: 83 / 937 Main Model Loss: 0.024523918 Interpreter Loss: 13977.968\n",
      "Epoch:[ 4 ] Batch: 84 / 937 Main Model Loss: 0.0064857253 Interpreter Loss: 13256.812\n",
      "Epoch:[ 4 ] Batch: 85 / 937 Main Model Loss: 0.010872525 Interpreter Loss: 13093.155\n",
      "Epoch:[ 4 ] Batch: 86 / 937 Main Model Loss: 0.020374462 Interpreter Loss: 13331.126\n",
      "Epoch:[ 4 ] Batch: 87 / 937 Main Model Loss: 0.0016674907 Interpreter Loss: 12537.45\n",
      "Epoch:[ 4 ] Batch: 88 / 937 Main Model Loss: 0.007090972 Interpreter Loss: 12463.237\n",
      "Epoch:[ 4 ] Batch: 89 / 937 Main Model Loss: 0.02175385 Interpreter Loss: 13541.525\n",
      "Epoch:[ 4 ] Batch: 90 / 937 Main Model Loss: 0.0109162005 Interpreter Loss: 12957.565\n",
      "Epoch:[ 4 ] Batch: 91 / 937 Main Model Loss: 0.0057802554 Interpreter Loss: 12209.967\n",
      "Epoch:[ 4 ] Batch: 92 / 937 Main Model Loss: 0.0072615133 Interpreter Loss: 12571.306\n",
      "Epoch:[ 4 ] Batch: 93 / 937 Main Model Loss: 0.0012284507 Interpreter Loss: 13568.178\n",
      "Epoch:[ 4 ] Batch: 94 / 937 Main Model Loss: 0.002795131 Interpreter Loss: 13639.955\n",
      "Epoch:[ 4 ] Batch: 95 / 937 Main Model Loss: 0.018226817 Interpreter Loss: 14626.635\n",
      "Epoch:[ 4 ] Batch: 96 / 937 Main Model Loss: 0.005323818 Interpreter Loss: 13152.393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 4 ] Batch: 97 / 937 Main Model Loss: 0.034219444 Interpreter Loss: 13466.946\n",
      "Epoch:[ 4 ] Batch: 98 / 937 Main Model Loss: 0.012814147 Interpreter Loss: 13397.52\n",
      "Epoch:[ 4 ] Batch: 99 / 937 Main Model Loss: 0.01258279 Interpreter Loss: 13017.053\n",
      "Epoch:[ 4 ] Batch: 100 / 937 Main Model Loss: 0.008602868 Interpreter Loss: 13499.252\n",
      "Epoch:[ 4 ] Batch: 101 / 937 Main Model Loss: 0.0023625032 Interpreter Loss: 12509.774\n",
      "Epoch:[ 4 ] Batch: 102 / 937 Main Model Loss: 0.00081589684 Interpreter Loss: 11394.1455\n",
      "Epoch:[ 4 ] Batch: 103 / 937 Main Model Loss: 0.0095774075 Interpreter Loss: 12535.59\n",
      "Epoch:[ 4 ] Batch: 104 / 937 Main Model Loss: 0.0067271097 Interpreter Loss: 11523.227\n",
      "Epoch:[ 4 ] Batch: 105 / 937 Main Model Loss: 0.0018469507 Interpreter Loss: 11421.592\n",
      "Epoch:[ 4 ] Batch: 106 / 937 Main Model Loss: 0.011848091 Interpreter Loss: 11521.944\n",
      "Epoch:[ 4 ] Batch: 107 / 937 Main Model Loss: 0.010131542 Interpreter Loss: 13634.321\n",
      "Epoch:[ 4 ] Batch: 108 / 937 Main Model Loss: 0.006474659 Interpreter Loss: 13104.328\n",
      "Epoch:[ 4 ] Batch: 109 / 937 Main Model Loss: 0.008876755 Interpreter Loss: 14348.289\n",
      "Epoch:[ 4 ] Batch: 110 / 937 Main Model Loss: 0.035585623 Interpreter Loss: 11498.615\n",
      "Epoch:[ 4 ] Batch: 111 / 937 Main Model Loss: 0.006261695 Interpreter Loss: 11858.026\n",
      "Epoch:[ 4 ] Batch: 112 / 937 Main Model Loss: 0.0046123536 Interpreter Loss: 11441.84\n",
      "Epoch:[ 4 ] Batch: 113 / 937 Main Model Loss: 0.020563263 Interpreter Loss: 13466.765\n",
      "Epoch:[ 4 ] Batch: 114 / 937 Main Model Loss: 0.007563128 Interpreter Loss: 10746.999\n",
      "Epoch:[ 4 ] Batch: 115 / 937 Main Model Loss: 0.005062928 Interpreter Loss: 11070.674\n",
      "Epoch:[ 4 ] Batch: 116 / 937 Main Model Loss: 0.0021182366 Interpreter Loss: 11597.913\n",
      "Epoch:[ 4 ] Batch: 117 / 937 Main Model Loss: 0.014250496 Interpreter Loss: 11516.539\n",
      "Epoch:[ 4 ] Batch: 118 / 937 Main Model Loss: 0.004792863 Interpreter Loss: 12229.709\n",
      "Epoch:[ 4 ] Batch: 119 / 937 Main Model Loss: 0.012263718 Interpreter Loss: 12669.263\n",
      "Epoch:[ 4 ] Batch: 120 / 937 Main Model Loss: 0.002735456 Interpreter Loss: 12530.435\n",
      "Epoch:[ 4 ] Batch: 121 / 937 Main Model Loss: 0.0030035465 Interpreter Loss: 12718.38\n",
      "Epoch:[ 4 ] Batch: 122 / 937 Main Model Loss: 0.0026073556 Interpreter Loss: 12421.408\n",
      "Epoch:[ 4 ] Batch: 123 / 937 Main Model Loss: 0.011129293 Interpreter Loss: 13536.132\n",
      "Epoch:[ 4 ] Batch: 124 / 937 Main Model Loss: 0.0037479969 Interpreter Loss: 13502.366\n",
      "Epoch:[ 4 ] Batch: 125 / 937 Main Model Loss: 0.007361915 Interpreter Loss: 12883.383\n",
      "Epoch:[ 4 ] Batch: 126 / 937 Main Model Loss: 0.009031004 Interpreter Loss: 13844.824\n",
      "Epoch:[ 4 ] Batch: 127 / 937 Main Model Loss: 0.0039623575 Interpreter Loss: 11229.153\n",
      "Epoch:[ 4 ] Batch: 128 / 937 Main Model Loss: 0.029547542 Interpreter Loss: 12975.0625\n",
      "Epoch:[ 4 ] Batch: 129 / 937 Main Model Loss: 0.044990934 Interpreter Loss: 13513.377\n",
      "Epoch:[ 4 ] Batch: 130 / 937 Main Model Loss: 0.005562731 Interpreter Loss: 12453.319\n",
      "Epoch:[ 4 ] Batch: 131 / 937 Main Model Loss: 0.010310443 Interpreter Loss: 12499.347\n",
      "Epoch:[ 4 ] Batch: 132 / 937 Main Model Loss: 0.015255608 Interpreter Loss: 14884.577\n",
      "Epoch:[ 4 ] Batch: 133 / 937 Main Model Loss: 0.0026592931 Interpreter Loss: 13147.139\n",
      "Epoch:[ 4 ] Batch: 134 / 937 Main Model Loss: 0.0068199947 Interpreter Loss: 13301.559\n",
      "Epoch:[ 4 ] Batch: 135 / 937 Main Model Loss: 0.017679853 Interpreter Loss: 13936.878\n",
      "Epoch:[ 4 ] Batch: 136 / 937 Main Model Loss: 0.01271633 Interpreter Loss: 14504.221\n",
      "Epoch:[ 4 ] Batch: 137 / 937 Main Model Loss: 0.0092412215 Interpreter Loss: 12676.575\n",
      "Epoch:[ 4 ] Batch: 138 / 937 Main Model Loss: 0.02653565 Interpreter Loss: 14161.378\n",
      "Epoch:[ 4 ] Batch: 139 / 937 Main Model Loss: 0.0026531147 Interpreter Loss: 12534.932\n",
      "Epoch:[ 4 ] Batch: 140 / 937 Main Model Loss: 0.005407505 Interpreter Loss: 12122.341\n",
      "Epoch:[ 4 ] Batch: 141 / 937 Main Model Loss: 0.00070226006 Interpreter Loss: 12163.296\n",
      "Epoch:[ 4 ] Batch: 142 / 937 Main Model Loss: 0.003505796 Interpreter Loss: 11778.015\n",
      "Epoch:[ 4 ] Batch: 143 / 937 Main Model Loss: 0.002007669 Interpreter Loss: 11908.643\n",
      "Epoch:[ 4 ] Batch: 144 / 937 Main Model Loss: 0.021038255 Interpreter Loss: 11613.6455\n",
      "Epoch:[ 4 ] Batch: 145 / 937 Main Model Loss: 0.013110516 Interpreter Loss: 12545.005\n",
      "Epoch:[ 4 ] Batch: 146 / 937 Main Model Loss: 0.0074276654 Interpreter Loss: 13060.754\n",
      "Epoch:[ 4 ] Batch: 147 / 937 Main Model Loss: 0.020720148 Interpreter Loss: 13043.243\n",
      "Epoch:[ 4 ] Batch: 148 / 937 Main Model Loss: 0.004183413 Interpreter Loss: 12901.863\n",
      "Epoch:[ 4 ] Batch: 149 / 937 Main Model Loss: 0.009502465 Interpreter Loss: 11989.243\n",
      "Epoch:[ 4 ] Batch: 150 / 937 Main Model Loss: 0.007689943 Interpreter Loss: 12539.025\n",
      "Epoch:[ 4 ] Batch: 151 / 937 Main Model Loss: 0.0042908303 Interpreter Loss: 12584.853\n",
      "Epoch:[ 4 ] Batch: 152 / 937 Main Model Loss: 0.0073593217 Interpreter Loss: 13180.888\n",
      "Epoch:[ 4 ] Batch: 153 / 937 Main Model Loss: 0.0013552764 Interpreter Loss: 11707.635\n",
      "Epoch:[ 4 ] Batch: 154 / 937 Main Model Loss: 0.00042302758 Interpreter Loss: 11631.035\n",
      "Epoch:[ 4 ] Batch: 155 / 937 Main Model Loss: 0.0015517436 Interpreter Loss: 11713.717\n",
      "Epoch:[ 4 ] Batch: 156 / 937 Main Model Loss: 0.001985159 Interpreter Loss: 13240.479\n",
      "Epoch:[ 4 ] Batch: 157 / 937 Main Model Loss: 0.005285854 Interpreter Loss: 11940.033\n",
      "Epoch:[ 4 ] Batch: 158 / 937 Main Model Loss: 0.007825004 Interpreter Loss: 11560.475\n",
      "Epoch:[ 4 ] Batch: 159 / 937 Main Model Loss: 0.009926554 Interpreter Loss: 15357.648\n",
      "Epoch:[ 4 ] Batch: 160 / 937 Main Model Loss: 0.019813204 Interpreter Loss: 15052.673\n",
      "Epoch:[ 4 ] Batch: 161 / 937 Main Model Loss: 0.0053882417 Interpreter Loss: 12944.363\n",
      "Epoch:[ 4 ] Batch: 162 / 937 Main Model Loss: 0.013884003 Interpreter Loss: 12830.082\n",
      "Epoch:[ 4 ] Batch: 163 / 937 Main Model Loss: 0.00057469285 Interpreter Loss: 12742.371\n",
      "Epoch:[ 4 ] Batch: 164 / 937 Main Model Loss: 0.0013058144 Interpreter Loss: 12322.653\n",
      "Epoch:[ 4 ] Batch: 165 / 937 Main Model Loss: 0.0023802274 Interpreter Loss: 11915.052\n",
      "Epoch:[ 4 ] Batch: 166 / 937 Main Model Loss: 0.0042925472 Interpreter Loss: 11190.671\n",
      "Epoch:[ 4 ] Batch: 167 / 937 Main Model Loss: 0.0019583947 Interpreter Loss: 11814.799\n",
      "Epoch:[ 4 ] Batch: 168 / 937 Main Model Loss: 0.025232576 Interpreter Loss: 12870.01\n",
      "Epoch:[ 4 ] Batch: 169 / 937 Main Model Loss: 0.0049989074 Interpreter Loss: 12594.573\n",
      "Epoch:[ 4 ] Batch: 170 / 937 Main Model Loss: 0.0032964365 Interpreter Loss: 12406.188\n",
      "Epoch:[ 4 ] Batch: 171 / 937 Main Model Loss: 0.038156036 Interpreter Loss: 13048.673\n",
      "Epoch:[ 4 ] Batch: 172 / 937 Main Model Loss: 0.0030212437 Interpreter Loss: 12929.39\n",
      "Epoch:[ 4 ] Batch: 173 / 937 Main Model Loss: 0.003392045 Interpreter Loss: 12034.846\n",
      "Epoch:[ 4 ] Batch: 174 / 937 Main Model Loss: 0.04890409 Interpreter Loss: 12915.236\n",
      "Epoch:[ 4 ] Batch: 175 / 937 Main Model Loss: 0.011351397 Interpreter Loss: 12302.163\n",
      "Epoch:[ 4 ] Batch: 176 / 937 Main Model Loss: 0.00039853546 Interpreter Loss: 11458.45\n",
      "Epoch:[ 4 ] Batch: 177 / 937 Main Model Loss: 0.0059162606 Interpreter Loss: 12170.489\n",
      "Epoch:[ 4 ] Batch: 178 / 937 Main Model Loss: 0.0018330897 Interpreter Loss: 11885.862\n",
      "Epoch:[ 4 ] Batch: 179 / 937 Main Model Loss: 0.0027209802 Interpreter Loss: 11954.17\n",
      "Epoch:[ 4 ] Batch: 180 / 937 Main Model Loss: 0.013961556 Interpreter Loss: 12416.273\n",
      "Epoch:[ 4 ] Batch: 181 / 937 Main Model Loss: 0.0085896645 Interpreter Loss: 12577.82\n",
      "Epoch:[ 4 ] Batch: 182 / 937 Main Model Loss: 0.012971312 Interpreter Loss: 13136.382\n",
      "Epoch:[ 4 ] Batch: 183 / 937 Main Model Loss: 0.0027959212 Interpreter Loss: 12201.885\n",
      "Epoch:[ 4 ] Batch: 184 / 937 Main Model Loss: 0.05143304 Interpreter Loss: 12968.795\n",
      "Epoch:[ 4 ] Batch: 185 / 937 Main Model Loss: 0.009099279 Interpreter Loss: 12894.124\n",
      "Epoch:[ 4 ] Batch: 186 / 937 Main Model Loss: 0.004692048 Interpreter Loss: 12282.145\n",
      "Epoch:[ 4 ] Batch: 187 / 937 Main Model Loss: 0.0027558708 Interpreter Loss: 12771.008\n",
      "Epoch:[ 4 ] Batch: 188 / 937 Main Model Loss: 0.005467018 Interpreter Loss: 12742.496\n",
      "Epoch:[ 4 ] Batch: 189 / 937 Main Model Loss: 0.0048984056 Interpreter Loss: 12294.785\n",
      "Epoch:[ 4 ] Batch: 190 / 937 Main Model Loss: 0.001187216 Interpreter Loss: 12696.352\n",
      "Epoch:[ 4 ] Batch: 191 / 937 Main Model Loss: 0.009214425 Interpreter Loss: 12922.498\n",
      "Epoch:[ 4 ] Batch: 192 / 937 Main Model Loss: 0.0042597204 Interpreter Loss: 12960.67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 4 ] Batch: 193 / 937 Main Model Loss: 0.0016856843 Interpreter Loss: 13273.006\n",
      "Epoch:[ 4 ] Batch: 194 / 937 Main Model Loss: 0.002690997 Interpreter Loss: 12819.466\n",
      "Epoch:[ 4 ] Batch: 195 / 937 Main Model Loss: 0.0030271946 Interpreter Loss: 12456.285\n",
      "Epoch:[ 4 ] Batch: 196 / 937 Main Model Loss: 0.005813434 Interpreter Loss: 12995.918\n",
      "Epoch:[ 4 ] Batch: 197 / 937 Main Model Loss: 0.0055454085 Interpreter Loss: 13461.983\n",
      "Epoch:[ 4 ] Batch: 198 / 937 Main Model Loss: 0.002214924 Interpreter Loss: 12524.322\n",
      "Epoch:[ 4 ] Batch: 199 / 937 Main Model Loss: 0.0024929028 Interpreter Loss: 11607.298\n",
      "Epoch:[ 4 ] Batch: 200 / 937 Main Model Loss: 0.0028261035 Interpreter Loss: 11557.127\n",
      "Epoch:[ 4 ] Batch: 201 / 937 Main Model Loss: 0.0140847415 Interpreter Loss: 12910.768\n",
      "Epoch:[ 4 ] Batch: 202 / 937 Main Model Loss: 0.006344223 Interpreter Loss: 14376.103\n",
      "Epoch:[ 4 ] Batch: 203 / 937 Main Model Loss: 0.0075075715 Interpreter Loss: 14488.763\n",
      "Epoch:[ 4 ] Batch: 204 / 937 Main Model Loss: 0.0095901545 Interpreter Loss: 14036.563\n",
      "Epoch:[ 4 ] Batch: 205 / 937 Main Model Loss: 0.0076185586 Interpreter Loss: 12707.451\n",
      "Epoch:[ 4 ] Batch: 206 / 937 Main Model Loss: 0.009329402 Interpreter Loss: 12925.029\n",
      "Epoch:[ 4 ] Batch: 207 / 937 Main Model Loss: 0.0021078575 Interpreter Loss: 12471.219\n",
      "Epoch:[ 4 ] Batch: 208 / 937 Main Model Loss: 0.0022149545 Interpreter Loss: 12541.067\n",
      "Epoch:[ 4 ] Batch: 209 / 937 Main Model Loss: 0.015540933 Interpreter Loss: 13065.156\n",
      "Epoch:[ 4 ] Batch: 210 / 937 Main Model Loss: 0.0029786415 Interpreter Loss: 12673.908\n",
      "Epoch:[ 4 ] Batch: 211 / 937 Main Model Loss: 0.021268 Interpreter Loss: 15412.146\n",
      "Epoch:[ 4 ] Batch: 212 / 937 Main Model Loss: 0.0052092234 Interpreter Loss: 12392.675\n",
      "Epoch:[ 4 ] Batch: 213 / 937 Main Model Loss: 0.0056088325 Interpreter Loss: 12019.287\n",
      "Epoch:[ 4 ] Batch: 214 / 937 Main Model Loss: 0.0036358135 Interpreter Loss: 12179.248\n",
      "Epoch:[ 4 ] Batch: 215 / 937 Main Model Loss: 0.060932945 Interpreter Loss: 12000.561\n",
      "Epoch:[ 4 ] Batch: 216 / 937 Main Model Loss: 0.00982114 Interpreter Loss: 12300.769\n",
      "Epoch:[ 4 ] Batch: 217 / 937 Main Model Loss: 0.0027579616 Interpreter Loss: 12305.492\n",
      "Epoch:[ 4 ] Batch: 218 / 937 Main Model Loss: 0.0035777208 Interpreter Loss: 13295.298\n",
      "Epoch:[ 4 ] Batch: 219 / 937 Main Model Loss: 0.0039724316 Interpreter Loss: 13232.661\n",
      "Epoch:[ 4 ] Batch: 220 / 937 Main Model Loss: 0.0030812782 Interpreter Loss: 13307.992\n",
      "Epoch:[ 4 ] Batch: 221 / 937 Main Model Loss: 0.0023062367 Interpreter Loss: 13484.369\n",
      "Epoch:[ 4 ] Batch: 222 / 937 Main Model Loss: 0.0024542145 Interpreter Loss: 13020.654\n",
      "Epoch:[ 4 ] Batch: 223 / 937 Main Model Loss: 0.0075416835 Interpreter Loss: 12930.395\n",
      "Epoch:[ 4 ] Batch: 224 / 937 Main Model Loss: 0.07178205 Interpreter Loss: 14022.258\n",
      "Epoch:[ 4 ] Batch: 225 / 937 Main Model Loss: 0.016579445 Interpreter Loss: 11848.582\n",
      "Epoch:[ 4 ] Batch: 226 / 937 Main Model Loss: 0.0011946543 Interpreter Loss: 11520.393\n",
      "Epoch:[ 4 ] Batch: 227 / 937 Main Model Loss: 0.033809725 Interpreter Loss: 12607.139\n",
      "Epoch:[ 4 ] Batch: 228 / 937 Main Model Loss: 0.001995237 Interpreter Loss: 12304.503\n",
      "Epoch:[ 4 ] Batch: 229 / 937 Main Model Loss: 0.008410202 Interpreter Loss: 13099.883\n",
      "Epoch:[ 4 ] Batch: 230 / 937 Main Model Loss: 0.025892772 Interpreter Loss: 13247.43\n",
      "Epoch:[ 4 ] Batch: 231 / 937 Main Model Loss: 0.0062714866 Interpreter Loss: 13275.311\n",
      "Epoch:[ 4 ] Batch: 232 / 937 Main Model Loss: 0.0030262216 Interpreter Loss: 12007.229\n",
      "Epoch:[ 4 ] Batch: 233 / 937 Main Model Loss: 0.0010856823 Interpreter Loss: 11630.429\n",
      "Epoch:[ 4 ] Batch: 234 / 937 Main Model Loss: 0.00040943167 Interpreter Loss: 11044.969\n",
      "Epoch:[ 4 ] Batch: 235 / 937 Main Model Loss: 0.0051273736 Interpreter Loss: 12234.392\n",
      "Epoch:[ 4 ] Batch: 236 / 937 Main Model Loss: 0.007862251 Interpreter Loss: 12061.943\n",
      "Epoch:[ 4 ] Batch: 237 / 937 Main Model Loss: 0.005808493 Interpreter Loss: 11584.312\n",
      "Epoch:[ 4 ] Batch: 238 / 937 Main Model Loss: 0.0016409006 Interpreter Loss: 12009.219\n",
      "Epoch:[ 4 ] Batch: 239 / 937 Main Model Loss: 0.009791108 Interpreter Loss: 11838.956\n",
      "Epoch:[ 4 ] Batch: 240 / 937 Main Model Loss: 0.0136121325 Interpreter Loss: 11900.725\n",
      "Epoch:[ 4 ] Batch: 241 / 937 Main Model Loss: 0.011706195 Interpreter Loss: 12002.1\n",
      "Epoch:[ 4 ] Batch: 242 / 937 Main Model Loss: 0.0047181137 Interpreter Loss: 12031.025\n",
      "Epoch:[ 4 ] Batch: 243 / 937 Main Model Loss: 0.0050154417 Interpreter Loss: 11685.231\n",
      "Epoch:[ 4 ] Batch: 244 / 937 Main Model Loss: 0.003868163 Interpreter Loss: 11871.352\n",
      "Epoch:[ 4 ] Batch: 245 / 937 Main Model Loss: 0.006696515 Interpreter Loss: 11984.144\n",
      "Epoch:[ 4 ] Batch: 246 / 937 Main Model Loss: 0.012756905 Interpreter Loss: 13083.77\n",
      "Epoch:[ 4 ] Batch: 247 / 937 Main Model Loss: 0.0034085682 Interpreter Loss: 11888.789\n",
      "Epoch:[ 4 ] Batch: 248 / 937 Main Model Loss: 0.028041026 Interpreter Loss: 12590.572\n",
      "Epoch:[ 4 ] Batch: 249 / 937 Main Model Loss: 0.005030571 Interpreter Loss: 12698.973\n",
      "Epoch:[ 4 ] Batch: 250 / 937 Main Model Loss: 0.0204225 Interpreter Loss: 13122.249\n",
      "Epoch:[ 4 ] Batch: 251 / 937 Main Model Loss: 0.0041505545 Interpreter Loss: 12805.063\n",
      "Epoch:[ 4 ] Batch: 252 / 937 Main Model Loss: 0.017175749 Interpreter Loss: 12803.339\n",
      "Epoch:[ 4 ] Batch: 253 / 937 Main Model Loss: 0.009145499 Interpreter Loss: 12360.082\n",
      "Epoch:[ 4 ] Batch: 254 / 937 Main Model Loss: 0.0010248976 Interpreter Loss: 11850.892\n",
      "Epoch:[ 4 ] Batch: 255 / 937 Main Model Loss: 0.0013750829 Interpreter Loss: 12565.427\n",
      "Epoch:[ 4 ] Batch: 256 / 937 Main Model Loss: 0.0070090066 Interpreter Loss: 11771.724\n",
      "Epoch:[ 4 ] Batch: 257 / 937 Main Model Loss: 0.0020046644 Interpreter Loss: 12556.695\n",
      "Epoch:[ 4 ] Batch: 258 / 937 Main Model Loss: 0.001973276 Interpreter Loss: 11852.716\n",
      "Epoch:[ 4 ] Batch: 259 / 937 Main Model Loss: 0.0011433371 Interpreter Loss: 11298.788\n",
      "Epoch:[ 4 ] Batch: 260 / 937 Main Model Loss: 0.020275207 Interpreter Loss: 12834.683\n",
      "Epoch:[ 4 ] Batch: 261 / 937 Main Model Loss: 0.002741212 Interpreter Loss: 12470.672\n",
      "Epoch:[ 4 ] Batch: 262 / 937 Main Model Loss: 0.001985977 Interpreter Loss: 12000.63\n",
      "Epoch:[ 4 ] Batch: 263 / 937 Main Model Loss: 0.0145919025 Interpreter Loss: 12155.842\n",
      "Epoch:[ 4 ] Batch: 264 / 937 Main Model Loss: 0.008954539 Interpreter Loss: 11761.24\n",
      "Epoch:[ 4 ] Batch: 265 / 937 Main Model Loss: 0.0041425964 Interpreter Loss: 12465.849\n",
      "Epoch:[ 4 ] Batch: 266 / 937 Main Model Loss: 0.0045617432 Interpreter Loss: 11775.951\n",
      "Epoch:[ 4 ] Batch: 267 / 937 Main Model Loss: 0.009266775 Interpreter Loss: 12692.175\n",
      "Epoch:[ 4 ] Batch: 268 / 937 Main Model Loss: 0.008114959 Interpreter Loss: 12779.407\n",
      "Epoch:[ 4 ] Batch: 269 / 937 Main Model Loss: 0.005516813 Interpreter Loss: 13213.358\n",
      "Epoch:[ 4 ] Batch: 270 / 937 Main Model Loss: 0.002462996 Interpreter Loss: 12668.606\n",
      "Epoch:[ 4 ] Batch: 271 / 937 Main Model Loss: 0.009146707 Interpreter Loss: 11834.497\n",
      "Epoch:[ 4 ] Batch: 272 / 937 Main Model Loss: 0.028855884 Interpreter Loss: 12451.219\n",
      "Epoch:[ 4 ] Batch: 273 / 937 Main Model Loss: 0.0014129953 Interpreter Loss: 12139.129\n",
      "Epoch:[ 4 ] Batch: 274 / 937 Main Model Loss: 0.04187322 Interpreter Loss: 12734.462\n",
      "Epoch:[ 4 ] Batch: 275 / 937 Main Model Loss: 0.0016355519 Interpreter Loss: 11298.9375\n",
      "Epoch:[ 4 ] Batch: 276 / 937 Main Model Loss: 0.003791668 Interpreter Loss: 11946.434\n",
      "Epoch:[ 4 ] Batch: 277 / 937 Main Model Loss: 0.016912213 Interpreter Loss: 12325.312\n",
      "Epoch:[ 4 ] Batch: 278 / 937 Main Model Loss: 0.025697654 Interpreter Loss: 12201.163\n",
      "Epoch:[ 4 ] Batch: 279 / 937 Main Model Loss: 0.003142676 Interpreter Loss: 11081.283\n",
      "Epoch:[ 4 ] Batch: 280 / 937 Main Model Loss: 0.0040845117 Interpreter Loss: 12048.03\n",
      "Epoch:[ 4 ] Batch: 281 / 937 Main Model Loss: 0.02264509 Interpreter Loss: 13359.773\n",
      "Epoch:[ 4 ] Batch: 282 / 937 Main Model Loss: 0.014300685 Interpreter Loss: 11685.705\n",
      "Epoch:[ 4 ] Batch: 283 / 937 Main Model Loss: 0.056858666 Interpreter Loss: 12703.637\n",
      "Epoch:[ 4 ] Batch: 284 / 937 Main Model Loss: 0.00622312 Interpreter Loss: 12459.07\n",
      "Epoch:[ 4 ] Batch: 285 / 937 Main Model Loss: 0.0010257964 Interpreter Loss: 11533.385\n",
      "Epoch:[ 4 ] Batch: 286 / 937 Main Model Loss: 0.010408733 Interpreter Loss: 12908.314\n",
      "Epoch:[ 4 ] Batch: 287 / 937 Main Model Loss: 0.019725509 Interpreter Loss: 12565.365\n",
      "Epoch:[ 4 ] Batch: 288 / 937 Main Model Loss: 0.00067002693 Interpreter Loss: 11659.591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 4 ] Batch: 289 / 937 Main Model Loss: 0.0022189983 Interpreter Loss: 11997.649\n",
      "Epoch:[ 4 ] Batch: 290 / 937 Main Model Loss: 0.023714243 Interpreter Loss: 12811.826\n",
      "Epoch:[ 4 ] Batch: 291 / 937 Main Model Loss: 0.0015223264 Interpreter Loss: 12170.38\n",
      "Epoch:[ 4 ] Batch: 292 / 937 Main Model Loss: 0.005985649 Interpreter Loss: 12664.663\n",
      "Epoch:[ 4 ] Batch: 293 / 937 Main Model Loss: 0.0039983615 Interpreter Loss: 11733.743\n",
      "Epoch:[ 4 ] Batch: 294 / 937 Main Model Loss: 0.0036445544 Interpreter Loss: 11566.174\n",
      "Epoch:[ 4 ] Batch: 295 / 937 Main Model Loss: 0.004280143 Interpreter Loss: 11915.255\n",
      "Epoch:[ 4 ] Batch: 296 / 937 Main Model Loss: 0.0046300828 Interpreter Loss: 11663.212\n",
      "Epoch:[ 4 ] Batch: 297 / 937 Main Model Loss: 0.0011856599 Interpreter Loss: 11143.646\n",
      "Epoch:[ 4 ] Batch: 298 / 937 Main Model Loss: 0.0190008 Interpreter Loss: 12824.49\n",
      "Epoch:[ 4 ] Batch: 299 / 937 Main Model Loss: 0.0023680264 Interpreter Loss: 11567.039\n",
      "Epoch:[ 4 ] Batch: 300 / 937 Main Model Loss: 0.041569203 Interpreter Loss: 13221.075\n",
      "Epoch:[ 4 ] Batch: 301 / 937 Main Model Loss: 0.0054493337 Interpreter Loss: 12534.102\n",
      "Epoch:[ 4 ] Batch: 302 / 937 Main Model Loss: 0.02656288 Interpreter Loss: 14531.465\n",
      "Epoch:[ 4 ] Batch: 303 / 937 Main Model Loss: 0.0019463091 Interpreter Loss: 12420.174\n",
      "Epoch:[ 4 ] Batch: 304 / 937 Main Model Loss: 0.012461773 Interpreter Loss: 14225.203\n",
      "Epoch:[ 4 ] Batch: 305 / 937 Main Model Loss: 0.0037794332 Interpreter Loss: 13125.943\n",
      "Epoch:[ 4 ] Batch: 306 / 937 Main Model Loss: 0.0046971836 Interpreter Loss: 12883.143\n",
      "Epoch:[ 4 ] Batch: 307 / 937 Main Model Loss: 0.0007935862 Interpreter Loss: 12411.365\n",
      "Epoch:[ 4 ] Batch: 308 / 937 Main Model Loss: 0.0020037957 Interpreter Loss: 12398.04\n",
      "Epoch:[ 4 ] Batch: 309 / 937 Main Model Loss: 0.004122062 Interpreter Loss: 13106.173\n",
      "Epoch:[ 4 ] Batch: 310 / 937 Main Model Loss: 0.067615256 Interpreter Loss: 13157.225\n",
      "Epoch:[ 4 ] Batch: 311 / 937 Main Model Loss: 0.0011028171 Interpreter Loss: 13054.0\n",
      "Epoch:[ 4 ] Batch: 312 / 937 Main Model Loss: 0.0034193918 Interpreter Loss: 13050.177\n",
      "Epoch:[ 4 ] Batch: 313 / 937 Main Model Loss: 0.025943372 Interpreter Loss: 13078.061\n",
      "Epoch:[ 4 ] Batch: 314 / 937 Main Model Loss: 0.0027505641 Interpreter Loss: 12636.6\n",
      "Epoch:[ 4 ] Batch: 315 / 937 Main Model Loss: 0.007444989 Interpreter Loss: 13238.149\n",
      "Epoch:[ 4 ] Batch: 316 / 937 Main Model Loss: 0.010589402 Interpreter Loss: 11945.511\n",
      "Epoch:[ 4 ] Batch: 317 / 937 Main Model Loss: 0.01563336 Interpreter Loss: 11686.433\n",
      "Epoch:[ 4 ] Batch: 318 / 937 Main Model Loss: 0.0020491146 Interpreter Loss: 12078.07\n",
      "Epoch:[ 4 ] Batch: 319 / 937 Main Model Loss: 0.007467815 Interpreter Loss: 11485.79\n",
      "Epoch:[ 4 ] Batch: 320 / 937 Main Model Loss: 0.0017679363 Interpreter Loss: 12399.178\n",
      "Epoch:[ 4 ] Batch: 321 / 937 Main Model Loss: 0.0014597224 Interpreter Loss: 11917.7705\n",
      "Epoch:[ 4 ] Batch: 322 / 937 Main Model Loss: 0.0058565363 Interpreter Loss: 13275.211\n",
      "Epoch:[ 4 ] Batch: 323 / 937 Main Model Loss: 0.010230484 Interpreter Loss: 13238.686\n",
      "Epoch:[ 4 ] Batch: 324 / 937 Main Model Loss: 0.012488207 Interpreter Loss: 12472.5205\n",
      "Epoch:[ 4 ] Batch: 325 / 937 Main Model Loss: 0.0032613159 Interpreter Loss: 12613.281\n",
      "Epoch:[ 4 ] Batch: 326 / 937 Main Model Loss: 0.016732581 Interpreter Loss: 12672.758\n",
      "Epoch:[ 4 ] Batch: 327 / 937 Main Model Loss: 0.005256847 Interpreter Loss: 12932.871\n",
      "Epoch:[ 4 ] Batch: 328 / 937 Main Model Loss: 0.049984176 Interpreter Loss: 11846.482\n",
      "Epoch:[ 4 ] Batch: 329 / 937 Main Model Loss: 0.0017085415 Interpreter Loss: 11072.229\n",
      "Epoch:[ 4 ] Batch: 330 / 937 Main Model Loss: 0.06274861 Interpreter Loss: 12545.358\n",
      "Epoch:[ 4 ] Batch: 331 / 937 Main Model Loss: 0.0011377342 Interpreter Loss: 11508.907\n",
      "Epoch:[ 4 ] Batch: 332 / 937 Main Model Loss: 0.001889286 Interpreter Loss: 12047.181\n",
      "Epoch:[ 4 ] Batch: 333 / 937 Main Model Loss: 0.0018905995 Interpreter Loss: 11995.002\n",
      "Epoch:[ 4 ] Batch: 334 / 937 Main Model Loss: 0.004176041 Interpreter Loss: 12297.083\n",
      "Epoch:[ 4 ] Batch: 335 / 937 Main Model Loss: 0.011705003 Interpreter Loss: 12728.828\n",
      "Epoch:[ 4 ] Batch: 336 / 937 Main Model Loss: 0.0088965325 Interpreter Loss: 12579.541\n",
      "Epoch:[ 4 ] Batch: 337 / 937 Main Model Loss: 0.0062342775 Interpreter Loss: 12231.941\n",
      "Epoch:[ 4 ] Batch: 338 / 937 Main Model Loss: 0.0076775164 Interpreter Loss: 11770.808\n",
      "Epoch:[ 4 ] Batch: 339 / 937 Main Model Loss: 0.014952846 Interpreter Loss: 11428.699\n",
      "Epoch:[ 4 ] Batch: 340 / 937 Main Model Loss: 0.007354527 Interpreter Loss: 13189.066\n",
      "Epoch:[ 4 ] Batch: 341 / 937 Main Model Loss: 0.0016766586 Interpreter Loss: 12775.075\n",
      "Epoch:[ 4 ] Batch: 342 / 937 Main Model Loss: 0.010992971 Interpreter Loss: 13347.163\n",
      "Epoch:[ 4 ] Batch: 343 / 937 Main Model Loss: 0.0020979205 Interpreter Loss: 12837.259\n",
      "Epoch:[ 4 ] Batch: 344 / 937 Main Model Loss: 0.0021998049 Interpreter Loss: 12077.385\n",
      "Epoch:[ 4 ] Batch: 345 / 937 Main Model Loss: 0.012209887 Interpreter Loss: 12412.087\n",
      "Epoch:[ 4 ] Batch: 346 / 937 Main Model Loss: 0.000855429 Interpreter Loss: 12046.909\n",
      "Epoch:[ 4 ] Batch: 347 / 937 Main Model Loss: 0.021093894 Interpreter Loss: 12707.446\n",
      "Epoch:[ 4 ] Batch: 348 / 937 Main Model Loss: 0.0041786428 Interpreter Loss: 11751.195\n",
      "Epoch:[ 4 ] Batch: 349 / 937 Main Model Loss: 0.0041813627 Interpreter Loss: 11736.799\n",
      "Epoch:[ 4 ] Batch: 350 / 937 Main Model Loss: 0.0026635928 Interpreter Loss: 11641.001\n",
      "Epoch:[ 4 ] Batch: 351 / 937 Main Model Loss: 0.0082423445 Interpreter Loss: 12580.546\n",
      "Epoch:[ 4 ] Batch: 352 / 937 Main Model Loss: 0.00874217 Interpreter Loss: 13013.469\n",
      "Epoch:[ 4 ] Batch: 353 / 937 Main Model Loss: 0.006495889 Interpreter Loss: 13324.083\n",
      "Epoch:[ 4 ] Batch: 354 / 937 Main Model Loss: 0.0057901363 Interpreter Loss: 13303.608\n",
      "Epoch:[ 4 ] Batch: 355 / 937 Main Model Loss: 0.016996121 Interpreter Loss: 12988.755\n",
      "Epoch:[ 4 ] Batch: 356 / 937 Main Model Loss: 0.008720077 Interpreter Loss: 12532.596\n",
      "Epoch:[ 4 ] Batch: 357 / 937 Main Model Loss: 0.006464931 Interpreter Loss: 12442.025\n",
      "Epoch:[ 4 ] Batch: 358 / 937 Main Model Loss: 0.00031879605 Interpreter Loss: 12359.313\n",
      "Epoch:[ 4 ] Batch: 359 / 937 Main Model Loss: 0.040596895 Interpreter Loss: 13422.41\n",
      "Epoch:[ 4 ] Batch: 360 / 937 Main Model Loss: 0.008222934 Interpreter Loss: 14004.116\n",
      "Epoch:[ 4 ] Batch: 361 / 937 Main Model Loss: 0.0060999105 Interpreter Loss: 12487.686\n",
      "Epoch:[ 4 ] Batch: 362 / 937 Main Model Loss: 0.0035819302 Interpreter Loss: 11915.893\n",
      "Epoch:[ 4 ] Batch: 363 / 937 Main Model Loss: 0.0015285983 Interpreter Loss: 11786.774\n",
      "Epoch:[ 4 ] Batch: 364 / 937 Main Model Loss: 0.0007591767 Interpreter Loss: 12125.461\n",
      "Epoch:[ 4 ] Batch: 365 / 937 Main Model Loss: 0.01574361 Interpreter Loss: 12416.364\n",
      "Epoch:[ 4 ] Batch: 366 / 937 Main Model Loss: 0.0036469824 Interpreter Loss: 11889.513\n",
      "Epoch:[ 4 ] Batch: 367 / 937 Main Model Loss: 0.0040210113 Interpreter Loss: 11492.576\n",
      "Epoch:[ 4 ] Batch: 368 / 937 Main Model Loss: 0.011673059 Interpreter Loss: 11902.379\n",
      "Epoch:[ 4 ] Batch: 369 / 937 Main Model Loss: 0.0020789145 Interpreter Loss: 11261.582\n",
      "Epoch:[ 4 ] Batch: 370 / 937 Main Model Loss: 0.018654373 Interpreter Loss: 12487.738\n",
      "Epoch:[ 4 ] Batch: 371 / 937 Main Model Loss: 0.039603524 Interpreter Loss: 13167.93\n",
      "Epoch:[ 4 ] Batch: 372 / 937 Main Model Loss: 0.0046280227 Interpreter Loss: 13021.908\n",
      "Epoch:[ 4 ] Batch: 373 / 937 Main Model Loss: 0.01781975 Interpreter Loss: 12653.088\n",
      "Epoch:[ 4 ] Batch: 374 / 937 Main Model Loss: 0.012712381 Interpreter Loss: 12553.16\n",
      "Epoch:[ 4 ] Batch: 375 / 937 Main Model Loss: 0.0023790179 Interpreter Loss: 12715.482\n",
      "Epoch:[ 4 ] Batch: 376 / 937 Main Model Loss: 0.006199689 Interpreter Loss: 12401.124\n",
      "Epoch:[ 4 ] Batch: 377 / 937 Main Model Loss: 0.0069508003 Interpreter Loss: 11831.404\n",
      "Epoch:[ 4 ] Batch: 378 / 937 Main Model Loss: 0.0032080398 Interpreter Loss: 11950.82\n",
      "Epoch:[ 4 ] Batch: 379 / 937 Main Model Loss: 0.0013390345 Interpreter Loss: 12290.4\n",
      "Epoch:[ 4 ] Batch: 380 / 937 Main Model Loss: 0.00057306467 Interpreter Loss: 10871.039\n",
      "Epoch:[ 4 ] Batch: 381 / 937 Main Model Loss: 0.009330047 Interpreter Loss: 12647.607\n",
      "Epoch:[ 4 ] Batch: 382 / 937 Main Model Loss: 0.015514759 Interpreter Loss: 12371.042\n",
      "Epoch:[ 4 ] Batch: 383 / 937 Main Model Loss: 0.014559802 Interpreter Loss: 11855.182\n",
      "Epoch:[ 4 ] Batch: 384 / 937 Main Model Loss: 0.00443246 Interpreter Loss: 12327.763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 4 ] Batch: 385 / 937 Main Model Loss: 0.0066706226 Interpreter Loss: 12782.072\n",
      "Epoch:[ 4 ] Batch: 386 / 937 Main Model Loss: 0.0013887589 Interpreter Loss: 11869.236\n",
      "Epoch:[ 4 ] Batch: 387 / 937 Main Model Loss: 0.009271158 Interpreter Loss: 13135.203\n",
      "Epoch:[ 4 ] Batch: 388 / 937 Main Model Loss: 0.002414873 Interpreter Loss: 12455.936\n",
      "Epoch:[ 4 ] Batch: 389 / 937 Main Model Loss: 0.00570646 Interpreter Loss: 10625.675\n",
      "Epoch:[ 4 ] Batch: 390 / 937 Main Model Loss: 0.00038926137 Interpreter Loss: 11782.176\n",
      "Epoch:[ 4 ] Batch: 391 / 937 Main Model Loss: 0.0011878598 Interpreter Loss: 11535.218\n",
      "Epoch:[ 4 ] Batch: 392 / 937 Main Model Loss: 0.013734043 Interpreter Loss: 12155.57\n",
      "Epoch:[ 4 ] Batch: 393 / 937 Main Model Loss: 0.0032249845 Interpreter Loss: 11911.412\n",
      "Epoch:[ 4 ] Batch: 394 / 937 Main Model Loss: 0.0022960533 Interpreter Loss: 11406.88\n",
      "Epoch:[ 4 ] Batch: 395 / 937 Main Model Loss: 0.0038890974 Interpreter Loss: 14931.423\n",
      "Epoch:[ 4 ] Batch: 396 / 937 Main Model Loss: 0.0022353288 Interpreter Loss: 12976.917\n",
      "Epoch:[ 4 ] Batch: 397 / 937 Main Model Loss: 0.0006012297 Interpreter Loss: 12187.473\n",
      "Epoch:[ 4 ] Batch: 398 / 937 Main Model Loss: 0.003278011 Interpreter Loss: 12677.117\n",
      "Epoch:[ 4 ] Batch: 399 / 937 Main Model Loss: 0.0147634465 Interpreter Loss: 12350.938\n",
      "Epoch:[ 4 ] Batch: 400 / 937 Main Model Loss: 0.00785594 Interpreter Loss: 11741.416\n",
      "Epoch:[ 4 ] Batch: 401 / 937 Main Model Loss: 0.0013816558 Interpreter Loss: 12852.019\n",
      "Epoch:[ 4 ] Batch: 402 / 937 Main Model Loss: 0.013914683 Interpreter Loss: 11766.068\n",
      "Epoch:[ 4 ] Batch: 403 / 937 Main Model Loss: 0.007902714 Interpreter Loss: 11979.6\n",
      "Epoch:[ 4 ] Batch: 404 / 937 Main Model Loss: 0.0020827209 Interpreter Loss: 10580.596\n",
      "Epoch:[ 4 ] Batch: 405 / 937 Main Model Loss: 0.0040026237 Interpreter Loss: 11133.404\n",
      "Epoch:[ 4 ] Batch: 406 / 937 Main Model Loss: 0.00056683697 Interpreter Loss: 12260.304\n",
      "Epoch:[ 4 ] Batch: 407 / 937 Main Model Loss: 0.010384548 Interpreter Loss: 12412.677\n",
      "Epoch:[ 4 ] Batch: 408 / 937 Main Model Loss: 0.0028894925 Interpreter Loss: 11689.675\n",
      "Epoch:[ 4 ] Batch: 409 / 937 Main Model Loss: 0.0074358806 Interpreter Loss: 11931.689\n",
      "Epoch:[ 4 ] Batch: 410 / 937 Main Model Loss: 0.0030524794 Interpreter Loss: 11541.283\n",
      "Epoch:[ 4 ] Batch: 411 / 937 Main Model Loss: 0.013580823 Interpreter Loss: 11641.354\n",
      "Epoch:[ 4 ] Batch: 412 / 937 Main Model Loss: 0.017188607 Interpreter Loss: 13648.95\n",
      "Epoch:[ 4 ] Batch: 413 / 937 Main Model Loss: 0.0012673213 Interpreter Loss: 11413.52\n",
      "Epoch:[ 4 ] Batch: 414 / 937 Main Model Loss: 0.018614803 Interpreter Loss: 11907.572\n",
      "Epoch:[ 4 ] Batch: 415 / 937 Main Model Loss: 0.0156289 Interpreter Loss: 13754.25\n",
      "Epoch:[ 4 ] Batch: 416 / 937 Main Model Loss: 0.023672404 Interpreter Loss: 13654.95\n",
      "Epoch:[ 4 ] Batch: 417 / 937 Main Model Loss: 0.029116089 Interpreter Loss: 13776.682\n",
      "Epoch:[ 4 ] Batch: 418 / 937 Main Model Loss: 0.0043550134 Interpreter Loss: 12568.853\n",
      "Epoch:[ 4 ] Batch: 419 / 937 Main Model Loss: 0.022752007 Interpreter Loss: 13394.846\n",
      "Epoch:[ 4 ] Batch: 420 / 937 Main Model Loss: 0.0041351262 Interpreter Loss: 11575.432\n",
      "Epoch:[ 4 ] Batch: 421 / 937 Main Model Loss: 0.0028410524 Interpreter Loss: 11139.278\n",
      "Epoch:[ 4 ] Batch: 422 / 937 Main Model Loss: 0.0041733137 Interpreter Loss: 12074.798\n",
      "Epoch:[ 4 ] Batch: 423 / 937 Main Model Loss: 0.0011395655 Interpreter Loss: 12639.844\n",
      "Epoch:[ 4 ] Batch: 424 / 937 Main Model Loss: 0.0071702376 Interpreter Loss: 13125.88\n",
      "Epoch:[ 4 ] Batch: 425 / 937 Main Model Loss: 0.010685997 Interpreter Loss: 12874.277\n",
      "Epoch:[ 4 ] Batch: 426 / 937 Main Model Loss: 0.013481041 Interpreter Loss: 13165.842\n",
      "Epoch:[ 4 ] Batch: 427 / 937 Main Model Loss: 0.009465817 Interpreter Loss: 11809.922\n",
      "Epoch:[ 4 ] Batch: 428 / 937 Main Model Loss: 0.003639314 Interpreter Loss: 12413.771\n",
      "Epoch:[ 4 ] Batch: 429 / 937 Main Model Loss: 0.022575522 Interpreter Loss: 11738.239\n",
      "Epoch:[ 4 ] Batch: 430 / 937 Main Model Loss: 0.006220497 Interpreter Loss: 12019.523\n",
      "Epoch:[ 4 ] Batch: 431 / 937 Main Model Loss: 0.0045322427 Interpreter Loss: 11723.761\n",
      "Epoch:[ 4 ] Batch: 432 / 937 Main Model Loss: 0.0122741265 Interpreter Loss: 11499.592\n",
      "Epoch:[ 4 ] Batch: 433 / 937 Main Model Loss: 0.001673387 Interpreter Loss: 11616.926\n",
      "Epoch:[ 4 ] Batch: 434 / 937 Main Model Loss: 0.006535408 Interpreter Loss: 12085.968\n",
      "Epoch:[ 4 ] Batch: 435 / 937 Main Model Loss: 0.0018610227 Interpreter Loss: 13322.685\n",
      "Epoch:[ 4 ] Batch: 436 / 937 Main Model Loss: 0.003866455 Interpreter Loss: 12452.621\n",
      "Epoch:[ 4 ] Batch: 437 / 937 Main Model Loss: 0.0049896794 Interpreter Loss: 12937.293\n",
      "Epoch:[ 4 ] Batch: 438 / 937 Main Model Loss: 0.002343358 Interpreter Loss: 12173.6875\n",
      "Epoch:[ 4 ] Batch: 439 / 937 Main Model Loss: 0.092740335 Interpreter Loss: 16015.967\n",
      "Epoch:[ 4 ] Batch: 440 / 937 Main Model Loss: 0.008816214 Interpreter Loss: 13128.266\n",
      "Epoch:[ 4 ] Batch: 441 / 937 Main Model Loss: 0.0022703013 Interpreter Loss: 12483.708\n",
      "Epoch:[ 4 ] Batch: 442 / 937 Main Model Loss: 0.001335334 Interpreter Loss: 12285.603\n",
      "Epoch:[ 4 ] Batch: 443 / 937 Main Model Loss: 0.035253823 Interpreter Loss: 14029.204\n",
      "Epoch:[ 4 ] Batch: 444 / 937 Main Model Loss: 0.002800378 Interpreter Loss: 12838.561\n",
      "Epoch:[ 4 ] Batch: 445 / 937 Main Model Loss: 0.0017511467 Interpreter Loss: 12650.547\n",
      "Epoch:[ 4 ] Batch: 446 / 937 Main Model Loss: 0.004314848 Interpreter Loss: 12733.827\n",
      "Epoch:[ 4 ] Batch: 447 / 937 Main Model Loss: 0.07340298 Interpreter Loss: 12397.128\n",
      "Epoch:[ 4 ] Batch: 448 / 937 Main Model Loss: 0.011340076 Interpreter Loss: 12836.908\n",
      "Epoch:[ 4 ] Batch: 449 / 937 Main Model Loss: 0.00063099584 Interpreter Loss: 11908.605\n",
      "Epoch:[ 4 ] Batch: 450 / 937 Main Model Loss: 0.0023991526 Interpreter Loss: 11768.409\n",
      "Epoch:[ 4 ] Batch: 451 / 937 Main Model Loss: 0.0004711802 Interpreter Loss: 12391.132\n",
      "Epoch:[ 4 ] Batch: 452 / 937 Main Model Loss: 0.012638576 Interpreter Loss: 12922.072\n",
      "Epoch:[ 4 ] Batch: 453 / 937 Main Model Loss: 0.002987593 Interpreter Loss: 12873.395\n",
      "Epoch:[ 4 ] Batch: 454 / 937 Main Model Loss: 0.008795996 Interpreter Loss: 11773.691\n",
      "Epoch:[ 4 ] Batch: 455 / 937 Main Model Loss: 0.009477455 Interpreter Loss: 12032.026\n",
      "Epoch:[ 4 ] Batch: 456 / 937 Main Model Loss: 0.0107111875 Interpreter Loss: 12057.254\n",
      "Epoch:[ 4 ] Batch: 457 / 937 Main Model Loss: 0.0032485067 Interpreter Loss: 12868.8125\n",
      "Epoch:[ 4 ] Batch: 458 / 937 Main Model Loss: 0.012238784 Interpreter Loss: 12921.02\n",
      "Epoch:[ 4 ] Batch: 459 / 937 Main Model Loss: 0.0022075197 Interpreter Loss: 13152.976\n",
      "Epoch:[ 4 ] Batch: 460 / 937 Main Model Loss: 0.0008463416 Interpreter Loss: 13073.063\n",
      "Epoch:[ 4 ] Batch: 461 / 937 Main Model Loss: 0.007617566 Interpreter Loss: 11572.973\n",
      "Epoch:[ 4 ] Batch: 462 / 937 Main Model Loss: 0.007025555 Interpreter Loss: 12261.379\n",
      "Epoch:[ 4 ] Batch: 463 / 937 Main Model Loss: 0.0036150892 Interpreter Loss: 11488.701\n",
      "Epoch:[ 4 ] Batch: 464 / 937 Main Model Loss: 0.011692191 Interpreter Loss: 12265.447\n",
      "Epoch:[ 4 ] Batch: 465 / 937 Main Model Loss: 0.0008055725 Interpreter Loss: 11034.068\n",
      "Epoch:[ 4 ] Batch: 466 / 937 Main Model Loss: 0.009765968 Interpreter Loss: 11727.0\n",
      "Epoch:[ 4 ] Batch: 467 / 937 Main Model Loss: 0.0049370117 Interpreter Loss: 11728.953\n",
      "Epoch:[ 4 ] Batch: 468 / 937 Main Model Loss: 0.0036732706 Interpreter Loss: 11310.095\n",
      "Epoch:[ 4 ] Batch: 469 / 937 Main Model Loss: 0.005355506 Interpreter Loss: 12503.503\n",
      "Epoch:[ 4 ] Batch: 470 / 937 Main Model Loss: 0.0024749825 Interpreter Loss: 11827.232\n",
      "Epoch:[ 4 ] Batch: 471 / 937 Main Model Loss: 0.0058402163 Interpreter Loss: 12478.158\n",
      "Epoch:[ 4 ] Batch: 472 / 937 Main Model Loss: 0.0021196199 Interpreter Loss: 11398.66\n",
      "Epoch:[ 4 ] Batch: 473 / 937 Main Model Loss: 0.0020681776 Interpreter Loss: 11478.928\n",
      "Epoch:[ 4 ] Batch: 474 / 937 Main Model Loss: 0.0034021058 Interpreter Loss: 11915.266\n",
      "Epoch:[ 4 ] Batch: 475 / 937 Main Model Loss: 0.0022361288 Interpreter Loss: 12047.824\n",
      "Epoch:[ 4 ] Batch: 476 / 937 Main Model Loss: 0.010924151 Interpreter Loss: 12728.124\n",
      "Epoch:[ 4 ] Batch: 477 / 937 Main Model Loss: 0.056449916 Interpreter Loss: 13709.659\n",
      "Epoch:[ 4 ] Batch: 478 / 937 Main Model Loss: 0.006833692 Interpreter Loss: 10969.186\n",
      "Epoch:[ 4 ] Batch: 479 / 937 Main Model Loss: 0.0025542087 Interpreter Loss: 10598.965\n",
      "Epoch:[ 4 ] Batch: 480 / 937 Main Model Loss: 0.00097425363 Interpreter Loss: 10529.147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 4 ] Batch: 481 / 937 Main Model Loss: 0.011289332 Interpreter Loss: 12261.437\n",
      "Epoch:[ 4 ] Batch: 482 / 937 Main Model Loss: 0.019875046 Interpreter Loss: 11931.842\n",
      "Epoch:[ 4 ] Batch: 483 / 937 Main Model Loss: 0.027928766 Interpreter Loss: 11646.977\n",
      "Epoch:[ 4 ] Batch: 484 / 937 Main Model Loss: 0.004681261 Interpreter Loss: 11754.241\n",
      "Epoch:[ 4 ] Batch: 485 / 937 Main Model Loss: 0.011705456 Interpreter Loss: 11741.016\n",
      "Epoch:[ 4 ] Batch: 486 / 937 Main Model Loss: 0.0036643692 Interpreter Loss: 11618.891\n",
      "Epoch:[ 4 ] Batch: 487 / 937 Main Model Loss: 0.0102129085 Interpreter Loss: 11988.918\n",
      "Epoch:[ 4 ] Batch: 488 / 937 Main Model Loss: 0.0044585513 Interpreter Loss: 11947.087\n",
      "Epoch:[ 4 ] Batch: 489 / 937 Main Model Loss: 0.004523275 Interpreter Loss: 12110.451\n",
      "Epoch:[ 4 ] Batch: 490 / 937 Main Model Loss: 0.053778306 Interpreter Loss: 12524.223\n",
      "Epoch:[ 4 ] Batch: 491 / 937 Main Model Loss: 0.0038576936 Interpreter Loss: 11481.409\n",
      "Epoch:[ 4 ] Batch: 492 / 937 Main Model Loss: 0.0013785554 Interpreter Loss: 10717.578\n",
      "Epoch:[ 4 ] Batch: 493 / 937 Main Model Loss: 0.06586655 Interpreter Loss: 12212.454\n",
      "Epoch:[ 4 ] Batch: 494 / 937 Main Model Loss: 0.0064012352 Interpreter Loss: 11602.98\n",
      "Epoch:[ 4 ] Batch: 495 / 937 Main Model Loss: 0.005370482 Interpreter Loss: 13711.188\n",
      "Epoch:[ 4 ] Batch: 496 / 937 Main Model Loss: 0.007941554 Interpreter Loss: 11618.089\n",
      "Epoch:[ 4 ] Batch: 497 / 937 Main Model Loss: 0.048205607 Interpreter Loss: 12006.11\n",
      "Epoch:[ 4 ] Batch: 498 / 937 Main Model Loss: 0.0023286967 Interpreter Loss: 11492.744\n",
      "Epoch:[ 4 ] Batch: 499 / 937 Main Model Loss: 0.0033566158 Interpreter Loss: 12228.999\n",
      "Epoch:[ 4 ] Batch: 500 / 937 Main Model Loss: 0.038546152 Interpreter Loss: 12858.357\n",
      "Epoch:[ 4 ] Batch: 501 / 937 Main Model Loss: 0.037912726 Interpreter Loss: 12627.634\n",
      "Epoch:[ 4 ] Batch: 502 / 937 Main Model Loss: 0.0061609903 Interpreter Loss: 12755.279\n",
      "Epoch:[ 4 ] Batch: 503 / 937 Main Model Loss: 0.043989304 Interpreter Loss: 12580.517\n",
      "Epoch:[ 4 ] Batch: 504 / 937 Main Model Loss: 0.007888624 Interpreter Loss: 13164.696\n",
      "Epoch:[ 4 ] Batch: 505 / 937 Main Model Loss: 0.004349983 Interpreter Loss: 14208.287\n",
      "Epoch:[ 4 ] Batch: 506 / 937 Main Model Loss: 0.015865915 Interpreter Loss: 14353.861\n",
      "Epoch:[ 4 ] Batch: 507 / 937 Main Model Loss: 0.012330536 Interpreter Loss: 13735.084\n",
      "Epoch:[ 4 ] Batch: 508 / 937 Main Model Loss: 0.006953812 Interpreter Loss: 12295.068\n",
      "Epoch:[ 4 ] Batch: 509 / 937 Main Model Loss: 0.0018617068 Interpreter Loss: 11383.935\n",
      "Epoch:[ 4 ] Batch: 510 / 937 Main Model Loss: 0.015744569 Interpreter Loss: 11791.689\n",
      "Epoch:[ 4 ] Batch: 511 / 937 Main Model Loss: 0.026565248 Interpreter Loss: 11329.149\n",
      "Epoch:[ 4 ] Batch: 512 / 937 Main Model Loss: 0.011381161 Interpreter Loss: 12108.414\n",
      "Epoch:[ 4 ] Batch: 513 / 937 Main Model Loss: 0.012765692 Interpreter Loss: 12057.486\n",
      "Epoch:[ 4 ] Batch: 514 / 937 Main Model Loss: 0.0010555066 Interpreter Loss: 11890.169\n",
      "Epoch:[ 4 ] Batch: 515 / 937 Main Model Loss: 0.00032663267 Interpreter Loss: 12059.392\n",
      "Epoch:[ 4 ] Batch: 516 / 937 Main Model Loss: 0.0017562425 Interpreter Loss: 13049.798\n",
      "Epoch:[ 4 ] Batch: 517 / 937 Main Model Loss: 0.00066823617 Interpreter Loss: 11807.567\n",
      "Epoch:[ 4 ] Batch: 518 / 937 Main Model Loss: 0.0022139295 Interpreter Loss: 12508.899\n",
      "Epoch:[ 4 ] Batch: 519 / 937 Main Model Loss: 0.002692411 Interpreter Loss: 12173.95\n",
      "Epoch:[ 4 ] Batch: 520 / 937 Main Model Loss: 0.028248565 Interpreter Loss: 13201.537\n",
      "Epoch:[ 4 ] Batch: 521 / 937 Main Model Loss: 0.0027212715 Interpreter Loss: 11742.324\n",
      "Epoch:[ 4 ] Batch: 522 / 937 Main Model Loss: 0.027338464 Interpreter Loss: 12637.353\n",
      "Epoch:[ 4 ] Batch: 523 / 937 Main Model Loss: 0.011841341 Interpreter Loss: 11576.898\n",
      "Epoch:[ 4 ] Batch: 524 / 937 Main Model Loss: 0.002042617 Interpreter Loss: 11389.406\n",
      "Epoch:[ 4 ] Batch: 525 / 937 Main Model Loss: 0.008518397 Interpreter Loss: 11084.234\n",
      "Epoch:[ 4 ] Batch: 526 / 937 Main Model Loss: 0.0084999865 Interpreter Loss: 12073.002\n",
      "Epoch:[ 4 ] Batch: 527 / 937 Main Model Loss: 0.0015128594 Interpreter Loss: 12634.91\n",
      "Epoch:[ 4 ] Batch: 528 / 937 Main Model Loss: 0.0019578307 Interpreter Loss: 12602.2705\n",
      "Epoch:[ 4 ] Batch: 529 / 937 Main Model Loss: 0.00087517675 Interpreter Loss: 11556.609\n",
      "Epoch:[ 4 ] Batch: 530 / 937 Main Model Loss: 0.0026746932 Interpreter Loss: 11524.706\n",
      "Epoch:[ 4 ] Batch: 531 / 937 Main Model Loss: 0.001754387 Interpreter Loss: 10854.48\n",
      "Epoch:[ 4 ] Batch: 532 / 937 Main Model Loss: 0.017904766 Interpreter Loss: 12560.91\n",
      "Epoch:[ 4 ] Batch: 533 / 937 Main Model Loss: 0.023857303 Interpreter Loss: 12026.076\n",
      "Epoch:[ 4 ] Batch: 534 / 937 Main Model Loss: 0.0007077843 Interpreter Loss: 11651.547\n",
      "Epoch:[ 4 ] Batch: 535 / 937 Main Model Loss: 0.0011107749 Interpreter Loss: 10899.845\n",
      "Epoch:[ 4 ] Batch: 536 / 937 Main Model Loss: 0.009133067 Interpreter Loss: 12329.3\n",
      "Epoch:[ 4 ] Batch: 537 / 937 Main Model Loss: 0.019339388 Interpreter Loss: 13836.669\n",
      "Epoch:[ 4 ] Batch: 538 / 937 Main Model Loss: 0.0025542756 Interpreter Loss: 12121.459\n",
      "Epoch:[ 4 ] Batch: 539 / 937 Main Model Loss: 0.025368093 Interpreter Loss: 12751.583\n",
      "Epoch:[ 4 ] Batch: 540 / 937 Main Model Loss: 0.0035690519 Interpreter Loss: 11954.475\n",
      "Epoch:[ 4 ] Batch: 541 / 937 Main Model Loss: 0.010010003 Interpreter Loss: 13706.26\n",
      "Epoch:[ 4 ] Batch: 542 / 937 Main Model Loss: 0.021280026 Interpreter Loss: 12874.803\n",
      "Epoch:[ 4 ] Batch: 543 / 937 Main Model Loss: 0.0065075965 Interpreter Loss: 12418.54\n",
      "Epoch:[ 4 ] Batch: 544 / 937 Main Model Loss: 0.013319319 Interpreter Loss: 12677.493\n",
      "Epoch:[ 4 ] Batch: 545 / 937 Main Model Loss: 0.028665308 Interpreter Loss: 12237.197\n",
      "Epoch:[ 4 ] Batch: 546 / 937 Main Model Loss: 0.004936386 Interpreter Loss: 11740.286\n",
      "Epoch:[ 4 ] Batch: 547 / 937 Main Model Loss: 0.015044479 Interpreter Loss: 13204.489\n",
      "Epoch:[ 4 ] Batch: 548 / 937 Main Model Loss: 0.0033528195 Interpreter Loss: 11774.284\n",
      "Epoch:[ 4 ] Batch: 549 / 937 Main Model Loss: 0.07791679 Interpreter Loss: 11703.183\n",
      "Epoch:[ 4 ] Batch: 550 / 937 Main Model Loss: 0.086356044 Interpreter Loss: 11502.674\n",
      "Epoch:[ 4 ] Batch: 551 / 937 Main Model Loss: 0.048537835 Interpreter Loss: 12163.694\n",
      "Epoch:[ 4 ] Batch: 552 / 937 Main Model Loss: 0.004207546 Interpreter Loss: 12147.304\n",
      "Epoch:[ 4 ] Batch: 553 / 937 Main Model Loss: 0.0036560658 Interpreter Loss: 12706.344\n",
      "Epoch:[ 4 ] Batch: 554 / 937 Main Model Loss: 0.03572885 Interpreter Loss: 14262.123\n",
      "Epoch:[ 4 ] Batch: 555 / 937 Main Model Loss: 0.0067276554 Interpreter Loss: 11526.08\n",
      "Epoch:[ 4 ] Batch: 556 / 937 Main Model Loss: 0.04050935 Interpreter Loss: 11986.646\n",
      "Epoch:[ 4 ] Batch: 557 / 937 Main Model Loss: 0.017094774 Interpreter Loss: 12214.313\n",
      "Epoch:[ 4 ] Batch: 558 / 937 Main Model Loss: 0.0078862235 Interpreter Loss: 11961.297\n",
      "Epoch:[ 4 ] Batch: 559 / 937 Main Model Loss: 0.0007964756 Interpreter Loss: 11249.162\n",
      "Epoch:[ 4 ] Batch: 560 / 937 Main Model Loss: 0.0032985103 Interpreter Loss: 11991.166\n",
      "Epoch:[ 4 ] Batch: 561 / 937 Main Model Loss: 0.012970453 Interpreter Loss: 11165.689\n",
      "Epoch:[ 4 ] Batch: 562 / 937 Main Model Loss: 0.062314082 Interpreter Loss: 12103.717\n",
      "Epoch:[ 4 ] Batch: 563 / 937 Main Model Loss: 0.042644225 Interpreter Loss: 12083.878\n",
      "Epoch:[ 4 ] Batch: 564 / 937 Main Model Loss: 0.027546417 Interpreter Loss: 12586.424\n",
      "Epoch:[ 4 ] Batch: 565 / 937 Main Model Loss: 0.0035055082 Interpreter Loss: 13248.9375\n",
      "Epoch:[ 4 ] Batch: 566 / 937 Main Model Loss: 0.011012062 Interpreter Loss: 13016.38\n",
      "Epoch:[ 4 ] Batch: 567 / 937 Main Model Loss: 0.0036465125 Interpreter Loss: 12756.012\n",
      "Epoch:[ 4 ] Batch: 568 / 937 Main Model Loss: 0.003760235 Interpreter Loss: 11771.831\n",
      "Epoch:[ 4 ] Batch: 569 / 937 Main Model Loss: 0.057998825 Interpreter Loss: 13662.879\n",
      "Epoch:[ 4 ] Batch: 570 / 937 Main Model Loss: 0.0009728952 Interpreter Loss: 11326.096\n",
      "Epoch:[ 4 ] Batch: 571 / 937 Main Model Loss: 0.00136208 Interpreter Loss: 13155.185\n",
      "Epoch:[ 4 ] Batch: 572 / 937 Main Model Loss: 0.00271259 Interpreter Loss: 12806.056\n",
      "Epoch:[ 4 ] Batch: 573 / 937 Main Model Loss: 0.002346074 Interpreter Loss: 13185.445\n",
      "Epoch:[ 4 ] Batch: 574 / 937 Main Model Loss: 0.009440861 Interpreter Loss: 13533.169\n",
      "Epoch:[ 4 ] Batch: 575 / 937 Main Model Loss: 0.049590718 Interpreter Loss: 13343.83\n",
      "Epoch:[ 4 ] Batch: 576 / 937 Main Model Loss: 0.02882769 Interpreter Loss: 12706.635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 4 ] Batch: 577 / 937 Main Model Loss: 0.060151994 Interpreter Loss: 12418.036\n",
      "Epoch:[ 4 ] Batch: 578 / 937 Main Model Loss: 0.022545224 Interpreter Loss: 12349.553\n",
      "Epoch:[ 4 ] Batch: 579 / 937 Main Model Loss: 0.015648475 Interpreter Loss: 13454.764\n",
      "Epoch:[ 4 ] Batch: 580 / 937 Main Model Loss: 0.0040999632 Interpreter Loss: 12871.23\n",
      "Epoch:[ 4 ] Batch: 581 / 937 Main Model Loss: 0.004755648 Interpreter Loss: 12807.061\n",
      "Epoch:[ 4 ] Batch: 582 / 937 Main Model Loss: 0.0030421668 Interpreter Loss: 13561.539\n",
      "Epoch:[ 4 ] Batch: 583 / 937 Main Model Loss: 0.0066334037 Interpreter Loss: 13299.353\n",
      "Epoch:[ 4 ] Batch: 584 / 937 Main Model Loss: 0.0031045666 Interpreter Loss: 12390.03\n",
      "Epoch:[ 4 ] Batch: 585 / 937 Main Model Loss: 0.006717303 Interpreter Loss: 13307.299\n",
      "Epoch:[ 4 ] Batch: 586 / 937 Main Model Loss: 0.015091872 Interpreter Loss: 12005.813\n",
      "Epoch:[ 4 ] Batch: 587 / 937 Main Model Loss: 0.0036267256 Interpreter Loss: 11439.289\n",
      "Epoch:[ 4 ] Batch: 588 / 937 Main Model Loss: 0.040219326 Interpreter Loss: 11649.553\n",
      "Epoch:[ 4 ] Batch: 589 / 937 Main Model Loss: 0.021482334 Interpreter Loss: 13775.299\n",
      "Epoch:[ 4 ] Batch: 590 / 937 Main Model Loss: 0.012320254 Interpreter Loss: 13420.91\n",
      "Epoch:[ 4 ] Batch: 591 / 937 Main Model Loss: 0.0136940945 Interpreter Loss: 13259.685\n",
      "Epoch:[ 4 ] Batch: 592 / 937 Main Model Loss: 0.0025319043 Interpreter Loss: 13578.548\n",
      "Epoch:[ 4 ] Batch: 593 / 937 Main Model Loss: 0.0027345703 Interpreter Loss: 12621.947\n",
      "Epoch:[ 4 ] Batch: 594 / 937 Main Model Loss: 0.009105637 Interpreter Loss: 11179.04\n",
      "Epoch:[ 4 ] Batch: 595 / 937 Main Model Loss: 0.0016336418 Interpreter Loss: 11975.847\n",
      "Epoch:[ 4 ] Batch: 596 / 937 Main Model Loss: 0.0019346841 Interpreter Loss: 11830.7705\n",
      "Epoch:[ 4 ] Batch: 597 / 937 Main Model Loss: 0.0025707583 Interpreter Loss: 11677.795\n",
      "Epoch:[ 4 ] Batch: 598 / 937 Main Model Loss: 0.009418967 Interpreter Loss: 12608.277\n",
      "Epoch:[ 4 ] Batch: 599 / 937 Main Model Loss: 0.038062964 Interpreter Loss: 12873.698\n",
      "Epoch:[ 4 ] Batch: 600 / 937 Main Model Loss: 0.1021062 Interpreter Loss: 12132.011\n",
      "Epoch:[ 4 ] Batch: 601 / 937 Main Model Loss: 0.0077741696 Interpreter Loss: 11200.078\n",
      "Epoch:[ 4 ] Batch: 602 / 937 Main Model Loss: 0.01846099 Interpreter Loss: 12037.13\n",
      "Epoch:[ 4 ] Batch: 603 / 937 Main Model Loss: 0.0074123153 Interpreter Loss: 13125.432\n",
      "Epoch:[ 4 ] Batch: 604 / 937 Main Model Loss: 0.032491416 Interpreter Loss: 11927.427\n",
      "Epoch:[ 4 ] Batch: 605 / 937 Main Model Loss: 0.008794956 Interpreter Loss: 12198.136\n",
      "Epoch:[ 4 ] Batch: 606 / 937 Main Model Loss: 0.007387325 Interpreter Loss: 11821.326\n",
      "Epoch:[ 4 ] Batch: 607 / 937 Main Model Loss: 0.002571688 Interpreter Loss: 11739.673\n",
      "Epoch:[ 4 ] Batch: 608 / 937 Main Model Loss: 0.017479151 Interpreter Loss: 11631.664\n",
      "Epoch:[ 4 ] Batch: 609 / 937 Main Model Loss: 0.0038586226 Interpreter Loss: 11398.307\n",
      "Epoch:[ 4 ] Batch: 610 / 937 Main Model Loss: 0.0003555106 Interpreter Loss: 11422.966\n",
      "Epoch:[ 4 ] Batch: 611 / 937 Main Model Loss: 0.017289624 Interpreter Loss: 12998.138\n",
      "Epoch:[ 4 ] Batch: 612 / 937 Main Model Loss: 0.039169185 Interpreter Loss: 12648.438\n",
      "Epoch:[ 4 ] Batch: 613 / 937 Main Model Loss: 0.005852625 Interpreter Loss: 13041.239\n",
      "Epoch:[ 4 ] Batch: 614 / 937 Main Model Loss: 0.021782966 Interpreter Loss: 13516.088\n",
      "Epoch:[ 4 ] Batch: 615 / 937 Main Model Loss: 0.040178668 Interpreter Loss: 13527.202\n",
      "Epoch:[ 4 ] Batch: 616 / 937 Main Model Loss: 0.00258582 Interpreter Loss: 12686.444\n",
      "Epoch:[ 4 ] Batch: 617 / 937 Main Model Loss: 0.0065743667 Interpreter Loss: 12328.075\n",
      "Epoch:[ 4 ] Batch: 618 / 937 Main Model Loss: 0.0051557086 Interpreter Loss: 12375.109\n",
      "Epoch:[ 4 ] Batch: 619 / 937 Main Model Loss: 0.014700284 Interpreter Loss: 13267.431\n",
      "Epoch:[ 4 ] Batch: 620 / 937 Main Model Loss: 0.029988877 Interpreter Loss: 12268.245\n",
      "Epoch:[ 4 ] Batch: 621 / 937 Main Model Loss: 0.0045397617 Interpreter Loss: 10824.186\n",
      "Epoch:[ 4 ] Batch: 622 / 937 Main Model Loss: 0.0040528327 Interpreter Loss: 11770.147\n",
      "Epoch:[ 4 ] Batch: 623 / 937 Main Model Loss: 0.005060205 Interpreter Loss: 11589.578\n",
      "Epoch:[ 4 ] Batch: 624 / 937 Main Model Loss: 0.020989986 Interpreter Loss: 12606.537\n",
      "Epoch:[ 4 ] Batch: 625 / 937 Main Model Loss: 0.010030237 Interpreter Loss: 11860.454\n",
      "Epoch:[ 4 ] Batch: 626 / 937 Main Model Loss: 0.0114255175 Interpreter Loss: 12468.526\n",
      "Epoch:[ 4 ] Batch: 627 / 937 Main Model Loss: 0.0026469026 Interpreter Loss: 12968.239\n",
      "Epoch:[ 4 ] Batch: 628 / 937 Main Model Loss: 0.019543912 Interpreter Loss: 12228.597\n",
      "Epoch:[ 4 ] Batch: 629 / 937 Main Model Loss: 0.02166898 Interpreter Loss: 13453.897\n",
      "Epoch:[ 4 ] Batch: 630 / 937 Main Model Loss: 0.004120567 Interpreter Loss: 11917.008\n",
      "Epoch:[ 4 ] Batch: 631 / 937 Main Model Loss: 0.0015199147 Interpreter Loss: 12519.394\n",
      "Epoch:[ 4 ] Batch: 632 / 937 Main Model Loss: 0.011411327 Interpreter Loss: 13004.825\n",
      "Epoch:[ 4 ] Batch: 633 / 937 Main Model Loss: 0.0033645274 Interpreter Loss: 12220.595\n",
      "Epoch:[ 4 ] Batch: 634 / 937 Main Model Loss: 0.03357971 Interpreter Loss: 12890.281\n",
      "Epoch:[ 4 ] Batch: 635 / 937 Main Model Loss: 0.023981959 Interpreter Loss: 11655.871\n",
      "Epoch:[ 4 ] Batch: 636 / 937 Main Model Loss: 0.003860596 Interpreter Loss: 12237.398\n",
      "Epoch:[ 4 ] Batch: 637 / 937 Main Model Loss: 0.0035278918 Interpreter Loss: 11330.75\n",
      "Epoch:[ 4 ] Batch: 638 / 937 Main Model Loss: 0.047184736 Interpreter Loss: 12159.79\n",
      "Epoch:[ 4 ] Batch: 639 / 937 Main Model Loss: 0.008082471 Interpreter Loss: 11497.87\n",
      "Epoch:[ 4 ] Batch: 640 / 937 Main Model Loss: 0.018149355 Interpreter Loss: 12630.392\n",
      "Epoch:[ 4 ] Batch: 641 / 937 Main Model Loss: 0.01846147 Interpreter Loss: 11924.728\n",
      "Epoch:[ 4 ] Batch: 642 / 937 Main Model Loss: 0.007967376 Interpreter Loss: 11659.523\n",
      "Epoch:[ 4 ] Batch: 643 / 937 Main Model Loss: 0.06975138 Interpreter Loss: 13410.253\n",
      "Epoch:[ 4 ] Batch: 644 / 937 Main Model Loss: 0.0024640185 Interpreter Loss: 12398.157\n",
      "Epoch:[ 4 ] Batch: 645 / 937 Main Model Loss: 0.02303229 Interpreter Loss: 13336.668\n",
      "Epoch:[ 4 ] Batch: 646 / 937 Main Model Loss: 0.012775242 Interpreter Loss: 12656.486\n",
      "Epoch:[ 4 ] Batch: 647 / 937 Main Model Loss: 0.010491954 Interpreter Loss: 13449.827\n",
      "Epoch:[ 4 ] Batch: 648 / 937 Main Model Loss: 0.014540672 Interpreter Loss: 11244.405\n",
      "Epoch:[ 4 ] Batch: 649 / 937 Main Model Loss: 0.015194808 Interpreter Loss: 13412.465\n",
      "Epoch:[ 4 ] Batch: 650 / 937 Main Model Loss: 0.0017034598 Interpreter Loss: 11672.512\n",
      "Epoch:[ 4 ] Batch: 651 / 937 Main Model Loss: 0.0010646424 Interpreter Loss: 10686.213\n",
      "Epoch:[ 4 ] Batch: 652 / 937 Main Model Loss: 0.047321137 Interpreter Loss: 10203.155\n",
      "Epoch:[ 4 ] Batch: 653 / 937 Main Model Loss: 0.012388018 Interpreter Loss: 11712.154\n",
      "Epoch:[ 4 ] Batch: 654 / 937 Main Model Loss: 0.018481618 Interpreter Loss: 12918.561\n",
      "Epoch:[ 4 ] Batch: 655 / 937 Main Model Loss: 0.006072442 Interpreter Loss: 13226.863\n",
      "Epoch:[ 4 ] Batch: 656 / 937 Main Model Loss: 0.061663948 Interpreter Loss: 13476.836\n",
      "Epoch:[ 4 ] Batch: 657 / 937 Main Model Loss: 0.022293624 Interpreter Loss: 12885.934\n",
      "Epoch:[ 4 ] Batch: 658 / 937 Main Model Loss: 0.0032880725 Interpreter Loss: 13077.529\n",
      "Epoch:[ 4 ] Batch: 659 / 937 Main Model Loss: 0.003326402 Interpreter Loss: 12849.564\n",
      "Epoch:[ 4 ] Batch: 660 / 937 Main Model Loss: 0.002915459 Interpreter Loss: 12555.708\n",
      "Epoch:[ 4 ] Batch: 661 / 937 Main Model Loss: 0.024425104 Interpreter Loss: 12472.023\n",
      "Epoch:[ 4 ] Batch: 662 / 937 Main Model Loss: 0.004472138 Interpreter Loss: 12436.002\n",
      "Epoch:[ 4 ] Batch: 663 / 937 Main Model Loss: 0.011267224 Interpreter Loss: 12627.102\n",
      "Epoch:[ 4 ] Batch: 664 / 937 Main Model Loss: 0.0049463017 Interpreter Loss: 11910.22\n",
      "Epoch:[ 4 ] Batch: 665 / 937 Main Model Loss: 0.030560523 Interpreter Loss: 12690.288\n",
      "Epoch:[ 4 ] Batch: 666 / 937 Main Model Loss: 0.0024423301 Interpreter Loss: 13085.84\n",
      "Epoch:[ 4 ] Batch: 667 / 937 Main Model Loss: 0.037028577 Interpreter Loss: 12441.067\n",
      "Epoch:[ 4 ] Batch: 668 / 937 Main Model Loss: 0.004930215 Interpreter Loss: 12933.272\n",
      "Epoch:[ 4 ] Batch: 669 / 937 Main Model Loss: 0.0457332 Interpreter Loss: 12369.796\n",
      "Epoch:[ 4 ] Batch: 670 / 937 Main Model Loss: 0.0038474544 Interpreter Loss: 12405.483\n",
      "Epoch:[ 4 ] Batch: 671 / 937 Main Model Loss: 0.0035425301 Interpreter Loss: 11334.1455\n",
      "Epoch:[ 4 ] Batch: 672 / 937 Main Model Loss: 0.01643375 Interpreter Loss: 12605.971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 4 ] Batch: 673 / 937 Main Model Loss: 0.031471062 Interpreter Loss: 11588.98\n",
      "Epoch:[ 4 ] Batch: 674 / 937 Main Model Loss: 0.0032925154 Interpreter Loss: 12605.697\n",
      "Epoch:[ 4 ] Batch: 675 / 937 Main Model Loss: 0.0017154084 Interpreter Loss: 11878.513\n",
      "Epoch:[ 4 ] Batch: 676 / 937 Main Model Loss: 0.008441825 Interpreter Loss: 11651.615\n",
      "Epoch:[ 4 ] Batch: 677 / 937 Main Model Loss: 0.032296102 Interpreter Loss: 13458.993\n",
      "Epoch:[ 4 ] Batch: 678 / 937 Main Model Loss: 0.0051964507 Interpreter Loss: 12631.49\n",
      "Epoch:[ 4 ] Batch: 679 / 937 Main Model Loss: 0.11007752 Interpreter Loss: 11976.286\n",
      "Epoch:[ 4 ] Batch: 680 / 937 Main Model Loss: 0.013668112 Interpreter Loss: 11806.854\n",
      "Epoch:[ 4 ] Batch: 681 / 937 Main Model Loss: 0.0018206718 Interpreter Loss: 11830.341\n",
      "Epoch:[ 4 ] Batch: 682 / 937 Main Model Loss: 0.031160776 Interpreter Loss: 12466.295\n",
      "Epoch:[ 4 ] Batch: 683 / 937 Main Model Loss: 0.0003104366 Interpreter Loss: 11270.962\n",
      "Epoch:[ 4 ] Batch: 684 / 937 Main Model Loss: 0.0055090543 Interpreter Loss: 11748.005\n",
      "Epoch:[ 4 ] Batch: 685 / 937 Main Model Loss: 0.009245986 Interpreter Loss: 12292.918\n",
      "Epoch:[ 4 ] Batch: 686 / 937 Main Model Loss: 0.042790014 Interpreter Loss: 11726.969\n",
      "Epoch:[ 4 ] Batch: 687 / 937 Main Model Loss: 0.0056828316 Interpreter Loss: 11073.285\n",
      "Epoch:[ 4 ] Batch: 688 / 937 Main Model Loss: 0.0019674795 Interpreter Loss: 11551.935\n",
      "Epoch:[ 4 ] Batch: 689 / 937 Main Model Loss: 0.001953514 Interpreter Loss: 11322.588\n",
      "Epoch:[ 4 ] Batch: 690 / 937 Main Model Loss: 0.0018289449 Interpreter Loss: 11824.535\n",
      "Epoch:[ 4 ] Batch: 691 / 937 Main Model Loss: 0.005476071 Interpreter Loss: 12724.811\n",
      "Epoch:[ 4 ] Batch: 692 / 937 Main Model Loss: 0.0069730487 Interpreter Loss: 12487.305\n",
      "Epoch:[ 4 ] Batch: 693 / 937 Main Model Loss: 0.018058563 Interpreter Loss: 11203.445\n",
      "Epoch:[ 4 ] Batch: 694 / 937 Main Model Loss: 0.0052561895 Interpreter Loss: 14054.922\n",
      "Epoch:[ 4 ] Batch: 695 / 937 Main Model Loss: 0.0040368177 Interpreter Loss: 11819.73\n",
      "Epoch:[ 4 ] Batch: 696 / 937 Main Model Loss: 0.01517363 Interpreter Loss: 11377.684\n",
      "Epoch:[ 4 ] Batch: 697 / 937 Main Model Loss: 0.0030595616 Interpreter Loss: 11520.337\n",
      "Epoch:[ 4 ] Batch: 698 / 937 Main Model Loss: 0.006077885 Interpreter Loss: 11477.498\n",
      "Epoch:[ 4 ] Batch: 699 / 937 Main Model Loss: 0.0019656147 Interpreter Loss: 11297.378\n",
      "Epoch:[ 4 ] Batch: 700 / 937 Main Model Loss: 0.017012376 Interpreter Loss: 12100.759\n",
      "Epoch:[ 4 ] Batch: 701 / 937 Main Model Loss: 0.020824991 Interpreter Loss: 12599.866\n",
      "Epoch:[ 4 ] Batch: 702 / 937 Main Model Loss: 0.007848287 Interpreter Loss: 11937.957\n",
      "Epoch:[ 4 ] Batch: 703 / 937 Main Model Loss: 0.0045556533 Interpreter Loss: 11671.473\n",
      "Epoch:[ 4 ] Batch: 704 / 937 Main Model Loss: 0.00861039 Interpreter Loss: 12596.612\n",
      "Epoch:[ 4 ] Batch: 705 / 937 Main Model Loss: 0.01769454 Interpreter Loss: 12848.036\n",
      "Epoch:[ 4 ] Batch: 706 / 937 Main Model Loss: 0.0019298046 Interpreter Loss: 12225.353\n",
      "Epoch:[ 4 ] Batch: 707 / 937 Main Model Loss: 0.043293633 Interpreter Loss: 12887.842\n",
      "Epoch:[ 4 ] Batch: 708 / 937 Main Model Loss: 0.019248884 Interpreter Loss: 11560.53\n",
      "Epoch:[ 4 ] Batch: 709 / 937 Main Model Loss: 0.055443708 Interpreter Loss: 11996.138\n",
      "Epoch:[ 4 ] Batch: 710 / 937 Main Model Loss: 0.038683143 Interpreter Loss: 11961.447\n",
      "Epoch:[ 4 ] Batch: 711 / 937 Main Model Loss: 0.040719107 Interpreter Loss: 12324.172\n",
      "Epoch:[ 4 ] Batch: 712 / 937 Main Model Loss: 0.016045421 Interpreter Loss: 13218.381\n",
      "Epoch:[ 4 ] Batch: 713 / 937 Main Model Loss: 0.003747316 Interpreter Loss: 11862.614\n",
      "Epoch:[ 4 ] Batch: 714 / 937 Main Model Loss: 0.0015073596 Interpreter Loss: 11423.534\n",
      "Epoch:[ 4 ] Batch: 715 / 937 Main Model Loss: 0.032672234 Interpreter Loss: 12115.775\n",
      "Epoch:[ 4 ] Batch: 716 / 937 Main Model Loss: 0.0042970697 Interpreter Loss: 13415.897\n",
      "Epoch:[ 4 ] Batch: 717 / 937 Main Model Loss: 0.0023060064 Interpreter Loss: 11019.298\n",
      "Epoch:[ 4 ] Batch: 718 / 937 Main Model Loss: 0.021062495 Interpreter Loss: 11979.1045\n",
      "Epoch:[ 4 ] Batch: 719 / 937 Main Model Loss: 0.023107788 Interpreter Loss: 11701.199\n",
      "Epoch:[ 4 ] Batch: 720 / 937 Main Model Loss: 0.014713142 Interpreter Loss: 11533.608\n",
      "Epoch:[ 4 ] Batch: 721 / 937 Main Model Loss: 0.052000556 Interpreter Loss: 12249.909\n",
      "Epoch:[ 4 ] Batch: 722 / 937 Main Model Loss: 0.033281907 Interpreter Loss: 14280.099\n",
      "Epoch:[ 4 ] Batch: 723 / 937 Main Model Loss: 0.021679351 Interpreter Loss: 12089.948\n",
      "Epoch:[ 4 ] Batch: 724 / 937 Main Model Loss: 0.0027299304 Interpreter Loss: 12045.787\n",
      "Epoch:[ 4 ] Batch: 725 / 937 Main Model Loss: 0.027558785 Interpreter Loss: 12834.352\n",
      "Epoch:[ 4 ] Batch: 726 / 937 Main Model Loss: 0.0011012845 Interpreter Loss: 11311.569\n",
      "Epoch:[ 4 ] Batch: 727 / 937 Main Model Loss: 0.0072728274 Interpreter Loss: 11677.689\n",
      "Epoch:[ 4 ] Batch: 728 / 937 Main Model Loss: 0.013446061 Interpreter Loss: 12327.383\n",
      "Epoch:[ 4 ] Batch: 729 / 937 Main Model Loss: 0.009614975 Interpreter Loss: 12841.207\n",
      "Epoch:[ 4 ] Batch: 730 / 937 Main Model Loss: 0.05505881 Interpreter Loss: 13168.944\n",
      "Epoch:[ 4 ] Batch: 731 / 937 Main Model Loss: 0.0012662229 Interpreter Loss: 12514.307\n",
      "Epoch:[ 4 ] Batch: 732 / 937 Main Model Loss: 0.033053618 Interpreter Loss: 13391.418\n",
      "Epoch:[ 4 ] Batch: 733 / 937 Main Model Loss: 0.0037830204 Interpreter Loss: 11466.357\n",
      "Epoch:[ 4 ] Batch: 734 / 937 Main Model Loss: 0.013983517 Interpreter Loss: 13360.077\n",
      "Epoch:[ 4 ] Batch: 735 / 937 Main Model Loss: 0.0008053831 Interpreter Loss: 11790.491\n",
      "Epoch:[ 4 ] Batch: 736 / 937 Main Model Loss: 0.001572161 Interpreter Loss: 12033.035\n",
      "Epoch:[ 4 ] Batch: 737 / 937 Main Model Loss: 0.015636574 Interpreter Loss: 12250.367\n",
      "Epoch:[ 4 ] Batch: 738 / 937 Main Model Loss: 0.058393754 Interpreter Loss: 13090.052\n",
      "Epoch:[ 4 ] Batch: 739 / 937 Main Model Loss: 0.01381956 Interpreter Loss: 12330.5\n",
      "Epoch:[ 4 ] Batch: 740 / 937 Main Model Loss: 0.0311469 Interpreter Loss: 12629.423\n",
      "Epoch:[ 4 ] Batch: 741 / 937 Main Model Loss: 0.024644457 Interpreter Loss: 15067.152\n",
      "Epoch:[ 4 ] Batch: 742 / 937 Main Model Loss: 0.03691053 Interpreter Loss: 13006.305\n",
      "Epoch:[ 4 ] Batch: 743 / 937 Main Model Loss: 0.015123233 Interpreter Loss: 14145.095\n",
      "Epoch:[ 4 ] Batch: 744 / 937 Main Model Loss: 0.0065289484 Interpreter Loss: 13533.695\n",
      "Epoch:[ 4 ] Batch: 745 / 937 Main Model Loss: 0.015591958 Interpreter Loss: 13841.683\n",
      "Epoch:[ 4 ] Batch: 746 / 937 Main Model Loss: 0.011367423 Interpreter Loss: 12537.675\n",
      "Epoch:[ 4 ] Batch: 747 / 937 Main Model Loss: 0.003828499 Interpreter Loss: 12285.479\n",
      "Epoch:[ 4 ] Batch: 748 / 937 Main Model Loss: 0.031855296 Interpreter Loss: 12150.624\n",
      "Epoch:[ 4 ] Batch: 749 / 937 Main Model Loss: 0.021304129 Interpreter Loss: 12576.062\n",
      "Epoch:[ 4 ] Batch: 750 / 937 Main Model Loss: 0.004573842 Interpreter Loss: 12730.701\n",
      "Epoch:[ 4 ] Batch: 751 / 937 Main Model Loss: 0.051654637 Interpreter Loss: 13179.018\n",
      "Epoch:[ 4 ] Batch: 752 / 937 Main Model Loss: 0.0010704886 Interpreter Loss: 12280.801\n",
      "Epoch:[ 4 ] Batch: 753 / 937 Main Model Loss: 0.0043417597 Interpreter Loss: 13173.375\n",
      "Epoch:[ 4 ] Batch: 754 / 937 Main Model Loss: 0.0060043097 Interpreter Loss: 12712.575\n",
      "Epoch:[ 4 ] Batch: 755 / 937 Main Model Loss: 0.063183025 Interpreter Loss: 13587.595\n",
      "Epoch:[ 4 ] Batch: 756 / 937 Main Model Loss: 0.0017433763 Interpreter Loss: 12252.48\n",
      "Epoch:[ 4 ] Batch: 757 / 937 Main Model Loss: 0.018173778 Interpreter Loss: 12005.303\n",
      "Epoch:[ 4 ] Batch: 758 / 937 Main Model Loss: 0.022461332 Interpreter Loss: 13325.272\n",
      "Epoch:[ 4 ] Batch: 759 / 937 Main Model Loss: 0.025162581 Interpreter Loss: 13108.404\n",
      "Epoch:[ 4 ] Batch: 760 / 937 Main Model Loss: 0.03306134 Interpreter Loss: 12073.823\n",
      "Epoch:[ 4 ] Batch: 761 / 937 Main Model Loss: 0.0037377009 Interpreter Loss: 12016.89\n",
      "Epoch:[ 4 ] Batch: 762 / 937 Main Model Loss: 0.0071534757 Interpreter Loss: 12897.209\n",
      "Epoch:[ 4 ] Batch: 763 / 937 Main Model Loss: 0.0016978846 Interpreter Loss: 11733.461\n",
      "Epoch:[ 4 ] Batch: 764 / 937 Main Model Loss: 0.006016127 Interpreter Loss: 11709.934\n",
      "Epoch:[ 4 ] Batch: 765 / 937 Main Model Loss: 0.054922942 Interpreter Loss: 12447.019\n",
      "Epoch:[ 4 ] Batch: 766 / 937 Main Model Loss: 0.016752262 Interpreter Loss: 12497.01\n",
      "Epoch:[ 4 ] Batch: 767 / 937 Main Model Loss: 0.02243492 Interpreter Loss: 12603.097\n",
      "Epoch:[ 4 ] Batch: 768 / 937 Main Model Loss: 0.0037963535 Interpreter Loss: 13033.645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 4 ] Batch: 769 / 937 Main Model Loss: 0.038773637 Interpreter Loss: 11961.224\n",
      "Epoch:[ 4 ] Batch: 770 / 937 Main Model Loss: 0.0012154839 Interpreter Loss: 11421.08\n",
      "Epoch:[ 4 ] Batch: 771 / 937 Main Model Loss: 0.0024693953 Interpreter Loss: 11214.773\n",
      "Epoch:[ 4 ] Batch: 772 / 937 Main Model Loss: 0.039016496 Interpreter Loss: 11909.682\n",
      "Epoch:[ 4 ] Batch: 773 / 937 Main Model Loss: 0.040690534 Interpreter Loss: 13104.219\n",
      "Epoch:[ 4 ] Batch: 774 / 937 Main Model Loss: 0.0881197 Interpreter Loss: 12775.125\n",
      "Epoch:[ 4 ] Batch: 775 / 937 Main Model Loss: 0.011095802 Interpreter Loss: 12741.396\n",
      "Epoch:[ 4 ] Batch: 776 / 937 Main Model Loss: 0.0015462779 Interpreter Loss: 11214.748\n",
      "Epoch:[ 4 ] Batch: 777 / 937 Main Model Loss: 0.023135662 Interpreter Loss: 13003.007\n",
      "Epoch:[ 4 ] Batch: 778 / 937 Main Model Loss: 0.010156047 Interpreter Loss: 11369.911\n",
      "Epoch:[ 4 ] Batch: 779 / 937 Main Model Loss: 0.03633062 Interpreter Loss: 12941.385\n",
      "Epoch:[ 4 ] Batch: 780 / 937 Main Model Loss: 0.0044576284 Interpreter Loss: 10856.403\n",
      "Epoch:[ 4 ] Batch: 781 / 937 Main Model Loss: 0.0033390892 Interpreter Loss: 11472.22\n",
      "Epoch:[ 4 ] Batch: 782 / 937 Main Model Loss: 0.010400832 Interpreter Loss: 11616.327\n",
      "Epoch:[ 4 ] Batch: 783 / 937 Main Model Loss: 0.026204197 Interpreter Loss: 12066.021\n",
      "Epoch:[ 4 ] Batch: 784 / 937 Main Model Loss: 0.040545173 Interpreter Loss: 13359.695\n",
      "Epoch:[ 4 ] Batch: 785 / 937 Main Model Loss: 0.010000764 Interpreter Loss: 11333.486\n",
      "Epoch:[ 4 ] Batch: 786 / 937 Main Model Loss: 0.059318192 Interpreter Loss: 14047.644\n",
      "Epoch:[ 4 ] Batch: 787 / 937 Main Model Loss: 0.025225263 Interpreter Loss: 14067.274\n",
      "Epoch:[ 4 ] Batch: 788 / 937 Main Model Loss: 0.0116854105 Interpreter Loss: 12540.094\n",
      "Epoch:[ 4 ] Batch: 789 / 937 Main Model Loss: 0.012340017 Interpreter Loss: 12334.302\n",
      "Epoch:[ 4 ] Batch: 790 / 937 Main Model Loss: 0.007578009 Interpreter Loss: 12013.106\n",
      "Epoch:[ 4 ] Batch: 791 / 937 Main Model Loss: 0.0029088357 Interpreter Loss: 11292.171\n",
      "Epoch:[ 4 ] Batch: 792 / 937 Main Model Loss: 0.020191878 Interpreter Loss: 13330.79\n",
      "Epoch:[ 4 ] Batch: 793 / 937 Main Model Loss: 0.0036162129 Interpreter Loss: 12054.525\n",
      "Epoch:[ 4 ] Batch: 794 / 937 Main Model Loss: 0.008298746 Interpreter Loss: 11568.779\n",
      "Epoch:[ 4 ] Batch: 795 / 937 Main Model Loss: 0.12515119 Interpreter Loss: 14376.272\n",
      "Epoch:[ 4 ] Batch: 796 / 937 Main Model Loss: 0.0070105623 Interpreter Loss: 11584.788\n",
      "Epoch:[ 4 ] Batch: 797 / 937 Main Model Loss: 0.014787336 Interpreter Loss: 11241.913\n",
      "Epoch:[ 4 ] Batch: 798 / 937 Main Model Loss: 0.006210087 Interpreter Loss: 11993.495\n",
      "Epoch:[ 4 ] Batch: 799 / 937 Main Model Loss: 0.01775344 Interpreter Loss: 12884.954\n",
      "Epoch:[ 4 ] Batch: 800 / 937 Main Model Loss: 0.02247492 Interpreter Loss: 14399.108\n",
      "Epoch:[ 4 ] Batch: 801 / 937 Main Model Loss: 0.016826505 Interpreter Loss: 13692.45\n",
      "Epoch:[ 4 ] Batch: 802 / 937 Main Model Loss: 0.0074018585 Interpreter Loss: 12424.124\n",
      "Epoch:[ 4 ] Batch: 803 / 937 Main Model Loss: 0.027220946 Interpreter Loss: 12251.185\n",
      "Epoch:[ 4 ] Batch: 804 / 937 Main Model Loss: 0.015999334 Interpreter Loss: 13269.444\n",
      "Epoch:[ 4 ] Batch: 805 / 937 Main Model Loss: 0.009190476 Interpreter Loss: 11649.495\n",
      "Epoch:[ 4 ] Batch: 806 / 937 Main Model Loss: 0.0022269245 Interpreter Loss: 11985.839\n",
      "Epoch:[ 4 ] Batch: 807 / 937 Main Model Loss: 0.008303415 Interpreter Loss: 11367.415\n",
      "Epoch:[ 4 ] Batch: 808 / 937 Main Model Loss: 0.005661166 Interpreter Loss: 11593.486\n",
      "Epoch:[ 4 ] Batch: 809 / 937 Main Model Loss: 0.0023351174 Interpreter Loss: 12218.406\n",
      "Epoch:[ 4 ] Batch: 810 / 937 Main Model Loss: 0.0032385534 Interpreter Loss: 11094.363\n",
      "Epoch:[ 4 ] Batch: 811 / 937 Main Model Loss: 0.033643503 Interpreter Loss: 11662.165\n",
      "Epoch:[ 4 ] Batch: 812 / 937 Main Model Loss: 0.050446264 Interpreter Loss: 11720.327\n",
      "Epoch:[ 4 ] Batch: 813 / 937 Main Model Loss: 0.010892647 Interpreter Loss: 10886.711\n",
      "Epoch:[ 4 ] Batch: 814 / 937 Main Model Loss: 0.024116479 Interpreter Loss: 12867.54\n",
      "Epoch:[ 4 ] Batch: 815 / 937 Main Model Loss: 0.0043834914 Interpreter Loss: 11040.513\n",
      "Epoch:[ 4 ] Batch: 816 / 937 Main Model Loss: 0.039246947 Interpreter Loss: 11660.457\n",
      "Epoch:[ 4 ] Batch: 817 / 937 Main Model Loss: 0.020438928 Interpreter Loss: 13142.701\n",
      "Epoch:[ 4 ] Batch: 818 / 937 Main Model Loss: 0.0015332492 Interpreter Loss: 11623.736\n",
      "Epoch:[ 4 ] Batch: 819 / 937 Main Model Loss: 0.018638045 Interpreter Loss: 12402.891\n",
      "Epoch:[ 4 ] Batch: 820 / 937 Main Model Loss: 0.0056884806 Interpreter Loss: 11746.082\n",
      "Epoch:[ 4 ] Batch: 821 / 937 Main Model Loss: 0.0012432327 Interpreter Loss: 11418.0\n",
      "Epoch:[ 4 ] Batch: 822 / 937 Main Model Loss: 0.0050333915 Interpreter Loss: 11282.993\n",
      "Epoch:[ 4 ] Batch: 823 / 937 Main Model Loss: 0.026480427 Interpreter Loss: 12058.234\n",
      "Epoch:[ 4 ] Batch: 824 / 937 Main Model Loss: 0.0029936477 Interpreter Loss: 11197.162\n",
      "Epoch:[ 4 ] Batch: 825 / 937 Main Model Loss: 0.020561874 Interpreter Loss: 12853.69\n",
      "Epoch:[ 4 ] Batch: 826 / 937 Main Model Loss: 0.0111184325 Interpreter Loss: 13172.559\n",
      "Epoch:[ 4 ] Batch: 827 / 937 Main Model Loss: 0.10366964 Interpreter Loss: 13878.314\n",
      "Epoch:[ 4 ] Batch: 828 / 937 Main Model Loss: 0.016863003 Interpreter Loss: 12607.611\n",
      "Epoch:[ 4 ] Batch: 829 / 937 Main Model Loss: 0.011440601 Interpreter Loss: 11986.978\n",
      "Epoch:[ 4 ] Batch: 830 / 937 Main Model Loss: 0.00088889 Interpreter Loss: 11345.874\n",
      "Epoch:[ 4 ] Batch: 831 / 937 Main Model Loss: 0.008694857 Interpreter Loss: 12459.43\n",
      "Epoch:[ 4 ] Batch: 832 / 937 Main Model Loss: 0.00041806273 Interpreter Loss: 11403.62\n",
      "Epoch:[ 4 ] Batch: 833 / 937 Main Model Loss: 0.0031343675 Interpreter Loss: 11125.052\n",
      "Epoch:[ 4 ] Batch: 834 / 937 Main Model Loss: 0.08251742 Interpreter Loss: 12483.982\n",
      "Epoch:[ 4 ] Batch: 835 / 937 Main Model Loss: 0.0068239984 Interpreter Loss: 11514.475\n",
      "Epoch:[ 4 ] Batch: 836 / 937 Main Model Loss: 0.002684191 Interpreter Loss: 11332.864\n",
      "Epoch:[ 4 ] Batch: 837 / 937 Main Model Loss: 0.007065447 Interpreter Loss: 11168.716\n",
      "Epoch:[ 4 ] Batch: 838 / 937 Main Model Loss: 0.04569089 Interpreter Loss: 12132.433\n",
      "Epoch:[ 4 ] Batch: 839 / 937 Main Model Loss: 0.03313803 Interpreter Loss: 11910.642\n",
      "Epoch:[ 4 ] Batch: 840 / 937 Main Model Loss: 0.0071647763 Interpreter Loss: 11143.547\n",
      "Epoch:[ 4 ] Batch: 841 / 937 Main Model Loss: 0.028826907 Interpreter Loss: 12531.12\n",
      "Epoch:[ 4 ] Batch: 842 / 937 Main Model Loss: 0.037903838 Interpreter Loss: 12727.641\n",
      "Epoch:[ 4 ] Batch: 843 / 937 Main Model Loss: 0.039996356 Interpreter Loss: 13182.487\n",
      "Epoch:[ 4 ] Batch: 844 / 937 Main Model Loss: 0.018232593 Interpreter Loss: 12159.268\n",
      "Epoch:[ 4 ] Batch: 845 / 937 Main Model Loss: 0.0010247579 Interpreter Loss: 11348.414\n",
      "Epoch:[ 4 ] Batch: 846 / 937 Main Model Loss: 0.0044307006 Interpreter Loss: 12137.059\n",
      "Epoch:[ 4 ] Batch: 847 / 937 Main Model Loss: 0.009082581 Interpreter Loss: 10896.235\n",
      "Epoch:[ 4 ] Batch: 848 / 937 Main Model Loss: 0.006648704 Interpreter Loss: 11662.824\n",
      "Epoch:[ 4 ] Batch: 849 / 937 Main Model Loss: 0.004232047 Interpreter Loss: 11810.587\n",
      "Epoch:[ 4 ] Batch: 850 / 937 Main Model Loss: 0.011563585 Interpreter Loss: 11865.929\n",
      "Epoch:[ 4 ] Batch: 851 / 937 Main Model Loss: 0.008211914 Interpreter Loss: 12573.162\n",
      "Epoch:[ 4 ] Batch: 852 / 937 Main Model Loss: 0.017690344 Interpreter Loss: 12944.989\n",
      "Epoch:[ 4 ] Batch: 853 / 937 Main Model Loss: 0.008351295 Interpreter Loss: 11999.174\n",
      "Epoch:[ 4 ] Batch: 854 / 937 Main Model Loss: 0.0012354268 Interpreter Loss: 11574.344\n",
      "Epoch:[ 4 ] Batch: 855 / 937 Main Model Loss: 0.014444875 Interpreter Loss: 12848.05\n",
      "Epoch:[ 4 ] Batch: 856 / 937 Main Model Loss: 0.0017014806 Interpreter Loss: 12604.392\n",
      "Epoch:[ 4 ] Batch: 857 / 937 Main Model Loss: 0.02983586 Interpreter Loss: 12390.531\n",
      "Epoch:[ 4 ] Batch: 858 / 937 Main Model Loss: 0.010432212 Interpreter Loss: 12145.275\n",
      "Epoch:[ 4 ] Batch: 859 / 937 Main Model Loss: 0.0036649806 Interpreter Loss: 12050.786\n",
      "Epoch:[ 4 ] Batch: 860 / 937 Main Model Loss: 0.0106861815 Interpreter Loss: 11509.207\n",
      "Epoch:[ 4 ] Batch: 861 / 937 Main Model Loss: 0.0033205694 Interpreter Loss: 11383.461\n",
      "Epoch:[ 4 ] Batch: 862 / 937 Main Model Loss: 0.0016831879 Interpreter Loss: 11858.736\n",
      "Epoch:[ 4 ] Batch: 863 / 937 Main Model Loss: 0.002970517 Interpreter Loss: 11738.228\n",
      "Epoch:[ 4 ] Batch: 864 / 937 Main Model Loss: 0.0097484635 Interpreter Loss: 12547.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[ 4 ] Batch: 865 / 937 Main Model Loss: 0.0021962577 Interpreter Loss: 11034.253\n",
      "Epoch:[ 4 ] Batch: 866 / 937 Main Model Loss: 0.009251737 Interpreter Loss: 11390.851\n",
      "Epoch:[ 4 ] Batch: 867 / 937 Main Model Loss: 0.007644904 Interpreter Loss: 12805.433\n",
      "Epoch:[ 4 ] Batch: 868 / 937 Main Model Loss: 0.013286174 Interpreter Loss: 13005.036\n",
      "Epoch:[ 4 ] Batch: 869 / 937 Main Model Loss: 0.005995552 Interpreter Loss: 13396.404\n",
      "Epoch:[ 4 ] Batch: 870 / 937 Main Model Loss: 0.06033737 Interpreter Loss: 13318.849\n",
      "Epoch:[ 4 ] Batch: 871 / 937 Main Model Loss: 0.013813734 Interpreter Loss: 13588.984\n",
      "Epoch:[ 4 ] Batch: 872 / 937 Main Model Loss: 0.0126605695 Interpreter Loss: 11738.593\n",
      "Epoch:[ 4 ] Batch: 873 / 937 Main Model Loss: 0.0050728563 Interpreter Loss: 12781.459\n",
      "Epoch:[ 4 ] Batch: 874 / 937 Main Model Loss: 0.00066296064 Interpreter Loss: 11361.58\n",
      "Epoch:[ 4 ] Batch: 875 / 937 Main Model Loss: 0.051014114 Interpreter Loss: 11772.042\n",
      "Epoch:[ 4 ] Batch: 876 / 937 Main Model Loss: 0.019758437 Interpreter Loss: 11805.089\n",
      "Epoch:[ 4 ] Batch: 877 / 937 Main Model Loss: 0.027367633 Interpreter Loss: 12307.158\n",
      "Epoch:[ 4 ] Batch: 878 / 937 Main Model Loss: 0.0033595609 Interpreter Loss: 11925.822\n",
      "Epoch:[ 4 ] Batch: 879 / 937 Main Model Loss: 0.00696005 Interpreter Loss: 11601.903\n",
      "Epoch:[ 4 ] Batch: 880 / 937 Main Model Loss: 0.0032862728 Interpreter Loss: 10846.661\n",
      "Epoch:[ 4 ] Batch: 881 / 937 Main Model Loss: 0.0045706863 Interpreter Loss: 10848.815\n",
      "Epoch:[ 4 ] Batch: 882 / 937 Main Model Loss: 0.012655799 Interpreter Loss: 11525.304\n",
      "Epoch:[ 4 ] Batch: 883 / 937 Main Model Loss: 0.00037827875 Interpreter Loss: 11463.723\n",
      "Epoch:[ 4 ] Batch: 884 / 937 Main Model Loss: 0.0062827575 Interpreter Loss: 11729.676\n",
      "Epoch:[ 4 ] Batch: 885 / 937 Main Model Loss: 0.001652245 Interpreter Loss: 11287.717\n",
      "Epoch:[ 4 ] Batch: 886 / 937 Main Model Loss: 0.005314976 Interpreter Loss: 12182.654\n",
      "Epoch:[ 4 ] Batch: 887 / 937 Main Model Loss: 0.016744196 Interpreter Loss: 11950.459\n",
      "Epoch:[ 4 ] Batch: 888 / 937 Main Model Loss: 0.0027256138 Interpreter Loss: 12207.703\n",
      "Epoch:[ 4 ] Batch: 889 / 937 Main Model Loss: 0.0007316205 Interpreter Loss: 11060.131\n",
      "Epoch:[ 4 ] Batch: 890 / 937 Main Model Loss: 0.008931747 Interpreter Loss: 11121.517\n",
      "Epoch:[ 4 ] Batch: 891 / 937 Main Model Loss: 0.021063277 Interpreter Loss: 11622.93\n",
      "Epoch:[ 4 ] Batch: 892 / 937 Main Model Loss: 0.0003437667 Interpreter Loss: 10490.629\n",
      "Epoch:[ 4 ] Batch: 893 / 937 Main Model Loss: 0.003044372 Interpreter Loss: 11467.715\n",
      "Epoch:[ 4 ] Batch: 894 / 937 Main Model Loss: 0.00587184 Interpreter Loss: 11657.402\n",
      "Epoch:[ 4 ] Batch: 895 / 937 Main Model Loss: 0.0027447331 Interpreter Loss: 11820.785\n",
      "Epoch:[ 4 ] Batch: 896 / 937 Main Model Loss: 0.004278927 Interpreter Loss: 11488.226\n",
      "Epoch:[ 4 ] Batch: 897 / 937 Main Model Loss: 0.012801767 Interpreter Loss: 12060.319\n",
      "Epoch:[ 4 ] Batch: 898 / 937 Main Model Loss: 0.005747557 Interpreter Loss: 12089.586\n",
      "Epoch:[ 4 ] Batch: 899 / 937 Main Model Loss: 0.0058527016 Interpreter Loss: 11845.745\n",
      "Epoch:[ 4 ] Batch: 900 / 937 Main Model Loss: 0.009160151 Interpreter Loss: 12277.58\n",
      "Epoch:[ 4 ] Batch: 901 / 937 Main Model Loss: 0.01081692 Interpreter Loss: 10721.914\n",
      "Epoch:[ 4 ] Batch: 902 / 937 Main Model Loss: 0.01694001 Interpreter Loss: 12652.708\n",
      "Epoch:[ 4 ] Batch: 903 / 937 Main Model Loss: 0.005904944 Interpreter Loss: 10847.199\n",
      "Epoch:[ 4 ] Batch: 904 / 937 Main Model Loss: 0.0019110274 Interpreter Loss: 11000.035\n",
      "Epoch:[ 4 ] Batch: 905 / 937 Main Model Loss: 0.004678376 Interpreter Loss: 10839.124\n",
      "Epoch:[ 4 ] Batch: 906 / 937 Main Model Loss: 0.010067968 Interpreter Loss: 11944.425\n",
      "Epoch:[ 4 ] Batch: 907 / 937 Main Model Loss: 0.009489621 Interpreter Loss: 11775.961\n",
      "Epoch:[ 4 ] Batch: 908 / 937 Main Model Loss: 0.001929719 Interpreter Loss: 10170.489\n",
      "Epoch:[ 4 ] Batch: 909 / 937 Main Model Loss: 0.0014688373 Interpreter Loss: 11067.045\n",
      "Epoch:[ 4 ] Batch: 910 / 937 Main Model Loss: 0.0008997867 Interpreter Loss: 11431.007\n",
      "Epoch:[ 4 ] Batch: 911 / 937 Main Model Loss: 0.0018554983 Interpreter Loss: 11467.555\n",
      "Epoch:[ 4 ] Batch: 912 / 937 Main Model Loss: 0.007341279 Interpreter Loss: 12397.121\n",
      "Epoch:[ 4 ] Batch: 913 / 937 Main Model Loss: 0.00043281243 Interpreter Loss: 11717.177\n",
      "Epoch:[ 4 ] Batch: 914 / 937 Main Model Loss: 0.017858123 Interpreter Loss: 10763.738\n",
      "Epoch:[ 4 ] Batch: 915 / 937 Main Model Loss: 0.0008154501 Interpreter Loss: 9842.229\n",
      "Epoch:[ 4 ] Batch: 916 / 937 Main Model Loss: 0.0020720726 Interpreter Loss: 10038.939\n",
      "Epoch:[ 4 ] Batch: 917 / 937 Main Model Loss: 0.0015622927 Interpreter Loss: 9693.937\n",
      "Epoch:[ 4 ] Batch: 918 / 937 Main Model Loss: 0.016734473 Interpreter Loss: 11135.013\n",
      "Epoch:[ 4 ] Batch: 919 / 937 Main Model Loss: 0.017400227 Interpreter Loss: 12241.019\n",
      "Epoch:[ 4 ] Batch: 920 / 937 Main Model Loss: 0.001376379 Interpreter Loss: 11122.75\n",
      "Epoch:[ 4 ] Batch: 921 / 937 Main Model Loss: 5.4278946e-05 Interpreter Loss: 11143.955\n",
      "Epoch:[ 4 ] Batch: 922 / 937 Main Model Loss: 0.0023995482 Interpreter Loss: 10783.026\n",
      "Epoch:[ 4 ] Batch: 923 / 937 Main Model Loss: 7.3234485e-05 Interpreter Loss: 10739.806\n",
      "Epoch:[ 4 ] Batch: 924 / 937 Main Model Loss: 4.584324e-05 Interpreter Loss: 10796.075\n",
      "Epoch:[ 4 ] Batch: 925 / 937 Main Model Loss: 0.0025794958 Interpreter Loss: 11124.255\n",
      "Epoch:[ 4 ] Batch: 926 / 937 Main Model Loss: 0.004147571 Interpreter Loss: 12284.777\n",
      "Epoch:[ 4 ] Batch: 927 / 937 Main Model Loss: 0.0015985128 Interpreter Loss: 13948.256\n",
      "Epoch:[ 4 ] Batch: 928 / 937 Main Model Loss: 0.0070138965 Interpreter Loss: 15266.762\n",
      "Epoch:[ 4 ] Batch: 929 / 937 Main Model Loss: 0.00068737945 Interpreter Loss: 12090.254\n",
      "Epoch:[ 4 ] Batch: 930 / 937 Main Model Loss: 0.0002876495 Interpreter Loss: 10330.239\n",
      "Epoch:[ 4 ] Batch: 931 / 937 Main Model Loss: 0.00053470593 Interpreter Loss: 10981.036\n",
      "Epoch:[ 4 ] Batch: 932 / 937 Main Model Loss: 0.015711082 Interpreter Loss: 13396.518\n",
      "Epoch:[ 4 ] Batch: 933 / 937 Main Model Loss: 0.08497216 Interpreter Loss: 12956.311\n",
      "Epoch:[ 4 ] Batch: 934 / 937 Main Model Loss: 0.0026281294 Interpreter Loss: 12149.365\n",
      "Epoch:[ 4 ] Batch: 935 / 937 Main Model Loss: 0.0019955256 Interpreter Loss: 11789.536\n",
      "Epoch:[ 4 ] Batch: 936 / 937 Main Model Loss: 0.039067637 Interpreter Loss: 11688.333\n",
      " Main Model Acc:  0.96875 Interpreter Acc:  0.984375\n",
      "INFO:tensorflow:Assets written to: checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoint/assets\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    pine = PINE(batch_size=64, dataset_name=\"mnist\")\n",
    "    pine.train(epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "interpreter_model = tf.keras.models.load_model('checkpoint')\n",
    "samples = []\n",
    "X_test = pd.read_csv(\"test.csv\")\n",
    "X_test = X_test/255\n",
    "X_test = X_test.values.reshape(-1,28,28,1)\n",
    "tests = X_test[0:64]\n",
    "interpreter_model.compile()\n",
    "interprets = interpreter_model(tests)\n",
    "interprets = interprets.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2016x2016 with 128 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "fig, axs = plt.subplots(16, 8, figsize=(28,28))\n",
    "axs[0, 0].set_title('Input Image')\n",
    "axs[0, 2].set_title('Input Image')\n",
    "axs[0, 4].set_title('Input Image')\n",
    "axs[0, 6].set_title('Input Image')\n",
    "axs[0, 1].set_title('Interpretation')\n",
    "axs[0, 3].set_title('Interpretation')\n",
    "axs[0, 5].set_title('Interpretation')\n",
    "axs[0, 7].set_title('Interpretation')\n",
    "\n",
    "fig= plt.figure(figsize=(20, 20))\n",
    "\n",
    "for j in range(0,4):\n",
    "    for i in range(0,16):\n",
    "        tests_figs = tests[i+j*16].reshape((28,28))\n",
    "        axs[i, 2*j].imshow(tests_figs)\n",
    "        axs[i, 2*j].axis('off')\n",
    "\n",
    "        \n",
    "for j in range(0,4):\n",
    "    for i in range(0,16):\n",
    "        interprets_figs = interprets[i+j*16].reshape((28,28))\n",
    "        axs[i, 2*j+1].imshow(interprets_figs)\n",
    "        axs[i, 2*j+1].axis('off')        \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
