{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZPLVgFyn9wMM"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, UpSampling2D, Cropping2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "eX9A5-1l92Bg"
   },
   "outputs": [],
   "source": [
    "class PINE():\n",
    "  model_name = \"pine_mnist\"     # name for checkpoint\n",
    "  dataset_name = \"mnist\"\n",
    "\n",
    "  def __init__(self, batch_size, dataset_name):\n",
    "    \n",
    "      # Input shape\n",
    "      self.img_rows = 28\n",
    "      self.img_cols = 28\n",
    "      self.channels = 1\n",
    "      self.y_dim = 10\n",
    "      self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "      self.latent_dim = 100 \n",
    "      self.batch_size = batch_size\n",
    "      self.learning_rate_main_model = 0.0001\n",
    "      self.learning_rate_interpreter = 0.0001\n",
    "      self.checkpoint_dir = 'checkpoint'\n",
    "      self.dataset_name = dataset_name\n",
    " \n",
    "      # Build and compile the interpreter\n",
    "      self.interpreter = self.build_interpreter()\n",
    "\n",
    "      # Build the mian model\n",
    "      self.main_model = self.build_main_model()\n",
    "\n",
    "  def build_main_model(self):\n",
    "    \n",
    "    #    ___________\n",
    "    #   /           \\\n",
    "    #  / MAIN  MODEL \\\n",
    "    # /_______________\\\n",
    "    # model: https://github.com/yashk2810/MNIST-Keras/blob/master/Notebook/MNIST_keras_CNN-99.55%25.ipynb\n",
    "    \n",
    "    \n",
    "    imgs = tf.keras.Input(shape=(28, 28, 1), name=\"img\")\n",
    "    x = tf.keras.layers.Conv2D(32, 3, activation=\"relu\")(imgs)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = tf.keras.layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(2)(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = tf.keras.layers.Conv2D(64, 3, activation=\"relu\")(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = tf.keras.layers.Conv2D(64, 3, activation=\"relu\")(x)\n",
    "\n",
    "    x = tf.keras.layers.MaxPooling2D(2)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "    # Fully connected layer\n",
    "    x = BatchNormalization()(x)\n",
    "    out_logit = tf.keras.layers.Dense(512, activation=\"relu\")(x)\n",
    "    x = BatchNormalization()(out_logit)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    out = tf.keras.layers.Dense(10, activation=\"softmax\")(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs = imgs, outputs = out)\n",
    "\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "  def build_interpreter(self):\n",
    "    # _________________\n",
    "    # \\               /\n",
    "    #  \\             /\n",
    "    #   \\           /\n",
    "    #    INTERPRETER\n",
    "    #   /           \\\n",
    "    #  /             \\\n",
    "    # /_______________\\\n",
    "\n",
    "    # model = https://github.com/nathanhubens/Autoencoders/blob/master/Autoencoders.ipynb\n",
    "\n",
    "    # # Encoder\n",
    "    encoder_input = tf.keras.Input(shape=(28, 28, 1), name=\"img\")\n",
    "    x = tf.keras.layers.Conv2D(16, 3, activation=\"relu\", padding='same')(encoder_input)\n",
    "    x = tf.keras.layers.MaxPooling2D(2, padding='same')(x)\n",
    "    x = tf.keras.layers.Conv2D(8, 3, activation=\"relu\", padding='same')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(2, padding='same')(x)\n",
    "    x = tf.keras.layers.Conv2D(8, 3, activation=\"relu\", padding='same')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(2, padding='same')(x)\n",
    "\n",
    "    # # Decoder\n",
    "    x = tf.keras.layers.Conv2D(8, 3, activation=\"relu\", padding='same')(x)\n",
    "    x = tf.keras.layers.UpSampling2D(2)(x)\n",
    "    x = tf.keras.layers.Conv2D(8, 3, activation=\"relu\", padding='same')(x)\n",
    "    x = tf.keras.layers.UpSampling2D(2)(x)\n",
    "    x = tf.keras.layers.Conv2D(16, 3, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.UpSampling2D(2)(x)\n",
    "    out = tf.keras.layers.Conv2D(1, 3, activation=\"sigmoid\", padding='same')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs = encoder_input, outputs = out)\n",
    "\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    return model\n",
    "\n",
    "  def train(self, epochs, batch_size=128):\n",
    "    def categorical_accuracy(self, y_true, y_pred):\n",
    "      return tf.keras.backend.mean(tf.keras.backend.equal(tf.math.argmax(y_true, axis=-1), tf.math.argmax(y_pred, axis=-1)))\n",
    "        #################################################### \n",
    "        #                                ________________  #\n",
    "        #         ___________           \\               /  #\n",
    "        #        /           \\           \\             /   #\n",
    "        # Train / MAIN  MODEL \\           \\           /    #\n",
    "        #      /_______________\\           INTERPRETER     #\n",
    "        #                                 /           \\    #\n",
    "        #                                /             \\   #\n",
    "        #                               /_______________\\  #\n",
    "        ####################################################\n",
    "\n",
    "\n",
    "    start_batch_id=0\n",
    "    self.epochs = epochs\n",
    "\n",
    "    # Load the dataset\n",
    "    (X_train,y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "    # Rescale -1 to 1\n",
    "    X_train = X_train / 127.5 - 1.\n",
    "    X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "\n",
    "    X_test = X_test / 127.5 - 1.\n",
    "    X_test = np.expand_dims(X_test, axis=3)\n",
    "\n",
    "    y_vec = np.zeros((len(y_train), 10), dtype=np.float)\n",
    "    for i, label in enumerate(y_train):\n",
    "        y_vec[i, y_train[i]] = 1.0\n",
    "\n",
    "    y_vec_test = np.zeros((len(y_test), 10), dtype=np.float)\n",
    "    for i, label in enumerate(y_test):\n",
    "        y_vec_test[i, y_test[i]] = 1.0\n",
    "\n",
    "    # Adversarial ground truths\n",
    "    valid = np.ones((batch_size, 1))\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "    opt_interpreter = tf.keras.optimizers.Adam(self.learning_rate_interpreter)\n",
    "    opt_main_model = tf.keras.optimizers.Adam(self.learning_rate_main_model)\n",
    "    \n",
    "\n",
    "    self.num_batches = len(X_train) // self.batch_size    \n",
    "    for epoch in range(self.epochs):\n",
    "      for idx in range(start_batch_id, self.num_batches):\n",
    "        print('Batch:',idx,'/',self.num_batches, end=\" \")\n",
    "        imgs = X_train[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "        self.y = y_vec[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        # Iterate over the batches of a dataset.\n",
    "        # Open a GradientTape.\n",
    "        with tf.GradientTape(persistent= True) as tape:\n",
    "\n",
    "        # Train the interpreter (real classified as ones and generated as zeros)\n",
    "          ints = self.interpreter(imgs, training=True)\n",
    "\n",
    "          out_int = self.main_model(ints, training=True)\n",
    "\n",
    "          out_img = self.main_model(imgs, training=True)\n",
    "\n",
    "\n",
    "          # Get gradients of loss wrt the weights.\n",
    "          # Main Model Loss\n",
    "          CatCrossEnt = tf.keras.losses.CategoricalCrossentropy()\n",
    "          loss_eval = CatCrossEnt(self.y, out_img)\n",
    "          main_model_grads = tape.gradient(loss_eval, self.main_model.trainable_weights)\n",
    "          # Interpreter Loss\n",
    "          out_int = self.main_model(ints)\n",
    "          int_error = tf.sqrt(2 * tf.nn.l2_loss(out_img - out_int)) / self.batch_size        \n",
    "          l1 = tf.dtypes.cast(int_error, tf.float32)\n",
    "          l2 = tf.dtypes.cast(CatCrossEnt(self.y, out_int), tf.float32)\n",
    "          out_sqrt = tf.keras.backend.sqrt(out_int)\n",
    "          sumi = tf.keras.backend.sum(out_sqrt)**2        \n",
    "          l3 = tf.dtypes.cast(0.0002*(sumi), tf.float32)\n",
    "          self.interpreter_loss = l1 + l2 + l3\n",
    "          interpreter_grads = tape.gradient(self.interpreter_loss, self.interpreter.trainable_weights)\n",
    "\n",
    "\n",
    "          # Update the weights of the model.\n",
    "          \n",
    "          opt_interpreter.apply_gradients(zip(interpreter_grads, self.interpreter.trainable_weights))\n",
    "          opt_main_model.apply_gradients(zip(main_model_grads, self.main_model.trainable_weights))\n",
    "        # print('Main Model Loss: '+ loss_eval+  'Interpreter Loss: '+self.interpreter_loss)\n",
    "        print('Main Model Loss:',loss_eval.numpy(), end=\" \")\n",
    "        print('Interpreter Loss:',self.interpreter_loss.numpy())\n",
    "        \n",
    "\n",
    "      # self.main_model.save_model(self.checkpoint_dir)\n",
    "      # self.interpreter.save_model(self.checkpoint_dir)\n",
    "      pred_label = numpy.argmax(pred) # pred_label = 1 (index)\n",
    "\n",
    "      ints_test = self.interpreter(X_test, training=False)\n",
    "\n",
    "      out_int_test = self.main_model(ints_test, training=False)\n",
    "\n",
    "      out_img_test = self.main_model(X_test, training=False)\n",
    "\n",
    "      main_model_acc = categorical_accuracy(self, y_vec_test,out_img_test)\n",
    "      interpreter_acc =categorical_accuracy(self, y_vec_test,out_int_test)\n",
    "      print(' Main Model Acc: ', main_model_acc.numpy(), 'Interpreter Acc: ', interpreter_acc.numpy())\n",
    "      self.main_model.save(self.checkpoint_dir)\n",
    "      self.interpreter.save(self.checkpoint_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JGnfmtjmYAvO",
    "outputId": "bff34aea-8507-4e0d-b924-7129fb8f3c9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_50\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img (InputLayer)             [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_275 (Conv2D)          (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_125 (MaxPoolin (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_276 (Conv2D)          (None, 14, 14, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_126 (MaxPoolin (None, 7, 7, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_277 (Conv2D)          (None, 7, 7, 8)           584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_127 (MaxPoolin (None, 4, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_278 (Conv2D)          (None, 4, 4, 8)           584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_75 (UpSampling (None, 8, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_279 (Conv2D)          (None, 8, 8, 8)           584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_76 (UpSampling (None, 16, 16, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_280 (Conv2D)          (None, 14, 14, 16)        1168      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_77 (UpSampling (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_281 (Conv2D)          (None, 28, 28, 1)         145       \n",
      "=================================================================\n",
      "Total params: 4,385\n",
      "Trainable params: 4,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_51\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img (InputLayer)             [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_282 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_125 (Bat (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_283 (Conv2D)          (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_128 (MaxPoolin (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_126 (Bat (None, 12, 12, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_284 (Conv2D)          (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_127 (Bat (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_285 (Conv2D)          (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_129 (MaxPoolin (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_25 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_128 (Bat (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_129 (Bat (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 601,578\n",
      "Trainable params: 598,250\n",
      "Non-trainable params: 3,328\n",
      "_________________________________________________________________\n",
      "None\n",
      "Batch: 0 / 937 WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "Main Model Loss: 3.1700482 Interpreter Loss: 10.545897\n",
      "Batch: 1 / 937 Main Model Loss: 2.9069343 Interpreter Loss: 10.550109\n",
      "Batch: 2 / 937 Main Model Loss: 2.592688 Interpreter Loss: 10.545563\n",
      "Batch: 3 / 937 Main Model Loss: 2.6287537 Interpreter Loss: 10.559293\n",
      "Batch: 4 / 937 Main Model Loss: 2.144786 Interpreter Loss: 10.545287\n",
      "Batch: 5 / 937 Main Model Loss: 2.167188 Interpreter Loss: 10.5331745\n",
      "Batch: 6 / 937 Main Model Loss: 2.0378306 Interpreter Loss: 10.53225\n",
      "Batch: 7 / 937 Main Model Loss: 1.8844335 Interpreter Loss: 10.542729\n",
      "Batch: 8 / 937 Main Model Loss: 1.5809427 Interpreter Loss: 10.538219\n",
      "Batch: 9 / 937 Main Model Loss: 2.1257763 Interpreter Loss: 10.510813\n",
      "Batch: 10 / 937 Main Model Loss: 1.5248148 Interpreter Loss: 10.531046\n",
      "Batch: 11 / 937 Main Model Loss: 1.4939853 Interpreter Loss: 10.519705\n",
      "Batch: 12 / 937 Main Model Loss: 1.3735676 Interpreter Loss: 10.490477\n",
      "Batch: 13 / 937 Main Model Loss: 1.3502952 Interpreter Loss: 10.53138\n",
      "Batch: 14 / 937 Main Model Loss: 1.5572126 Interpreter Loss: 10.462388\n",
      "Batch: 15 / 937 Main Model Loss: 1.396707 Interpreter Loss: 10.492282\n",
      "Batch: 16 / 937 Main Model Loss: 1.1860209 Interpreter Loss: 10.415206\n",
      "Batch: 17 / 937 "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    pine = PINE(batch_size=64, dataset_name=\"mnist\")\n",
    "    pine.train(epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nq3-C8KWz_4n"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-5M-EBGiniH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
